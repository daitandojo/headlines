
# File: .claude/settings.local.json
{
  "permissions": {
    "allow": ["Bash(rm:src/config/users.js)"],
    "deny": []
  }
}


# File: .dockerignore
# File: .dockerignore (version 1.01)
/.git
/node_modules
.dockerignore
.env

# Explicitly include package-lock.json to ensure it's in the build context,
# overriding any other potential ignore rules.
!package-lock.json

# File: .env.template
      
# .env.template
# This file provides a template for the required environment variables.
# Copy this file to .env and fill in your actual values.
# DO NOT COMMIT THE .env FILE TO VERSION CONTROL.

# --- Core Application Behavior ---
NODE_ENV=development # 'development' or 'production'
LOG_LEVEL=debug      # 'debug', 'info', 'warn', 'error'
CONCURRENCY_LIMIT=3  # Number of parallel network operations (scraping, AI calls)
FORCE_EMAIL_SEND_DEV=true # Set to 'true' to force emails to be sent even if NODE_ENV is 'development'

# --- MongoDB Configuration ---
MONGO_URI="mongodb+srv://user:password@cluster.mongodb.net/database?retryWrites=true&w=majority"

# --- AI API Configuration ---
OPENAI_API_KEY=sk-proj-....
LLM_MODEL="gpt-5-mini"
GROQ_API_KEY=gsk_...

# --- NEW: Third-Party Service APIs ---
SERPAPI_API_KEY="Your_SerpApi_Api_Key_Here"

# --- Email Sending Configuration (via Nodemailer) ---
SMTP_HOST=smtp.gmail.com
SMTP_PORT=465
SMTP_SECURE=true # true for 465, false for other ports
SMTP_USER="your-email@gmail.com"
SMTP_PASS="your-app-password" # Use an App Password for Gmail
SMTP_FROM_ADDRESS="your-email@gmail.com"
SMTP_FROM_NAME="Wealth Events Bot"


# --- NEW: Push Notification VAPID Keys ---
# Generate these once using `npx web-push generate-vapid-keys`
VAPID_SUBJECT="mailto:your-email@gmail.com"
VAPID_PUBLIC_KEY="..."
VAPID_PRIVATE_KEY="..."

# --- NEW: Pusher Real-time Service ---
PUSHER_APP_ID="..."
PUSHER_KEY="..."
PUSHER_SECRET="..."
PUSHER_CLUSTER="..."

# --- Email Recipients ---
# All user and supervisor email recipients are now managed in ./src/config/users.js
# No environment variables are needed for recipients.

    

# File: .github/workflows/fly-deploy.yml
# See https://fly.io/docs/app-guides/continuous-deployment-with-github-actions/

name: Fly Deploy
on:
  push:
    branches:
      - main
jobs:
  deploy:
    name: Deploy app
    runs-on: ubuntu-latest
    concurrency: deploy-group
    steps:
      - uses: actions/checkout@v4
      
      # Step 1: Install flyctl using the official installer.
      - name: Install flyctl
        run: |
          curl -L https://fly.io/install.sh | sh
          # Step 2: Add flyctl to the PATH for subsequent steps.
          # This is the officially recommended and robust method.
          echo "/home/runner/.fly/bin" >> $GITHUB_PATH

      - name: Deploy to Fly.io
        # Now 'flyctl' can be called directly because its location is in the PATH.
        run: flyctl deploy --remote-only
        env:
          FLY_API_TOKEN: ${{ secrets.FLY_API_TOKEN }}

# File: .github/workflows/run-pipeline.yml
name: Run Pipeline on Schedule

on:
  workflow_dispatch: # Allows you to run this workflow manually from the Actions tab
  schedule:
    # IMPORTANT: GitHub schedules run on UTC time.
    # 10:00 Copenhagen (CEST, UTC+2) is 08:00 UTC
    # 16:30 Copenhagen (CEST, UTC+2) is 14:30 UTC
    - cron: '25 11 * * *'
    - cron: '25 12 * * *'
    - cron: '25 13 * * *'
    - cron: '25 16 * * *'

jobs:
  run-on-fly:
    name: Start a Fly Machine to Run the Pipeline
    runs-on: ubuntu-latest

    steps:
      # Step 1: Check out your repository's code
      - uses: actions/checkout@v4
      
      # Step 2: Install flyctl and add it to the PATH.
      - name: Install flyctl
        run: |
          curl -L https://fly.io/install.sh | sh
          echo "/home/runner/.fly/bin" >> $GITHUB_PATH
        
      # Step 3: Run the machine command.
      - name: Start a temporary machine and wait for completion
        env:
          FLY_API_TOKEN: ${{ secrets.FLY_API_TOKEN }}
        run: |
          # 'flyctl' can now be called directly.
          # MODIFIED: Replaced --autodestroy with --rm, the original and more compatible flag.
          # This ensures the machine is automatically destroyed server-side upon completion.
          flyctl machine run . --region lhr --memory 2048 --rm
          
          echo "The machine has completed its run and has been destroyed."

# File: .gitignore
/node_modules
/contacts
/.pnpm
/debug
error_run
.pnp.*
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/versions
# data only
papers.json
/scripts
# misc
.DS_Store
*.pem
# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*
# env files
.env*
!/.env.template
# vercel
.vercel
# typescript
*.tsbuildinfo
next-env.d.ts


# File: .nvmrc
20.15.1


# File: Dockerfile
# File: Dockerfile (version 1.03)
# syntax = docker/dockerfile:1

ARG NODE_VERSION=20.15.1
FROM node:${NODE_VERSION}-slim AS base

WORKDIR /app

# --- Build Stage ---
FROM base AS build
RUN apt-get update -qq && apt-get install -y --no-install-recommends build-essential python-is-python3
COPY package-lock.json package.json ./

# Switch to `npm install` which is more robust than `npm ci` in complex scenarios,
# especially with `file:` dependencies that might exist locally but not in the build context.
# Using --omit=dev is equivalent to --production, ensuring dev dependencies are not installed.
RUN npm install --omit=dev

COPY . .

# --- Final Production Image ---
FROM base
COPY --from=build --chown=node:node /app /app

# As root, install system dependencies needed for Playwright's browser.
# This ensures that the headless browser can run in the container.
RUN apt-get update -qq && \
    apt-get install -y --no-install-recommends wget ca-certificates && \
    npx playwright install-deps chromium && \
    rm -rf /var/lib/apt/lists/*

USER node

# As the non-root 'node' user, install the browser binary itself.
# It will be installed in the user's home directory cache (/home/node/.cache/ms-playwright).
RUN npx playwright install chromium

# This is no longer a web server, so no EXPOSE needed.
# It runs the pipeline script once and then exits.
CMD [ "node", "app.js" ]

# File: app-logic.js
// app-logic.js (version 3.0)
import { logger } from './src/utils/logger.js'
import { logFinalReport } from './src/utils/pipelineLogger.js'

// Import pipeline stages
import { runPreFlightChecks } from './src/pipeline/1_preflight.js'
import { runScrapeAndFilter } from './src/pipeline/2_scrapeAndFilter.js'
import { runAssessAndEnrich } from './src/pipeline/3_assessAndEnrich.js'
import { runClusterAndSynthesize } from './src/pipeline/4_clusterAndSynthesize.js'
import { runCommitAndNotify } from './src/pipeline/5_commitAndNotify.js'

export async function runPipeline(isRefreshMode = false) {
  const runStartTime = Date.now()
  logger.info('üöÄ STARTING DECOUPLED PIPELINE (v3.0)...')

  // Initialize the main data payload and run statistics object
  const pipelinePayload = {
    isRefreshMode,
    runStats: {
      headlinesScraped: 0,
      scraperHealth: [],
      freshHeadlinesFound: 0,
      headlinesAssessed: 0,
      relevantHeadlines: 0,
      enrichmentOutcomes: [],
      articlesEnriched: 0,
      relevantArticles: 0,
      enrichedBySource: {},
      eventsClustered: 0,
      eventsSynthesized: 0,
      synthesizedEventsForReport: [],
      eventsEmailed: 0,
      errors: [],
    },
    dbConnection: null,
  }

  try {
    // --- STAGE 1: PRE-FLIGHT CHECKS & CONNECTIONS ---
    const preflightResult = await runPreFlightChecks(pipelinePayload)
    if (!preflightResult.success) return // Abort if checks fail

    // --- STAGE 2: SCRAPE & FILTER ---
    const scrapeResult = await runScrapeAndFilter(preflightResult.payload)
    if (!scrapeResult.success) return // Abort if no new articles

    // --- STAGE 3: AI ASSESSMENT & ENRICHMENT ---
    const assessResult = await runAssessAndEnrich(scrapeResult.payload)
    if (!assessResult.success) return // Abort if no relevant articles after enrichment

    // --- STAGE 4: CLUSTERING & SYNTHESIS ---
    const synthesizeResult = await runClusterAndSynthesize(assessResult.payload)
    // This stage is not critical; if it fails, we still want to save the articles.

    // --- STAGE 5: COMMIT RESULTS & SEND NOTIFICATIONS ---
    await runCommitAndNotify(synthesizeResult.payload)
  } catch (error) {
    logger.fatal(
      { err: error },
      'A critical, unhandled error occurred in the main pipeline orchestrator.'
    )
    pipelinePayload.runStats.errors.push(`ORCHESTRATOR_FATAL: ${error.message}`)
    // Attempt to send a supervisor report even on critical failure
    await runCommitAndNotify(pipelinePayload)
  } finally {
    const runEndTime = Date.now()
    const duration = ((runEndTime - runStartTime) / 1000).toFixed(2)
    await logFinalReport(pipelinePayload.runStats, duration)
  }
}


# File: app.js
// app.js

// --- CRITICAL: Set environment based on command-line args BEFORE any other imports ---
// This ensures that all modules, especially the config, see the correct environment state
// from the very beginning of the application lifecycle.
const isRefreshMode = process.argv.includes('--refresh');
if (isRefreshMode) {
    process.env.REFRESH_MODE = 'true';
}

import 'dotenv/config'; // Load environment variables from .env file
import { logger } from './src/utils/logger.js';
import { runPipeline } from './app-logic.js';

// Now that the logger has been initialized (with the correct mode), we can safely log the warning.
if (isRefreshMode) {
    logger.warn('üöÄ REFRESH MODE ACTIVATED: Previously processed articles from this scrape will be treated as fresh.');
}

async function start() {
    try {
        // Pass the determined mode directly to the pipeline.
        await runPipeline(isRefreshMode);
        // The process will exit naturally after the pipeline completes.
    } catch (error) {
        logger.fatal({ err: error }, 'A top-level, unhandled exception occurred in the application. The pipeline did not complete.');
        // Exit with a failure code to signal an issue to the scheduler (e.g., Fly.io).
        process.exit(1);
    }
}

start();

# File: data/subscribers.json
[
  {
    "email": "christiansenalexandra@gmail.com",
    "password": "Stanley",
    "firstName": "Alexandra",
    "lastName": "Christiansen",
    "countries": [
      "Denmark"
    ],
    "role": "user",
    "emailNotificationsEnabled": true,
    "pushNotificationsEnabled": true,
    "subscriptionTier": "free",
    "subscriptionExpiresAt": null,
    "tokensPaid": 0,
    "isLifetimeFree": true,
    "isActive": true,
    "lastLoginAt": null
  },
  {
    "email": "reconozco@gmail.com",
    "password": "Stanley",
    "firstName": "Mark",
    "lastName": null,
    "countries": [
      "Denmark",
      "Norway",
      "Netherlands",
      "Global",
      "Scandinavia",
      "Europe"
    ],
    "role": "admin",
    "emailNotificationsEnabled": true,
    "pushNotificationsEnabled": true,
    "subscriptionTier": "free",
    "subscriptionExpiresAt": null,
    "tokensPaid": 0,
    "isLifetimeFree": true,
    "isActive": true,
    "lastLoginAt": null
  }
]

# File: docker-compose.yml
# docker-compose.yml (version 1.03)
# This file is for LOCAL DEVELOPMENT and TESTING ONLY.
# It allows us to reliably run the application in a container,
# mimicking the production environment.

services:
  app:
    # Build the image from the Dockerfile in the current directory.
    build: .
    # Use the .env file to supply environment variables to the container.
    # docker-compose has a robust parser that handles special characters correctly.
    env_file:
      - .env
    # The application is a script, not a web server, so no port mapping is needed.
    # Give the container a friendly name.
    container_name: headlines_local

# File: fly.toml
app = 'headlines-polished-sea-1731'
primary_region = 'lhr'

# This empty [processes] block tells flyctl to use the modern Machines platform
# and not look for a long-running web service.
# This is now the ONLY machine-related configuration in this file.
[processes]

# File: models/Article.js
// models/Article.js (version 2.4)
import mongoose from 'mongoose'

const { Schema, model, models } = mongoose

const ArticleSchema = new Schema(
  {
    headline: {
      type: String,
      required: true,
      trim: true,
      minlength: 5,
      maxlength: 500,
    },
    headline_en: { type: String, trim: true },
    link: { type: String, required: true, unique: true, trim: true },
    newspaper: { type: String, required: true, trim: true },
    source: { type: String, required: true, trim: true },
    country: { type: String, trim: true, index: true },
    imageUrl: { type: String, trim: true },
    headline_selector: { type: String, trim: true },
    relevance_headline: { type: Number, required: true, min: 0, max: 100 },
    assessment_headline: { type: String, required: true, trim: true },
    articleContent: {
      type: {
        contents: { type: [String], default: [] },
      },
      required: false,
    },
    topic: { type: String, trim: true },
    relevance_article: { type: Number, min: 0, max: 100 },
    assessment_article: { type: String, trim: true },
    amount: { type: Number },
    key_individuals: [
      {
        _id: false,
        name: { type: String, trim: true },
        role_in_event: { type: String, trim: true },
        company: { type: String, trim: true },
        email_suggestion: { type: String, trim: true },
      },
    ],
    enrichment_error: { type: String, trim: true },
    emailed: { type: Boolean, default: false },
    embedding: { type: [Number] },
  },
  {
    timestamps: true,
    collection: 'articles',
  }
)

ArticleSchema.index({ headline: 'text', headline_en: 'text', assessment_article: 'text' })
ArticleSchema.index({ newspaper: 1, createdAt: -1 })
ArticleSchema.index({ relevance_article: -1, createdAt: -1 })
ArticleSchema.index({ relevance_headline: -1, createdAt: -1 })
ArticleSchema.index({ country: 1, createdAt: -1 })

export default models.Article || model('Article', ArticleSchema)


# File: models/Opportunity.js
// src/models/Opportunity.js (version 3.1)
import mongoose from 'mongoose'

const { Schema, model, models } = mongoose

const ContactDetailsSchema = new Schema(
  {
    email: { type: String, trim: true },
    role: { type: String, trim: true },
    company: { type: String, trim: true },
  },
  { _id: false }
)

const OpportunitySchema = new Schema(
  {
    reachOutTo: { type: String, required: true, trim: true, unique: true, index: true },
    contactDetails: { type: ContactDetailsSchema },
    basedIn: { type: String, trim: true },
    whyContact: { type: [String], required: true },
    likelyMMDollarWealth: { type: Number, required: true, default: 0 },
    sourceArticleId: {
      type: Schema.Types.ObjectId,
      ref: 'Article',
      required: true,
      index: true,
    },
    sourceEventId: {
      type: Schema.Types.ObjectId,
      ref: 'SynthesizedEvent',
      required: true, // MADE REQUIRED
      index: true,
    },
  },
  {
    timestamps: true,
    collection: 'opportunities',
  }
)

export default models.Opportunity || model('Opportunity', OpportunitySchema)


# File: models/PushSubscription.js
// models/PushSubscription.js (version 1.1)
import mongoose from 'mongoose'

const { Schema, model, models } = mongoose

const PushSubscriptionSchema = new Schema(
  {
    subscriberId: {
      type: Schema.Types.ObjectId,
      ref: 'Subscriber',
      required: true,
      index: true,
    },
    endpoint: { type: String, required: true, unique: true },
    keys: {
      p256dh: { type: String, required: true },
      auth: { type: String, required: true },
    },
  },
  {
    timestamps: true,
    collection: 'push_subscriptions',
  }
)

export default models.PushSubscription ||
  model('PushSubscription', PushSubscriptionSchema)


# File: models/Source.js
// models/Source.js (version 1.0)
import mongoose from 'mongoose'

const { Schema, model, models } = mongoose

const SourceSchema = new Schema(
  {
    name: { type: String, required: true, unique: true, trim: true },
    baseUrl: { type: String, required: true, trim: true },
    sectionUrl: { type: String, required: true, trim: true },
    country: { type: String, required: true, trim: true, index: true },
    language: { type: String, required: true, trim: true, default: 'en' },
    status: {
      type: String,
      enum: ['active', 'paused', 'under_review'],
      default: 'active',
      required: true,
      index: true,
    },
    extractionMethod: {
      type: String,
      enum: ['custom', 'llm', 'json-ld'],
      required: true,
    },
    extractorKey: { type: String, required: false, trim: true },
    headlineSelector: { type: String, required: false, trim: true },
    articleSelector: { type: String, required: false, trim: true },
    imageUrlSelector: { type: String, required: false, trim: true },
    lastScrapedAt: { type: Date, required: false },
    lastSuccessAt: { type: Date, required: false },
    notes: { type: String, required: false, trim: true },
  },
  {
    timestamps: true,
    collection: 'sources',
  }
)

export default models.Source || model('Source', SourceSchema)


# File: models/Subscriber.js
// File: models/Subscriber.js (NEW FILE)
import mongoose from 'mongoose'
import bcrypt from 'bcrypt'

const { Schema, model, models } = mongoose
const SALT_WORK_FACTOR = 10

const SubscriberSchema = new Schema(
  {
    email: {
      type: String,
      required: true,
      unique: true,
      trim: true,
      lowercase: true,
      index: true,
    },
    password: {
      type: String,
      required: true,
      // select: false // uncomment this if you NEVER want the password hash returned in queries
    },
    firstName: {
      type: String,
      required: true,
      trim: true,
    },
    lastName: {
      type: String,
      required: false,
      trim: true,
    },
    countries: {
      type: [String],
      required: true,
      default: [],
    },
    role: {
      type: String,
      enum: ['user', 'admin'],
      default: 'user',
      required: true,
    },
    emailNotificationsEnabled: {
      type: Boolean,
      default: true,
    },
    pushNotificationsEnabled: {
      type: Boolean,
      default: true,
    },
    subscriptionTier: {
      type: String,
      enum: ['free', 'premium', 'enterprise'],
      default: 'free',
    },
    subscriptionExpiresAt: {
      type: Date,
      default: null,
    },
    tokensPaid: {
      type: Number,
      default: 0,
    },
    isLifetimeFree: {
      type: Boolean,
      default: false,
    },
    isActive: {
      type: Boolean,
      default: true,
      index: true,
    },
    lastLoginAt: {
      type: Date,
      default: null,
    },
  },
  {
    timestamps: true,
    collection: 'subscribers',
  }
)

// Mongoose pre-save hook to hash password before saving
SubscriberSchema.pre('save', function (next) {
  const user = this
  if (!user.isModified('password')) return next()

  bcrypt.genSalt(SALT_WORK_FACTOR, function (err, salt) {
    if (err) return next(err)
    bcrypt.hash(user.password, salt, function (err, hash) {
      if (err) return next(err)
      user.password = hash
      next()
    })
  })
})

export default models.Subscriber || model('Subscriber', SubscriberSchema)


# File: models/SynthesizedEvent.js
// models/SynthesizedEvent.js (version 2.2)
import mongoose from 'mongoose'

const { Schema, model, models } = mongoose

const SourceArticleSchema = new Schema(
  {
    headline: { type: String, required: true, trim: true },
    link: { type: String, required: true, trim: true },
    newspaper: { type: String, required: true, trim: true },
    imageUrl: { type: String, trim: true },
  },
  { _id: false }
)

const KeyIndividualSchema = new Schema(
  {
    name: { type: String, trim: true },
    role_in_event: { type: String, trim: true },
    company: { type: String, trim: true },
    email_suggestion: { type: String, trim: true },
  },
  { _id: false }
)

const SynthesizedEventSchema = new Schema(
  {
    event_key: {
      type: String,
      required: true,
      unique: true,
      trim: true,
      index: true,
    },
    synthesized_headline: { type: String, required: true, trim: true },
    synthesized_summary: { type: String, required: true, trim: true },
    ai_assessment_reason: { type: String, trim: true },
    country: { type: String, required: true, index: true },
    source_articles: { type: [SourceArticleSchema], required: true },
    highest_relevance_score: { type: Number, required: true, min: 0, max: 100 },
    key_individuals: { type: [KeyIndividualSchema], default: [] },
    event_date: { type: Date, default: Date.now },
    emailed: { type: Boolean, default: false },
    email_sent_at: { type: Date },
  },
  {
    timestamps: true,
    collection: 'synthesized_events',
  }
)

SynthesizedEventSchema.index({
  synthesized_headline: 'text',
  synthesized_summary: 'text',
})
SynthesizedEventSchema.index({ event_date: -1 })
SynthesizedEventSchema.index({ country: 1, createdAt: -1 })
SynthesizedEventSchema.index({ highest_relevance_score: -1 })

export default models.SynthesizedEvent ||
  model('SynthesizedEvent', SynthesizedEventSchema)


# File: package.json
{
  "name": "headlines-pipeline",
  "version": "3.0.0",
  "description": "A Node.js pipeline to scrape, analyze, and store news articles about wealth events.",
  "main": "app.js",
  "type": "module",
  "scripts": {
    "start": "node app.js",
    "chat": "node ./scripts/chat.js",
    "push": "node scripts/push.js",
    "check-sources": "node scripts/check-sources.js",
    "opportunities": "node scripts/generate-opportunities.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [
    "scraper",
    "axios",
    "cheerio",
    "nodejs",
    "openai",
    "mongoose"
  ],
  "author": "The Driver",
  "license": "ISC",
  "dependencies": {
    "@pinecone-database/pinecone": "^2.2.2",
    "@xenova/transformers": "^2.17.2",
    "axios": "^1.7.2",
    "bcrypt": "^5.1.1",
    "cheerio": "^1.0.0-rc.12",
    "dotenv": "^16.4.5",
    "https-proxy-agent": "^7.0.6",
    "mongoose": "^8.4.1",
    "nodemailer": "^6.9.13",
    "openai": "^4.47.3",
    "p-limit": "^5.0.0",
    "pino": "^9.1.0",
    "pino-pretty": "^11.1.0",
    "playwright": "^1.45.1",
    "pusher": "^5.2.0",
    "serpapi": "^2.1.0",
    "web-push": "^3.6.7"
  }
}


# File: run.sh
#!/bin/bash
cd /home/mark/Repos/projects/headlines
export $(grep -v '^#' .env | xargs)
 /home/mark/.nvm/versions/node/v22.18.0/bin/node app.js


# File: scrape.js
// scrape.js (version 2.2)
// A comprehensive health-check script for the sources.js configuration.
// It tests headline and content selectors for each source and saves debug files.
//
// Usage:
//   - Test all sources: `node scrape.js`
//   - Test a single source: `node scrape.js <site_key>`
//     (e.g., `node scrape.js kkr`)

import 'dotenv/config';
import fs from 'fs/promises';
import path from 'path';
import pLimit from 'p-limit';
import { COUNTRIES_CONFIG } from './src/config/sources.js';
import { scrapeSite, scrapeArticleContent } from './src/modules/scraper/index.js';
import { CONCURRENCY_LIMIT } from './src/config/index.js';
import { logger } from './src/utils/logger.js';

// --- Configuration ---
logger.level = 'info';
const DEBUG_DIR = path.join(process.cwd(), 'debug');
const MIN_HEADLINES = 1;
const MIN_CONTENT_CHARS = 150;

// --- Console Colors for Readability ---
const colors = {
    reset: "\x1b[0m",
    red: "\x1b[31m",
    green: "\x1b[32m",
    yellow: "\x1b[33m",
    cyan: "\x1b[36m",
    grey: "\x1b[90m",
};

const log = (msg) => console.log(msg);

/**
 * Runs a diagnostic health check on a single site configuration.
 * @param {object} site The site configuration, augmented with countryName.
 * @returns {Promise<{success: boolean, message: string}>} The result of the test.
 */
async function testSite(site) {
    const statusLine = [`${colors.cyan}[${site.countryName}] ${site.name.padEnd(35)}${colors.reset}`];
    
    // --- STAGE 1: HEADLINE SCRAPING ---
    const { articles, success: headlineSuccess } = await scrapeSite(site);
    
    if (!headlineSuccess || articles.length < MIN_HEADLINES) {
        const selector = site.useJsonLd ? 'JSON-LD' : site.selector;
        statusLine.push(`${colors.red}FAILED (Headlines: ${articles.length} found with selector '${selector}')${colors.reset}`);
        return { success: false, message: statusLine.join(' > ') };
    }
    statusLine.push(`${colors.green}HEADLINES OK (${articles.length})${colors.reset}`);

    // --- STAGE 2: ARTICLE CONTENT SCRAPING ---
    const firstArticle = articles[0];
    const articleWithContent = await scrapeArticleContent(firstArticle);
    const content = articleWithContent.articleContent?.contents?.join('') || '';

    if (content.length < MIN_CONTENT_CHARS) {
        const reason = articleWithContent.enrichment_error || `Content too short (${content.length} chars)`;
        statusLine.push(`${colors.red}FAILED (Content: ${reason})${colors.reset}`);
        return { success: false, message: statusLine.join(' > ') };
    }

    statusLine.push(`${colors.green}CONTENT OK (${content.length} chars)${colors.reset}`);
    return { success: true, message: statusLine.join(' > ') };
}

/**
 * Main function to orchestrate the health check.
 */
async function main() {
    await fs.rm(DEBUG_DIR, { recursive: true, force: true });
    log(`${colors.grey}Cleared debug directory.${colors.reset}`);

    const siteKey = process.argv[2];
    
    const allSites = COUNTRIES_CONFIG.flatMap(country => 
        country.sites.map(site => ({ ...site, countryName: country.countryName }))
    );
    let sitesToTest = allSites;

    const limit = pLimit(CONCURRENCY_LIMIT);

    if (siteKey) {
        const targetSite = allSites.find(site => site.key === siteKey);
        if (targetSite) {
            sitesToTest = [targetSite];
            log(`${colors.yellow}üöÄ Starting targeted health check for: ${siteKey}${colors.reset}`);
        } else {
            log(`${colors.red}Error: Site key "${siteKey}" not found in sources.js.${colors.reset}`);
            return;
        }
    } else {
        log(`${colors.yellow}üöÄ Starting full health check for all ${sitesToTest.length} sources...${colors.reset}`);
    }
    
    log('-------------------------------------------------------------------------------------------------------------');

    let successCount = 0;
    let failureCount = 0;

    const promises = sitesToTest.map(site => limit(async () => {
        const result = await testSite(site);
        log(result.message);
        if (result.success) {
            successCount++;
        } else {
            failureCount++;
        }
    }));

    await Promise.all(promises);

    log('-------------------------------------------------------------------------------------------------------------');
    const summaryColor = failureCount > 0 ? colors.red : colors.green;
    log(`${summaryColor}‚úÖ Health check finished. Passed: ${successCount}, Failed: ${failureCount}${colors.reset}`);
}

// --- Execute Script ---
main().catch(err => {
    console.error(`${colors.red}A critical, unhandled error occurred in the scrape script:${colors.reset}`, err);
    process.exit(1);
});

# File: src/config/PEFirms.json
[
  {
    "country": "Global PE",
    "flag_emoji": "üåê",
    "outlets": [
      {
        "name": "Apollo",
        "url": "https://www.apollo.com",
        "commentary": "Global alternative asset manager.",
        "labCheckPerformed": true,
        "analysis": {
          "urlDiscoveryMethod": "initial",
          "finalUrl": "https://www.apollo.com",
          "technology": "playwright + AI",
          "headlineSelectorMethod": "AI Structural Analysis",
          "headlineSelector": "a.cmp-insight-column-card__item__title--link, a.cmp-teaser__title-link, a.text-link-blck, a.cmp-navigation-featuredcontent__link",
          "headlinesFound": 21,
          "firstArticleUrl": "https://www.apollo.com/insights-news/insights/2025/06/mid-year-outlook-at-the-crossroads-of-stagflation-whats-next",
          "articleContentSelector": "main p",
          "sampleArticleLength": 8513,
          "aiInsights": {
            "pattern": "Headline links on this site share common traits: they usually use title-cased, descriptive text (often long) and live under /insights-news/ (either /insights/ or /pressreleases/) or the site‚Äôs feature/teaser areas. The CSS classes used for headlines include .cmp-insight-column-card__item__title--link (insight cards), .cmp-teaser__title-link (teasers/featured items), .text-link-blck (press releases/compact lists), and .cmp-navigation-featuredcontent__link (promoted featured content). Headlines often contain organization names, event names, or report titles and sometimes point to PDFs or IR pages.",
            "confidence": 0.9009523809523808
          },
          "notes": "Handled consent using persistent browser state."
        }
      },
      {
        "name": "KKR",
        "url": "https://www.kkr.com",
        "commentary": "Global investment company.",
        "labCheckPerformed": true,
        "analysis": {
          "urlDiscoveryMethod": "initial",
          "finalUrl": "https://www.kkr.com",
          "technology": "playwright + AI",
          "headlineSelectorMethod": "AI Structural Analysis",
          "headlineSelector": "a.article-teaser__link, a[href^=\"/insights/\"], a[href*=\"media.kkr.com/news-details\"]",
          "headlinesFound": 4,
          "firstArticleUrl": "https://www.kkr.com/insights/thoughts-from-the-road-asia-2025",
          "articleContentSelector": "article p",
          "sampleArticleLength": 2123,
          "aiInsights": {
            "pattern": "Headline links on this site appear in two primary patterns: 1) Insight/article teasers using the .article-teaser__link class with anchor text that begins with a content category (e.g., 'Macro Insights', 'Investment Insights'), followed by a concise headline and often a month/year and 'Learn More' suffix. These link URLs are under the /insights/ path with a readable slug. 2) Press releases use an external media subdomain (media.kkr.com) and a 'news-details' endpoint with a news_id GUID parameter. Navigation/utility links (about, invest, cookie policy, IR) use different selectors (generic a, cmp-button, .cmp-link) and shorter, non-article text.",
            "confidence": 0.9374999999999999
          },
          "notes": "Handled consent using persistent browser state."
        }
      },
      {
        "name": "PAI Partners",
        "url": "https://www.paipartners.com",
        "commentary": "European private equity firm.",
        "labCheckPerformed": true,
        "analysis": {
          "urlDiscoveryMethod": "initial",
          "finalUrl": "https://www.paipartners.com",
          "technology": "playwright + AI",
          "headlineSelectorMethod": "AI Structural Analysis",
          "headlineSelector": "a[href*=\"/mediaitem/\"]",
          "headlinesFound": 5,
          "firstArticleUrl": "https://www.paipartners.com/mediaitem/2025-annual-general-meetings/",
          "articleContentSelector": null,
          "sampleArticleLength": 0,
          "aiInsights": {
            "pattern": "Headline links share these characteristics: (1) URLs contain the segment '/mediaitem/' (site's press/news item pattern). (2) Anchor text is natural-language, headline-style (short-to-medium length, often starting with the organisation name or an active verb and containing proper nouns or numeric details). (3) The CSS selector for headline anchors is a plain 'a' within the news listing; navigation CTAs use distinct classes (e.g., 'a.btn') and case studies use different URL paths such as '/case-study/'.",
            "confidence": 0.95
          },
          "notes": "Handled consent using persistent browser state."
        }
      },
      {
        "name": "EQT Group",
        "url": "https://www.eqtgroup.com",
        "commentary": "Global investment organization.",
        "labCheckPerformed": true,
        "analysis": {
          "urlDiscoveryMethod": "initial",
          "finalUrl": "https://www.eqtgroup.com",
          "technology": "playwright + AI",
          "headlineSelectorMethod": "AI Structural Analysis",
          "headlineSelector": "Prefer URL-prefix + presentation-class combination to capture headlines while avoiding nav: \"a[href^='/thinq/'], a[href^='/news/']\". Optionally restrict to known article classes: \"a.p-6, a.bg-transparent, a.md\\:p-6, a[href^='/thinq/'], a[href^='/news/']\"",
          "headlinesFound": 18,
          "firstArticleUrl": "https://www.eqtgroup.com/thinq/private-markets/ipo-report-2025",
          "articleContentSelector": "main p",
          "sampleArticleLength": 2123,
          "aiInsights": {
            "pattern": "Headline links cluster under two main URL patterns: /thinq/ (editorial/insights, case-studies, education, opinion) and /news/ (press releases). Headlines tend to have: longer, descriptive anchor text (often >4 words), question or quoted formats, numeric values or company names, and appear with presentation classes such as a.p-6, a.bg-transparent, or a.md:p-6. Navigation and utility links are shorter (single words or short phrases like 'Private Capital', 'About') and often use a.w-full or a.bg-white selectors.",
            "confidence": 0.8833333333333332
          },
          "notes": "Handled consent using persistent browser state."
        }
      },
      {
        "name": "Egeria",
        "url": "https://egeriagroup.com",
        "commentary": "Dutch private equity firm."
      },
      {
        "name": "Rivean Capital (Gilde)",
        "url": "https://www.riveancapital.com",
        "commentary": "Formerly Gilde Equity Management (GEM)."
      },
      {
        "name": "IK Partners (News & Insights)",
        "url": "https://www.ikpartners.com",
        "commentary": "Main press releases and portfolio updates."
      },
      {
        "name": "IK Partners (Portfolio News)",
        "url": "https://www.ikpartners.com/portfolio-company-news",
        "commentary": "Specific news archive for portfolio companies."
      },
      {
        "name": "Triton Partners",
        "url": "https://www.triton-partners.com",
        "commentary": "European private equity investment firm."
      },
      {
        "name": "Bridgepoint (News & Insights)",
        "url": "https://www.bridgepoint.eu",
        "commentary": "Corporate news and insights."
      },
      {
        "name": "Bridgepoint (Regulatory News)",
        "url": "https://www.bridgepoint.eu/shareholder-centre/regulatory-news",
        "commentary": "Live LSE regulatory news feed."
      },
      {
        "name": "Hg Capital",
        "url": "https://hgcapital.com",
        "commentary": "Software and services investor.",
        "labCheckPerformed": true,
        "analysis": {
          "urlDiscoveryMethod": "initial",
          "finalUrl": "https://hgcapital.com",
          "technology": "playwright + AI",
          "headlineSelectorMethod": "AI Structural Analysis",
          "headlineSelector": "article h2 a, article h3 a, .card__link, .post-card a, a[href*=\"/insights/\"], a[href*=\"/news/\"], a[href*=\"/case-studies/\"]",
          "headlinesFound": 1,
          "firstArticleUrl": "https://hgcapital.com/portfolio/case-studies/visma",
          "articleContentSelector": "main p",
          "sampleArticleLength": 3547,
          "aiInsights": {
            "pattern": "In this sample, genuine content/headline links are characterized by: (1) non-generic, descriptive anchor text (not repeated section labels like 'News & Insights'); (2) URLs that contain content paths (e.g., /portfolio/case-studies/, /insights/, /news/ or similar slugs) rather than top-level section or utility domains; and (3) selectors that are not the generic 'a' used for utilities (cookie consent) or site-wide buttons. Note the provided CSS selector (a.index-style__ButtonMain-sc-207d00b9-2) appears used for header/CTA buttons and repeated navigation, so it is less reliable alone for distinguishing article headlines.",
            "confidence": 0.9
          },
          "notes": "Handled consent using persistent browser state."
        }
      },
      {
        "name": "3i Group (Press Releases)",
        "url": "https://www.3i.com/media/press-releases/",
        "commentary": "Main corporate press releases."
      },
      {
        "name": "3i Group (Regulatory News)",
        "url": "https://www.3i.com/investors/regulatory-news/",
        "commentary": "Investor relations and regulatory news."
      },
      {
        "name": "CVC Capital Partners",
        "url": "https://www.cvc.com",
        "commentary": "Global private equity and credit."
      },
      {
        "name": "Ardian (News & Insights)",
        "url": "https://www.ardian.com/news-insights",
        "commentary": "Thought leadership and news articles.",
        "labCheckPerformed": true,
        "analysis": {
          "urlDiscoveryMethod": "initial",
          "finalUrl": "https://www.ardian.com/news-insights",
          "technology": "playwright + AI",
          "headlineSelectorMethod": "AI Structural Analysis",
          "headlineSelector": "a[href^=\"/news-insights/\"]:not(.tag):not(.btn-outline), a[href*=\"-report\"], a[href*=\"-years\"], article h2 a, article h3 a",
          "headlinesFound": 4,
          "firstArticleUrl": "https://www.ardian.com/news-insights/responsible-finance?category=202",
          "articleContentSelector": "div[class*=\"content\"] p",
          "sampleArticleLength": 1528,
          "aiInsights": {
            "pattern": "True news/headline links in this sample mostly target the '/news-insights/' path or external microsites dedicated to reports/campaigns. Headline-like anchors tend to be simple 'a' elements or prominent CTAs (e.g., 'a.btn-outline'). Tag/filter links use a distinct class ('a.tag') and cookie/privacy/vendor links use cookie dialog-specific selectors‚Äîthese are not headlines. Headlines and content CTAs use descriptive, content-focused text (topic names, report titles or campaign domains) rather than generic utility/legal phrasing.",
            "confidence": 0.65
          },
          "notes": "Handled consent using persistent browser state."
        }
      },
      {
        "name": "Ardian (Press Releases)",
        "url": "https://www.ardian.com/press-releases",
        "commentary": "Official press releases.",
        "labCheckPerformed": true,
        "analysis": {
          "urlDiscoveryMethod": "initial",
          "finalUrl": "https://www.ardian.com/press-releases",
          "technology": "playwright + AI",
          "headlineSelectorMethod": "AI Structural Analysis",
          "headlineSelector": "a[href^='/news-insights/press-releases/']",
          "headlinesFound": 7,
          "firstArticleUrl": "https://www.ardian.com/news-insights/press-releases/diot-siaci-announces-new-ownership-structure-ardian-burrus-group-and",
          "articleContentSelector": "div[class*=\"content\"] p",
          "sampleArticleLength": 7719,
          "aiInsights": {
            "pattern": "Headlines are sentence-style, descriptive strings (often starting with firm names or action verbs like 'announces', 'enters', 'launches', 'acquire', 'finalizes') and typically include company names, transaction or product details, and locations/numbers. Their URLs consistently live under the /news-insights/press-releases/ path. The selector in the provided data is a generic 'a', implying these headline links are simple anchor tags within a news/press listing.",
            "confidence": 0.9585714285714287
          },
          "notes": "Handled consent using persistent browser state."
        }
      }
    ]
  }
]

# File: src/config/dynamicConfig.js
// src/config/dynamicConfig.js (version 1.0)
import Source from '../../models/Source.js'
import { logger } from '../utils/logger.js'

export const configStore = {
  newspaperToCountryMap: new Map(),
  countryNameToFlagMap: new Map(),
}

const COUNTRY_FLAG_MAP = {
  Denmark: 'üá©üá∞',
  Norway: 'üá≥üá¥',
  Sweden: 'üá∏üá™',
  Finland: 'üá´üáÆ',
  Netherlands: 'üá≥üá±',
  'Global PE': 'üåê',
  'M&A Aggregators': 'ü§ù',
}

let isInitialized = false

/**
 * Connects to the database, fetches all sources, and builds the global
 * configuration maps needed by various pipeline stages.
 */
export async function initializeConfig() {
  if (isInitialized) {
    return
  }
  try {
    logger.info('Initializing dynamic configuration from database...')
    const sources = await Source.find().lean()

    if (sources.length === 0) {
      logger.warn(
        'No sources found in the database. Configuration maps will be empty. Did you run the migration script?'
      )
    }

    for (const source of sources) {
      configStore.newspaperToCountryMap.set(source.name, source.country)
      if (
        !configStore.countryNameToFlagMap.has(source.country) &&
        COUNTRY_FLAG_MAP[source.country]
      ) {
        configStore.countryNameToFlagMap.set(
          source.country,
          COUNTRY_FLAG_MAP[source.country]
        )
      }
    }

    isInitialized = true
    logger.info(
      `Dynamic configuration initialized successfully. Loaded ${sources.length} sources.`
    )
  } catch (error) {
    logger.fatal({ err: error }, 'Failed to initialize dynamic configuration from DB.')
    throw error // Propagate error to halt the pipeline
  }
}


# File: src/config/index.js
// src/config/index.js (version 2.3 - Pinecone Integration)
import dotenv from 'dotenv';

dotenv.config();

/**
 * Helper function to safely read and clean string environment variables.
 * It trims whitespace and removes surrounding quotes.
 * @param {string} key The environment variable key.
 * @param {string} defaultValue The default value if the key is not found.
 * @returns {string} The cleaned environment variable value.
 */
function getCleanStringEnv(key, defaultValue = '') {
    let value = process.env[key] || defaultValue;
    value = value.trim();
    if ((value.startsWith('"') && value.endsWith('"')) || (value.startsWith("'") && value.endsWith("'"))) {
        return value.slice(1, -1);
    }
    return value;
}


// --- Core App Behavior ---
export const NODE_ENV = getCleanStringEnv('NODE_ENV', 'development');
export const IS_PRODUCTION = NODE_ENV === 'production';
export const LOG_LEVEL = getCleanStringEnv('LOG_LEVEL', 'info');
export const CONCURRENCY_LIMIT = parseInt(process.env.CONCURRENCY_LIMIT, 10) || 3;
export const FORCE_EMAIL_SEND_DEV = process.env.FORCE_EMAIL_SEND_DEV === 'true';
export const IS_REFRESH_MODE = process.env.REFRESH_MODE === 'true';

// --- Database ---
export const MONGO_URI = getCleanStringEnv('MONGO_URI');

// --- NEW: Pinecone Configuration ---
export const PINECONE_API_KEY = getCleanStringEnv('PINECONE_API_KEY');
export const PINECONE_INDEX_NAME = getCleanStringEnv('PINECONE_INDEX_NAME', 'headlines');

// --- LLM Configuration ---
export const OPENAI_API_KEY = getCleanStringEnv('OPENAI_API_KEY');
export const LLM_MODEL = getCleanStringEnv('LLM_MODEL', 'gpt-5-mini');
export const LLM_MODEL_TRIAGE = LLM_MODEL;
export const LLM_MODEL_HEADLINES = LLM_MODEL;
export const LLM_MODEL_ARTICLES = LLM_MODEL;

// --- Scraper Configuration ---
export const SCRAPER_PROXY_URL = getCleanStringEnv('SCRAPER_PROXY_URL') || null;

// --- NEW: Third-Party Service APIs ---
export const SERPAPI_API_KEY = getCleanStringEnv('SERPAPI_API_KEY');

// --- Thresholds ---
export const HEADLINES_RELEVANCE_THRESHOLD = 20;
export const ARTICLES_RELEVANCE_THRESHOLD = 50;
export const MIN_ARTICLE_CHARS = 150;
export const MAX_ARTICLE_CHARS = 100000;
export const MIN_HEADLINE_CHARS = 5;
export const MAX_HEADLINE_CHARS = 500;
export const AI_BATCH_SIZE = 6;

// --- Email Configuration ---
export const SMTP_CONFIG = {
    host: getCleanStringEnv('SMTP_HOST'),
    port: parseInt(process.env.SMTP_PORT, 10) || 587,
    secure: process.env.SMTP_SECURE === 'true',
    auth: {
        user: getCleanStringEnv('SMTP_USER'),
        pass: getCleanStringEnv('SMTP_PASS'),
    },
    fromAddress: getCleanStringEnv('SMTP_FROM_ADDRESS') || getCleanStringEnv('SMTP_USER'),
    fromName: getCleanStringEnv('SMTP_FROM_NAME', 'Headlines Bot'),
};

// --- Email Template Config ---
export const EMAIL_CONFIG = {
  templateName: 'wealthEvents',
  subject: 'New Nordic Banking Opportunities Detected',
  language: 'en',
  brandName: 'Your Wealth Watch',
  companyAddress: 'Wealth Watch Inc., Paris, France',
  unsubscribeUrl: '#',
};

export const SUPERVISOR_EMAIL_CONFIG = {
  templateName: 'supervisorReport',
  subject: '‚öôÔ∏è Hourly Headlines Processing Run Summary',
  language: 'en',
  brandName: 'Headlines Processing Bot',
};

# File: src/database.js
// src/database.js (version 1.0)
import mongoose from 'mongoose';
import { MONGO_URI } from './config/index.js';
import { logger } from './utils/logger.js';

export async function connectDatabase() {
    if (!MONGO_URI) {
        logger.fatal('MONGO_URI is not defined in environment variables. Exiting.');
        process.exit(1);
    }

    // If we are already connected or connecting, don't try again.
    if (mongoose.connection.readyState === 1 || mongoose.connection.readyState === 2) {
        logger.info('MongoDB connection is already active.');
        return true;
    }

    try {
        logger.info('Attempting to connect to MongoDB...');
        await mongoose.connect(MONGO_URI, {
            serverSelectionTimeoutMS: 5000,
        });
        
        if (mongoose.connection.readyState === 1) {
            logger.info('‚úÖ MongoDB connection successful.');
            return true;
        } else {
            logger.fatal('MongoDB connection attempt finished but readyState is not "connected".');
            return false;
        }

    } catch (error) {
        logger.fatal({ err: error }, '‚ùå CRITICAL: Failed to establish MongoDB connection.');
        // In case of an error, Mongoose might handle the process exit.
        // We ensure it exits if it doesn't.
        process.exit(1);
    }
}

export async function disconnectDatabase() {
    try {
        await mongoose.disconnect();
        logger.info('MongoDB connection closed.');
    } catch (error) {
        logger.error({ err: error }, 'Error disconnecting from MongoDB.');
    }
}

# File: src/modules/ai/client.js
// src/modules/ai/client.js (version 2.0)
import OpenAI from 'openai';
import { OPENAI_API_KEY } from '../../config/index.js';
import { logger } from '../../utils/logger.js';

if (!OPENAI_API_KEY) {
    throw new Error('OPENAI_API_KEY is not defined in the environment variables.');
}

logger.info('ü§ñ Initializing OpenAI AI client...');

// The timeout and maxRetries are configured for robustness, suitable for production use.
const client = new OpenAI({
    apiKey: OPENAI_API_KEY,
    // BaseURL is omitted to use the official OpenAI endpoint by default.
    timeout: 90 * 1000, // 90 seconds
    maxRetries: 3,
});

export default client;

# File: src/modules/ai/eventProcessing.js
// src/modules/ai/eventProcessing.js (version 2.8 - Improved Query Planning)
import client from './client.js';
import { LLM_MODEL_ARTICLES, LLM_MODEL } from '../../config/index.js';
import { logger } from '../../utils/logger.js';
import { instructionCluster } from '../assessments/instructionCluster.js';
import { instructionSynthesize } from '../assessments/instructionSynthesize.js';
import { safeExecute } from '../../utils/helpers.js';

const ENTITY_MODEL = LLM_MODEL;

// --- NEW: Domain-Constrained Query Planner Prompt ---
const QUERY_PLANNER_PROMPT = `You are a Research Planning Agent for a wealth management firm. Your task is to analyze the provided "Article Text" and determine the most critical entities to look up on Wikipedia for factual verification and enrichment.

**CRITICAL Instructions:**
1.  Your focus is exclusively on **wealth management intelligence**; people and investment entities who have more than $50mm to invest.
2.  You MUST ONLY extract specific, high-value proper nouns relevant to this domain:
    - **Individuals:** Founders, CEOs, UHNW investors, UHNW family members.
    - **Companies & Firms:** Private companies, PE/VC firms, investment vehicles, family offices.
    - **Transactions:** IPOs, M&A deals; events providing liquidity.
3.  You are FORBIDDEN from extracting generic locations (e.g., "Copenhagen", "Denmark") or concepts (e.g., "Pension", "Software").
    The only extraction should be clarification in relation to wealth (entities, named individuals)
4.  Return ONLY the core name of the entity which you would expect a Wikipedia page to exist for (e.g., "FSN Capital", not "FSN Capital (private equity firm)").

Respond ONLY with a valid JSON object:
{
  "reasoning": "A brief explanation of your choice of entities based on wealth management relevance.",
  "entities": ["Precise Search Query 1", "Precise Search Query 2"]
}`;

/**
 * Uses a domain-constrained AI agent to decide which entities to search for on Wikipedia.
 * @param {string} text - The text to analyze.
 * @returns {Promise<string[]>} An array of optimized, relevant search queries (entities).
 */
export async function extractEntities(text) {
    if (!text) return [];
    try {
        const response = await client.chat.completions.create({
            model: ENTITY_MODEL,
            messages: [{ role: 'system', content: QUERY_PLANNER_PROMPT }, { role: 'user', content: `Article Text:\n${text}` }],
            response_format: { type: 'json_object' },
        });
        const { reasoning, entities } = JSON.parse(response.choices[0].message.content);
        logger.info(`[Query Planner Agent] Reasoning: ${reasoning}`);

        if (!entities || !Array.isArray(entities)) return [];

        const sanitizedEntities = entities.map(entity => 
            entity.replace(/\s*\(.*\)\s*/g, '').trim()
        ).filter(Boolean); // Filter out any empty strings
        
        return sanitizedEntities;

    } catch (error) {
        logger.warn({ err: error }, "Wikipedia query planning (entity extraction) failed.");
        return [];
    }
}

// ... (The rest of the file - generateJsonResponse, clusterArticlesIntoEvents, synthesizeEvent, etc. - is unchanged) ...
async function generateJsonResponse(model, instructions, userContent, temperature = 0.1) {
    const messages = [ { role: 'system', content: JSON.stringify(instructions) }, { role: 'user', content: userContent } ];
    const result = await safeExecute(() => client.chat.completions.create({ model, messages, response_format: { type: "json_object" } }));
    if (!result) return { error: 'API call failed' };
    try { return JSON.parse(result.choices[0].message.content); }
    catch (parseError) { logger.error({ err: parseError, content: result.choices[0].message.content }, "JSON Parsing Error"); return { error: "JSON Parsing Error" }; }
}
export async function clusterArticlesIntoEvents(articles) {
    logger.info(`Clustering ${articles.length} articles into unique events...`);
    const articlePayload = articles.map(a => ({ id: a._id.toString(), headline: a.headline, source: a.newspaper, summary: (a.topic || a.assessment_article || '').substring(0, 400) }));
    const userContent = JSON.stringify(articlePayload);
    const response = await generateJsonResponse(LLM_MODEL_ARTICLES, instructionCluster, userContent);
    if (response.error || !response.events) { logger.error('Failed to cluster articles.', { response }); return []; }
    return response.events;
}
export async function synthesizeEvent(articlesInCluster, historicalContext, wikipediaContext) {
    const todayPayload = articlesInCluster.map(a => ({ headline: a.headline, source: a.newspaper, full_text: (a.articleContent?.contents || []).join('\n') }));
    const historyPayload = historicalContext.map(h => ({ headline: h.headline, source: h.newspaper, published: h.createdAt, summary: h.assessment_article || '' }));
    const userContent = JSON.stringify({
        '[ TODAY\'S NEWS ]': todayPayload,
        '[ HISTORICAL CONTEXT (Internal Database) ]': historyPayload,
        '[ PUBLIC WIKIPEDIA CONTEXT ]': wikipediaContext || 'Not available.',
    });
    const response = await generateJsonResponse(LLM_MODEL_ARTICLES, instructionSynthesize, userContent, 0.2);
    if (response.error) { logger.error('Failed to synthesize event.', { response }); return { error: 'Synthesis failed' }; }
    return response;
}
export async function synthesizeFromHeadline(article) {
    logger.warn({ headline: article.headline }, `Salvaging high-signal headline with failed enrichment...`);
    const todayPayload = [{ headline: article.headline, source: article.newspaper, full_text: "NOTE: Full article text could not be retrieved. Synthesize based on the headline's explicit claims and your general knowledge." }];
    const userContent = JSON.stringify({ '[ TODAY\'S NEWS ]': todayPayload, '[ HISTORICAL CONTEXT ]': [], '[ PUBLIC WIKIPEDIA CONTEXT ]': 'Not available.' });
    const response = await generateJsonResponse(LLM_MODEL_ARTICLES, instructionSynthesize, userContent, 0.2);
    if (response.error) { logger.error('Failed to salvage headline.', { response }); return null; }
    return response;
}

# File: src/modules/ai/index.js
// src/modules/ai/index.js (version 2.8)
import pLimit from 'p-limit'
import client from './client.js'
import {
  LLM_MODEL_TRIAGE,
  LLM_MODEL_ARTICLES,
  AI_BATCH_SIZE,
  CONCURRENCY_LIMIT,
  HEADLINES_RELEVANCE_THRESHOLD,
  LLM_MODEL,
} from '../../config/index.js'
import { logger } from '../../utils/logger.js'
import { instructionHeadlines } from '../assessments/instructionHeadlines.js'
import {
  shotsInput as shotsInputHeadlines,
  shotsOutput as shotsOutputHeadlines,
} from '../assessments/shotsHeadlines.js'
import { instructionArticle } from '../assessments/instructionArticle.js'
import {
  shotsInput as shotsInputArticle,
  shotsOutput as shotsOutputArticle,
} from '../assessments/shotsArticle.js'
import { instructionContacts } from '../assessments/instructionContacts.js'
import { instructionEnrichContact } from '../assessments/instructionEnrichContact.js'
import { instructionOpportunities } from '../assessments/instructionOpportunities.js'
import { safeExecute, truncateString } from '../../utils/helpers.js'
import { performGoogleSearch } from '../../utils/serpapi.js'

const limit = pLimit(CONCURRENCY_LIMIT)
let isApiKeyInvalid = false

export async function performAiSanityCheck() {
  try {
    logger.info('üî¨ Performing AI service sanity check (OpenAI)...')
    const response = await client.chat.completions.create(
      {
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'user',
            content: 'What is in one word the name of the capital of France',
          },
        ],
        temperature: 0,
      },
      { timeout: 20 * 1000 }
    )
    const answer = response.choices[0].message.content.trim().toLowerCase()
    if (answer.includes('paris')) {
      logger.info('‚úÖ AI service sanity check passed.')
      return true
    } else {
      logger.fatal(`OpenAI sanity check failed. Expected "Paris", got: "${answer}".`)
      return false
    }
  } catch (error) {
    if (error.status === 401) {
      logger.fatal(`OpenAI sanity check failed due to INVALID API KEY (401).`)
    } else {
      logger.fatal(
        { err: error },
        'OpenAI sanity check failed with an unexpected API error.'
      )
    }
    isApiKeyInvalid = true
    return false
  }
}
export async function checkModelPermissions(requiredModels) {
  logger.info('üî¨ Verifying permissions for configured OpenAI models...')
  try {
    const response = await client.models.list()
    const availableModels = new Set(response.data.map((model) => model.id))
    for (const model of requiredModels) {
      if (!availableModels.has(model)) {
        logger.fatal(`Model validation failed. Model "${model}" is not available.`)
        return false
      }
    }
    logger.info('‚úÖ All configured models are available.')
    return true
  } catch (error) {
    logger.fatal({ err: error }, 'Failed to retrieve model list from OpenAI API.')
    isApiKeyInvalid = true
    return false
  }
}

async function generateAssessment(
  model,
  instructions,
  userContent,
  fewShotInputs = [],
  fewShotOutputs = []
) {
  if (isApiKeyInvalid) {
    return { error: 'API Key is invalid. Halting further AI assessments.' }
  }
  const messages = [{ role: 'system', content: JSON.stringify(instructions) }]

  fewShotInputs.forEach((input, i) => {
    const shotContent = typeof input === 'string' ? input : JSON.stringify(input)
    if (shotContent) {
      messages.push({ role: 'user', content: shotContent })
      messages.push({ role: 'assistant', content: fewShotOutputs[i] })
    }
  })

  messages.push({ role: 'user', content: userContent })

  const result = await safeExecute(() =>
    client.chat.completions.create({
      model,
      messages,
      response_format: { type: 'json_object' },
    })
  )

  if (!result) return { error: 'API call failed' }

  try {
    return JSON.parse(result.choices[0].message.content)
  } catch (parseError) {
    logger.error(`JSON Parse Error: ${parseError.message}`)
    return { error: 'JSON Parsing Error' }
  }
}

export async function assessHeadlinesInBatches(articles) {
  const batches = []
  for (let i = 0; i < articles.length; i += AI_BATCH_SIZE) {
    batches.push(articles.slice(i, i + AI_BATCH_SIZE))
  }
  logger.info(`Assessing ${articles.length} headlines in ${batches.length} batches...`)
  const allAssessedPromises = []
  let completedBatches = 0
  for (const batch of batches) {
    allAssessedPromises.push(
      limit(async () => {
        const headlinesText = batch.map((a) => a.headline).join('\n- ')
        const response = await generateAssessment(
          LLM_MODEL_TRIAGE,
          instructionHeadlines,
          headlinesText,
          shotsInputHeadlines,
          shotsOutputHeadlines
        )
        completedBatches++
        logger.info(
          `\n--- [ BATCH ${completedBatches}/${batches.length} HEADLINE ANALYSIS ] ---`
        )
        if (response && response.assessment && Array.isArray(response.assessment)) {
          batch.forEach((article, i) => {
            const assessment = response.assessment[i]
            if (assessment && typeof assessment.relevance_headline === 'number') {
              const score = assessment.relevance_headline
              const comment = assessment.assessment_headline || 'No comment.'
              const emoji = score >= HEADLINES_RELEVANCE_THRESHOLD ? '‚úÖ' : '‚ùå'
              logger.info(
                `${emoji} [${String(score).padStart(3)}] "${truncateString(article.headline, 60)}" (${article.source}) | ${truncateString(comment, 45)}`
              )
            } else {
              logger.warn(
                `- Malformed assessment for: "${truncateString(article.headline, 70)}" (${article.source})`
              )
            }
          })
        } else {
          logger.error(
            `‚ùå Headline assessment failed for batch ${completedBatches}/${batches.length}. Reason: ${response.error || 'Malformed response'}`
          )
        }
        if (
          response.error ||
          !response.assessment ||
          !Array.isArray(response.assessment) ||
          response.assessment.length !== batch.length
        ) {
          return batch.map((article) => ({
            ...article,
            relevance_headline: 0,
            assessment_headline: response.error || 'AI assessment failed.',
          }))
        }
        return batch.map((article, i) => ({ ...article, ...response.assessment[i] }))
      })
    )
  }
  const assessedBatches = await Promise.all(allAssessedPromises)
  logger.info('Finished assessing all headline batches.')
  return assessedBatches.flat()
}
export async function assessArticleContent(article) {
  const articleText = `HEADLINE: ${article.headline}\n\nBODY:\n${article.articleContent.contents.join('\n')}`
  const response = await generateAssessment(
    LLM_MODEL_ARTICLES,
    instructionArticle,
    articleText,
    shotsInputArticle,
    shotsOutputArticle
  )
  if (response.error) {
    logger.error(`Article assessment failed for ${article.link}.`)
    return { ...article, error: `AI Error: ${response.error}` }
  }
  return { ...article, ...response, error: null }
}

export async function extractKeyContacts(article) {
  const articleText = `HEADLINE: ${article.headline_en || article.headline}\n\nSUMMARY: ${article.topic}\n\nFULL TEXT SNIPPET:\n${truncateString((article.articleContent?.contents || []).join('\n'), 1500)}`

  // --- NEW: Add a specific few-shot example to guide the AI ---
  const fewShotInputs = [
    `HEADLINE: Another great year for Aksel Lund Svindal's finances\n\nSUMMARY: Profile on the financial success of former athlete Aksel Lund Svindal.`,
  ]
  const fewShotOutputs = [
    JSON.stringify({
      key_individuals: [
        {
          name: 'Aksel Lund Svindal',
          role_in_event: 'Subject of Wealth Profile',
          company: 'A Management',
          email_suggestion: 'aksel@svindal.no',
        },
      ],
    }),
  ]
  // --- END NEW ---

  const response = await generateAssessment(
    LLM_MODEL,
    instructionContacts,
    articleText,
    fewShotInputs,
    fewShotOutputs
  )

  if (response.error || !response.key_individuals) {
    logger.warn(`Contact extraction failed for ${article.link}.`, {
      error: response.error,
    })
    return { key_individuals: [] }
  }

  logger.info(
    `[Contact Agent] Initial extraction found ${response.key_individuals.length} potential contact(s) for "${truncateString(article.headline, 50)}"`
  )
  return response
}

export async function enrichContact(contact, article) {
  const researchQuery = `${contact.name} ${contact.company || article.newspaper}`
  const searchResult = await performGoogleSearch(researchQuery)
  if (!searchResult.success) {
    return [contact]
  }
  const context = `Initial Contact Profile:\n${JSON.stringify(contact)}\n\nSource Article Headline: ${article.headline}\n\nGoogle Search Snippets:\n${searchResult.snippets}`
  const response = await generateAssessment(LLM_MODEL, instructionEnrichContact, context)
  if (
    response.error ||
    !response.enriched_contacts ||
    response.enriched_contacts.length === 0
  ) {
    logger.warn(
      `[Enrichment Agent] Failed to enrich contact "${contact.name}". Returning original.`
    )
    return [contact]
  }
  logger.info(
    `[Enrichment Agent] Successfully enriched contact: "${contact.name}" -> "${response.enriched_contacts.map((c) => c.name).join(', ')}"`
  )
  return response.enriched_contacts
}
export async function generateOpportunitiesFromArticle(article) {
  const inputText = `
        Headline: ${article.headline_en || article.headline}
        Source: ${article.newspaper}
        Link: ${article.link}
        AI Summary: ${article.topic || article.assessment_article}
        Enriched Key Individuals: ${JSON.stringify(article.key_individuals, null, 2)}
        Full Text Snippet: ${truncateString((article.articleContent?.contents || []).join(' '), 1500)}
    `
  const response = await generateAssessment(
    LLM_MODEL,
    instructionOpportunities,
    inputText
  )
  if (response.error || !response.opportunities) {
    logger.warn(`Opportunity generation failed for ${article.link}.`, {
      error: response.error,
    })
    return []
  }
  logger.info(
    `[Opportunity Agent] Generated ${response.opportunities.length} opportunity/ies from "${truncateString(article.headline, 50)}"`
  )
  return response.opportunities
}


# File: src/modules/ai/rag.js
// src/modules/ai/rag.js (version 2.1 - Add RAG Result Logging)
import { Pinecone } from '@pinecone-database/pinecone';
import { logger } from '../../utils/logger.js';
import { generateEmbedding } from '../../utils/vectorUtils.js';
import { PINECONE_API_KEY, PINECONE_INDEX_NAME } from '../../config/index.js';

const SIMILARITY_THRESHOLD = 0.65;
const MAX_CONTEXT_ARTICLES = 3;

if (!PINECONE_API_KEY) {
    throw new Error('Pinecone API Key must be defined in .env file for RAG module.');
}
const pc = new Pinecone({ apiKey: PINECONE_API_KEY });
const pineconeIndex = pc.index(PINECONE_INDEX_NAME);

/**
 * Finds historical articles similar to a given set of new articles by querying Pinecone.
 * @param {Array<Object>} articlesInCluster - The new articles forming an event.
 * @returns {Promise<Array<Object>>} A promise that resolves to an array of relevant historical articles.
 */
export async function findSimilarArticles(articlesInCluster) {
    logger.info('RAG: Searching for historical context in Pinecone...');
    if (!articlesInCluster || articlesInCluster.length === 0) return [];

    const queryText = articlesInCluster.map(a => a.headline).join('\n');
    const queryEmbedding = await generateEmbedding(queryText);

    try {
        const queryResponse = await pineconeIndex.query({
            topK: MAX_CONTEXT_ARTICLES,
            vector: queryEmbedding,
            includeMetadata: true,
        });

        const relevantMatches = queryResponse.matches.filter(match => match.score >= SIMILARITY_THRESHOLD);

        if (relevantMatches.length > 0) {
            // --- NEW: Log the headlines and scores of retrieved articles ---
            const retrievedArticlesForLogging = relevantMatches.map(match => 
                `  - [Score: ${match.score.toFixed(3)}] "${match.metadata.headline}"`
            ).join('\n');
            logger.info(`RAG: Found ${relevantMatches.length} relevant historical articles:\n${retrievedArticlesForLogging}`);
            // --- END NEW LOGGING ---
            
            return relevantMatches.map(match => ({
                headline: match.metadata.headline,
                newspaper: match.metadata.newspaper,
                assessment_article: match.metadata.summary
            }));
        } else {
            logger.info('RAG: Found no relevant historical articles in Pinecone.');
            return [];
        }
    } catch (error) {
        logger.error({ err: error }, "RAG: Pinecone query failed.");
        return [];
    }
}

# File: src/modules/assessments/instructionArticle.js
// File: src/modules/assessments/instructionArticle.js
// src/modules/assessments/instructionArticle.js (version 2.6)
export const instructionArticle = {
  whoYouAre:
    'You are a private wealth relevance analyst specialized in scouring newspapers and other media.',

  whatYouDo: `You analyze full-text articles. Your primary goal is to identify if they report a direct, substantial private wealth event (over $30 million) benefiting private individuals, families, their holding companies, or family offices/foundations. 
    Additionally, you flag articles discussing significant business activities by known Rich List individuals.`,

  writingStyle:
    'Use concise, factual English. Avoid speculation. Maintain a formal tone.',

  outputFormatDescription:
    'Respond only with a valid JSON object using this structure: { "headline_en": "English translation of the headline if needed", "country": "United States", "topic": "Short summary of the event", "relevance_article": 95, "assessment_article": "Rationale for you giving the score", "amount": 500, "key_individuals": [], "background": "Contextual info with a focus on the recipient of the wealth" }',

  guidelines: `
Focus on:
1.  **PRIVATE EQUITY (PE) & VENTURE CAPITAL (VC) TRANSACTIONS**: Any article announcing an acquisition, investment, partnership, sale, or exit by a named PE or VC firm (e.g., "Egeria acquires Company X", "KKR invests in Startup Y"). This is your highest priority.

2.  **Direct Wealth Events**: Articles involving direct wealth transfers (company sales, IPOs, M&A, inheritances, significant asset sales) to named individuals/families, their holding companies, or family offices/foundations, where the new wealth clearly exceeds $30 million. Obituaries of very wealthy individuals are also key.

3.  Investment Banking needs (large single stock positions, plans to sell or IPO a company, plans for mergers and acquisitions)

4.  **Rich List Individual Activity**: Articles featuring prominent Rich List individuals (e.g., Martin Thorborg, Anders Holch Povlsen, Kirk Kristiansen family members, etc.) discussing:
    *   Significant strategic decisions for their main businesses.
    *   Major investments or divestments, even if the article doesn't explicitly state a >$30M personal gain but the context implies substantial financial activity.
    *   Interviews where they speak at length about their company's performance or future plans that could significantly impact their wealth.

5.  **High-Value Strategic Intelligence**: News concerning major strategic developments at large, publicly-listed companies that are central to the region's wealth creation landscape (e.g., DSV, Maersk, Novo Nordisk), especially when quoting C-level executives.

6.  **Country Determination (CRITICAL)**: You MUST determine the country where the wealth event is taking place and where the primary beneficiaries are located. This is based on the ARTICLE CONTENT, not the newspaper's origin. If a Danish newspaper reports on a deal in the US, the country MUST be "United States". You MUST use official United Nations-recognized country names. You are FORBIDDEN from using cities (e.g., "Brussels") or incorrect regional terms (e.g., "Nordics"). The ONLY exceptions allowed are "Global", "Europe", and "Scandinavia" if and only if the location is truly ambiguous or transnational. Default to the newspaper's origin country ONLY as a last resort if no other information is available.

7.  **Key Individuals (Preliminary Pass)**: The 'key_individuals' field in your output for this step should ALWAYS BE AN EMPTY ARRAY \'[]\' A specialist agent will handle this task later. Your job is to focus on scoring and summarizing.

8.  **English Headline**: If the original article headline is not in English, you MUST provide a concise and accurate English translation in the "headline_en" field. If the headline is already in English, you may repeat it or omit the field.

NOTE: The user input may contain pre-fetched Wikipedia context after the main article body, separated by '---WIKIPEDIA CONTEXT---'. You should NOT treat this as part of the original article but use it to inform your analysis of country and background.

Exclude any articles primarily about:
-   A PE or VC firm's own operational news, such as fundraising or closing a new fund. Focus on their *transactions*.
-   Investment decisions by large institutional pension funds (like ATP).
-   Companies or projects without a clearly identified private individual/family beneficiary.
-   Routine company performance reports *unless* they directly quote a Rich List owner or CEO discussing significant strategic implications.
`,

  scoring: `
  Score 95-100 for:
  -   **Clear PE/VC acquisitions, exits, or sales.** (Guideline #1)
  -   **Direct Wealth Events (Guideline #2).** Confirmed, direct, substantial wealth transfers to private individuals/families. Assessment must state "Direct wealth event."

  Score 85-94 for:
  -   **PE/VC investments, "partnerships", or providing growth capital.** (Guideline #1)
  -   **Rich List Individual Activity (Guideline #3).** A known Rich List person making significant business moves or statements. Assessment must state "High relevance due to [Rich List Person]'s strategic involvement."
  -   **High-Value Strategic Intelligence (Guideline #4).** A major update on a key company like DSV or Maersk. Assessment must state "Strategic intelligence on a key wealth-generating entity."

  Score 50-84 for:
  -   Strongly implied but unconfirmed wealth events, smaller transactions (<$30M), or news about Rich List individuals that is business-related but less impactful.

  Score 0-49 for:
  -   Irrelevant news, general company news without significant strategic input from top leadership, or anything from the 'Exclude' list.
  `,

  vitals: `Pay extremely close attention to articles involving Private Equity firms (Egeria, Axcel, KKR, etc.) involved in a transaction (acquiring, investing, selling, partnering). These MUST be scored 85 or higher.
     Also, an interview with a founder of a large family company for example (e.g. John Blem being interviewed to tell about Milestone) should score 100.
     Finally, articles involving known Rich List individuals and their core business activities are highly important.
    `,

  reiteration:
    'Only respond with a properly formatted JSON object. The "key_individuals" field MUST be an empty array `[]`. Always determine and include the event country based on the content, following the strict naming rules (UN names or "Global", "Europe", "Scandinavia"). Provide an English headline if necessary.',
}


# File: src/modules/assessments/instructionCluster.js
// src/modules/assessments/instructionCluster.js

export const instructionCluster = {
  whoYouAre: "You are a news clustering analyst. Your goal is to identify which news articles are reporting on the exact same real-world event.",
  whatYouDo: "You will receive a JSON array of articles, each with an ID, headline, and summary. You must group articles that describe the same underlying event (e.g., the same company sale, the same IPO, the same investment).",
  guidelines: `
    1.  **Analyze Content:** Read the headline and summary of each article to understand the core event it describes.
    2.  **Group by Event:** If two or more articles are about the same event (e.g., 'Visma buys InnovateAI'), they belong in the same group. Articles about different events (e.g., 'Polaris invests in NewCo', 'Axcel sells OldCo') belong in separate groups.
    3.  **Create a Unique Event Key:** For each unique event group, create a short, descriptive, lowercase key. The key should include the main entities and the action, plus today's date in YYYY-MM-DD format. Example: \`acquisition-visma-innovateai-2024-05-20\`.
    4.  **Handle Singletons:** If an article describes an event that no other article covers, it forms its own group of one.
    5.  **Be Conservative:** If you are not highly confident that two articles describe the exact same event, place them in separate groups. It is better to have two small groups than to incorrectly merge two distinct events.
  `,
  outputFormatDescription: `
    Respond ONLY with a valid JSON object with a single top-level key "events".
    The value of "events" should be an array of objects.
    Each object in the array represents one unique event and must have two keys:
    - "event_key": The unique, descriptive key you created (e.g., "acquisition-visma-innovateai-2024-05-20").
    - "article_ids": An array of strings, where each string is the ID of an article belonging to this event.

    Example Response:
    {
      "events": [
        {
          "event_key": "acquisition-visma-innovateai-2024-05-20",
          "article_ids": ["60d21b4667d0d8992e610c85", "60d21b4667d0d8992e610c88"]
        },
        {
          "event_key": "investment-polaris-newco-2024-05-20",
          "article_ids": ["60d21b4667d0d8992e610c91"]
        }
      ]
    }
  `,
  reiteration: "Your entire response must be a single, valid JSON object as described. Do not include any other text, explanations, or markdown formatting."
};

# File: src/modules/assessments/instructionContacts.js
// src/modules/assessments/instructionContacts.js (version 2.0)
export const instructionContacts = {
  whoYouAre:
    'You are a ruthless M&A deal-flow analyst and CRM data enrichment specialist. Your output is pure, structured JSON data. You are obsessively focused on identifying individuals who have just gained or already possess significant liquid wealth.',
  whatYouDo:
    'Your sole mission is to analyze news data and extract a list of ALL individuals who are prime candidates for wealth management services (>$30M).',
  guidelines: [
    "**M&A ANALYSIS (Non-Negotiable Rule #1)**: In any M&A transaction (merger, acquisition, sale), your **unwavering primary target** is the **SELLER**. The buyer is irrelevant. You must deduce who the seller is, even if they are not explicitly named. Example: 'ProData Consult acquires Eliantie.' -> Your target is 'The owners/founders of Eliantie', because they are the ones receiving money.",
    "**WEALTH PROFILE ANALYSIS (Non-negotiable Rule #2)**: If the article is a **wealth profile** or a report on the financial success of a specific, named individual (like an athlete or entrepreneur), you MUST identify that individual as the key contact. Their 'role_in_event' should be 'Subject of Wealth Profile'.",
    "**IDENTIFICATION**: If a name isn't provided, you MUST describe the role (e.g., 'The sellers of Eliantie', 'The founding family of Prodata'). Be as specific as possible.",
    '**COMPREHENSIVENESS**: Extract multiple contacts from a single event if applicable (e.g., multiple co-founders selling, key executives with equity).',
    "**INVENTIVENESS**: Use your general knowledge. If the article mentions 'the founders of a well-known company,' try to name them. If an email is not provided, you MUST suggest a plausible corporate email address format (e.g., 'firstname.lastname@company.com').",
    "**FILTERING**: If the news does not describe a clear opportunity for a specific person or group, you MUST return an empty 'key_individuals' array.",
  ],
  outputFormatDescription: `
    Respond ONLY with a valid JSON object containing a single key "key_individuals".
    The value must be an array of JSON objects. IF NO CONTACTS ARE FOUND, RETURN AN EMPTY ARRAY.
    Example Structure:
    {
      "key_individuals": [
        {
           "name": "Full Name or 'The Sellers of ExampleCo'",
           "role_in_event": "Founder & Seller",
           "company": "ExampleCo",
           "email_suggestion": "name.surname@example.com"
        }
      ]
    }
  `,
}


# File: src/modules/assessments/instructionEnrichContact.js
// src/modules/assessments/instructionEnrichContact.js (version 1.0)
export const instructionEnrichContact = {
  whoYouAre: "You are a specialist corporate intelligence analyst. Your task is to synthesize information from a news article and Google search results to create a precise, actionable contact profile.",
  whatYouDo: "You will receive an 'Initial Contact Profile' (which may be vague) and 'Google Search Snippets'. Your mission is to use the search snippets to verify, correct, and enrich the initial profile, turning a role into a name if possible.",
  guidelines: [
    "**PRIORITY #1**: Resolve vague roles into specific names. If the initial profile is 'The founders of Eliantie' and a search result says 'Eliantie, founded by Jeroen Diederik and Maurice Blanken...', your primary output MUST be two distinct contact objects for these individuals.",
    "**SYNTHESIZE, DON'T GUESS**: Base your final output ONLY on the provided article and search snippets. Do not invent information not present in the context.",
    "**EMAIL SUGGESTION**: Use the verified company name and individual names to suggest a highly plausible corporate email address (e.g., 'j.diederik@eliantie.com').",
    "**LOCATION**: Extract the most specific location available from the context (e.g., 'Gorinchem, Netherlands' is better than just 'Netherlands').",
    "**MULTIPLE CONTACTS**: If the context reveals multiple relevant individuals (e.g., co-founders), you MUST return an array containing an object for each person.",
    "**NO ENRICHMENT**: If the search results provide no new, concrete information to improve the initial profile, simply return the initial profile data, formatted correctly."
  ],
  outputFormatDescription: `
    Respond ONLY with a valid JSON object containing a single key "enriched_contacts".
    The value must be an array of JSON objects.
    Example Structure:
    {
      "enriched_contacts": [
        {
           "name": "Jeroen Diederik",
           "role_in_event": "Founder & Seller of Eliantie",
           "company": "Eliantie B.V.",
           "email_suggestion": "jeroen.diederik@eliantie.com"
        },
        {
           "name": "Maurice Blanken",
           "role_in_event": "Founder & Seller of Eliantie",
           "company": "Eliantie B.V.",
           "email_suggestion": "maurice.blanken@eliantie.com"
        }
      ]
    }
  `
};

# File: src/modules/assessments/instructionHeadlines.js
// src/modules/assessments/instructionHeadlines.js (version 2.1 - Add English Translation)
export const instructionHeadlines = {
  whoYouAre: 'You are a wealth management analyst.',
  whatYouDo:
    'You assess whether news paper headlines describe immediate, substantial private wealth events and translate them to English.',
  guidelines: `
Include only:
- **PRIVATE EQUITY (PE) & VENTURE CAPITAL (VC) TRANSACTIONS**: Any headline announcing an acquisition, investment, partnership, sale, or exit by a named PE or VC firm (e.g., "Egeria acquires Company X", "KKR invests in Startup Y", "Axcel sells Portfolio Z"). Score these very high (85-100).
- Major liquidity events for private individuals, families, their family offices, or family foundations (e.g., company sales, IPOs benefiting founders, substantial asset sales) generating >$50M.
- Obituaries or similar events of ultra high net worth individuals leading to substantial wealth transfer/inheritance.
- Significant transactions or capital events within privately-held/family-owned holding companies of rich list families that clearly indicate a substantial change in the family's private wealth (e.g., large dividend payouts from holding to family, sale of a major subsidiary by the holding company).
- Any headlines directly indicating substantial (>$50M) wealth generation or transfer for rich list families or their primary business entities where the family is the clear beneficiary (e.g., "Bestseller owner Anders Holch Povlsen acquires major real estate portfolio for DKK 1 billion", "Grundfos owner foundation distributes DKK 500 million to Due Jensen family").
- **SPECIAL ATTENTION**: News involving known Rich List individuals like **Martin Thorborg**, Anders Holch Povlsen, the Kirk Kristiansen family (LEGO), the Holch Povlsen family (Bestseller), the Due Jensen family (Grundfos), etc., especially related to their business or investment activities should be scored with high relevance (70-100).

Strictly exclude:
- A Private Equity or Venture Capital firm's own operational news, such as fundraising, closing a new fund, or hiring partners. Focus on their *transactions* (buying/selling companies), not their internal business.
- Investment decisions made by large institutional pension funds (like ATP), as these do not represent private family wealth.
- General corporate news such as expansions, new product launches, operational performance (profits/losses of publicly traded companies). **EXCEPTION:** A takeover bid or M&A of a public company is RELEVANT.
- Headlines without direct, immediate, and substantial (>$50M) wealth impact for private individuals/families (unless it's a Rich List individual per "SPECIAL ATTENTION" rule).
- Foreign corporate or public institution activity, unless it's a direct acquisition/sale involving a private individual/family.
- Philanthropic donations by foundations or individuals (unless on the rich list)
- Appointments to boards or executive positions.
- General market commentary or economic trends.

// --- NEW REQUIREMENT ---
English Headline Generation:
- For EVERY headline, you MUST provide a concise and accurate English translation in the "headline_en" field.
- If the headline is already in English, simply repeat it in the "headline_en" field.

Relevance Scoring:
- 91‚Äì100: Clear PE/VC acquisitions or exits. Clear and substantial private wealth gain/transfer (>$50M) for individuals/families; news directly concerning Rich List families and significant activities of their primary businesses that clearly impact family wealth. Obituaries of UHNW individuals.
- 71‚Äì90: PE/VC investments, "partnerships", or providing growth capital. Strongly implied but unconfirmed wealth gains (e.g., major IPO of a family company). Likely or partial substantial wealth gain (potentially >$50M, or an IPO of a significant family-owned company). News about significant investments/divestments by Rich List family holdings where the private benefit is strongly implied. For Rich List individuals (like Martin Thorborg), this score applies if the event suggests significant business involvement or strategy shift.
- 51‚Äì70: Moderate or indirect wealth gain (typically <$50M but still a clear private wealth event).
- 31‚Äì50: Minor or future potential gain, or wealth event of unclear substantiality.
- 0‚Äì30: No private wealth relevance, or event clearly below significance thresholds, or anything from the 'Strictly Exclude' list.
`,
  scoring: `
Examples of High Relevance (91‚Äì100):
- "Danish family sells tech company for EUR 150M"
- "LEGO heir passes away leaving substantial estate"
- "Grundfos owner Poul Due Jensen's family holding company, KIRKBI A/S, acquires significant UK property portfolio for DKK 2 billion"
- "Bestseller owner Anders Holch Povlsen receives DKK 1 billion dividend from family holding company"
- "Martin Thorborg's company Dinero acquired by Visma" 
- "Anders Holch Povlsen invests DKK 500 million in new green tech venture"

Examples of Moderate/High Relevance (70-89 for Rich List):
- "Martin Thorborg's new AI venture secures seed funding" (Implies potential future wealth, activity of rich list person)
- "Business-update: Martin Thorborg erkender: Kunstig intelligens kan true hans forretning" (Significant strategic statement from Rich List individual about their business - score 70-80 to flag for review)

Examples of Low Relevance (0‚Äì29):
- "Boeing raises billions to pay debts"
- "Rockwool plans global expansion"
- "Homeowners to receive tax relief"
- "Grundfos (the company) announces record profits"
- "Danfoss heir appointed to new board" 
- "Martin Wellesen gives a public lecture on entrepreneurship" (Not a wealth event for him, and not on rich list)
- "Axcel closes its seventh fund at EUR 1.3 billion" (PE firm operational news)
- "ATP sells its stake in Bavarian Nordic" (Pension fund activity)
`,
  vitals: `
  **VITAL: Any headline mentioning a Private Equity firm (Egeria, Axcel, KKR, etc.) involved in a transaction (acquiring, investing, selling, partnering) MUST be scored 85 or higher.**
  **VITAL: Headlines mentioning names from the Rich List (e.g., Martin Thorborg, Holch Povlsen, Kirk Kristiansen) should be considered highly relevant (score 70-100).**
    But also an interview with a founder of a large family company for example (e.g. John Blem being interviewed to tell about Milestone) should score 100.
`,
  outputFormatDescription: `
Respond in English with a valid JSON object, exactly formatted like below.
It is vital that your response has a top-level "assessment" key:
{
  "assessment": [
    {
      "headline_en": "Aarstiderne sold to giant",
      "relevance_headline": 95,
      "assessment_headline": "Imminent personal wealth generation due to company sale."
    }
  ]
}
NEVER RETURN A PLAIN ARRAY.
`,
};

  

# File: src/modules/assessments/instructionOpportunities.js
// File: src/modules/assessments/instructionOpportunities.js
// src/modules/assessments/instructionOpportunities.js (version 3.0)
export const instructionOpportunities = {
  whoYouAre: `You are a ruthless M&A deal-flow data extraction engine. Your output is pure, structured JSON data for a CRM. 
    You are obsessively focused on identifying individuals who have just gained or already possess significant liquid wealth.
    These may be related to the transaction article; they may also just pop up on the "sideline", out of no-where even, prompting you to highlight them.
    `,
  whatYouDo:
    'Your sole mission is to analyze news data and extract a list of ALL individuals whose wealth makes them prime candidates for wealth management services (>$30M). You must estimate the wealth associated with the specific event or profile.',
  guidelines: [
    `**M&A ANALYSIS (Non-Negotiable Rule #1)**: In any M&A transaction (merger, acquisition, sale), 
    your **unwavering primary target** is the **SELLER**. The buyer is ONLY RELEVANT TO MENTION IN ADDITION, in case they are UHNW and worth contacting.
    You must deduce who the seller is, even if they are not explicitly named.
    For a clear sale of a company, or for a wealthy person such as a senior PE partner involved in the seller, you MUST estimate 'likelyMMDollarWealth' as 
    a number greater than 0. Returning 0 for a seller is a critical failure.`,

    `**WEALTH PROFILE ANALYSIS (Non-Negotiable Rule #2)**: If the article is a **wealth profile** of a known UHNW individual (e.g., 
    a Rich List member like Troels Holch Povlsen), you MUST list them. The 'whyContact' reason should be 'Identified as a UHNW 
    individual with significant existing assets.'`,

    `**NON-OPPORTUNITY CONTACTS (Non-Negotiable Rule #3)**: For individuals relevant to an article but who are **NOT** wealth opportunities 
    (e.g., the CEO of a public company in crisis), you MUST still include them, but you MUST set their 'likelyMMDollarWealth' to '0'.`,

    `**WEALTH ESTIMATION**: You MUST provide a numerical estimate for 'likelyMMDollarWealth' for all true opportunities. Analyze the deal size, 
    company revenue, and context to make a reasonable estimate in millions of USD. This may be your best guess, for example based on the
    revenues, turnover, sector or number of employees of the entity sold, or the profile of the buyer (for example, EQT would not purchase
    a company if it were valued less than $100mm, so if they are the buyer, that should give you a hint.)`,

    `**CONTACT DETAILS**: The 'contactDetails' field MUST be a JSON object containing 'email', 'role', and 'company'. If any detail is unknown, 
    its value should be 'null'. However you are asked to do your utter, deep thinking best to come up with an email address, which you may
    derive from the common format for the individual's company. However NEVER make up email addresses with domains such as "unknowncompany.com"
    or "personalemail.com", domains need to exist.`,

    `**LOCATION FORMATTING (Non-Negotiable Rule #4)**: The 'basedIn' field MUST contain the country where the identified individual is located. You MUST use official United Nations-recognized country names. You are FORBIDDEN from using cities or incorrect regional terms. The ONLY exceptions allowed are "Global", "Europe", and "Scandinavia" if and only if the person's location is truly ambiguous or transnational.`,

    `**HISTORY FORMATTING (Non-Negotiable Rule #5)**: The 'whyContact' field should be formatted to be appended to an existing record. 
    Start it with a timestamp in '[YYYY-MM-DD]' format, followed by the new reason. For example: '[2025-08-15] Received significant 
    liquidity from the sale of Eliantie to ProData Consult.'`,
  ],
  outputFormatDescription: `
    Respond ONLY with a valid JSON object containing a single key "opportunities". The value must be an array of JSON objects. IF NO CONTACTS ARE FOUND, RETURN AN EMPTY ARRAY.
    Example Structure:
    {
      "opportunities": [
        {
           "reachOutTo": "The founders of Eliantie",
           "contactDetails": {
              "email": "contact@eliantie.com",
              "role": "Founder & Seller",
              "company": "Eliantie"
           },
           "basedIn": "Netherlands",
           "whyContact": "[2025-08-15] Received significant liquidity from the sale of Eliantie to ProData Consult.",
           "likelyMMDollarWealth": 50
        }
      ]
    }
  `,
}


# File: src/modules/assessments/instructionSynthesize.js
// File: src/modules/assessments/instructionSynthesize.js

// src/modules/assessments/instructionSynthesize.js (version 2.0)
export const instructionSynthesize = {
  whoYouAre:
    'You are an expert financial journalist working for an exclusive executive briefing service in English.',
  whatYouDo:
    "You will receive JSON data containing today's news articles, historical context from our database, and public context from Wikipedia. Your task is to synthesize this information into a concise, high-value intelligence brief.",
  writingStyle:
    'Factual, dense, and objective, in the style of the Wall Street Journal or Financial Times. Use clear, professional English. Omit filler words and speculation.',
  guidelines: `
    1.  **Prioritize Today's News:** Your summary MUST be based on the information provided in the \`[ TODAY'S NEWS ]\` key. This is the core of the brief.
    2.  **Use Context for Enrichment:** Use \`[ HISTORICAL CONTEXT ]\` and \`[ PUBLIC WIKIPEDIA CONTEXT ]\` ONLY to add depth, verify facts, and provide background. Mention this context briefly (e.g., 'This follows a funding round last year...'). DO NOT report historical information as if it is new.
    3.  **CRITICAL RULE:** You are FORBIDDEN from mentioning any limitations of your sources. NEVER state that "Wikipedia context was not available," "full articles were unavailable," "reporting relied on headlines," or any similar phrase that expresses uncertainty or justification. Present your summary as a confident, finished piece of intelligence based on the information you have.
    4.  **Create a New Headline:** Write a new, overarching headline for the event. It should be clear, concise, and capture the essence of the news.
    5.  **Write a Concise Summary:** Write a new summary of the event. **The summary must be no more than 4 sentences and under 90 words.**
    6.  **Identify Key Individuals:** From the text, identify the key individuals involved. Create a single, de-duplicated list. For each, include their name, role, company, and, if possible, infer a corporate email address.
  `,
  outputFormatDescription: `
    Respond ONLY with a valid JSON object with the following structure:
    {
      "headline": "New, synthesized headline here. In English.",
      "summary": "New, synthesized summary here. In English. It must be under 90 words and no more than 4 sentences.",
      "key_individuals": [
        {
          "name": "Full Name",
          "role_in_event": "e.g., Founder & Seller",
          "company": "Company Name",
          "email_suggestion": "name.surname@company.com"
        }
      ]
    }
  `,
  reiteration:
    'Your entire response must be a single, valid JSON object. Adhere strictly to the length and sentence constraints for the summary. Never mention your sources or any limitations in your analysis.',
}


# File: src/modules/assessments/shotsArticle.js
// src/modules/assessments/shotsArticle.js (version 2.0)
// src/modules/assessments/shotsArticle.js

export const shotsInput = [
  { articleText: 'Nyt anl√¶g ved Esbjerg skal producere klimavenlig brint. Direkt√∏r Jens Hansen udtaler...' },
  { articleText: 'Aarstiderne, stiftet af S√∏ren Ejlersen, er blevet solgt til en international f√∏devaregigant for et trecifret millionbel√∏b.' },
  { articleText: 'Many homeowners will see lower property taxes in 2025 and 2026' },
  { articleText: 'The M√∏ller family has sold their shipping software company, NaviTech, for $500M.' },
  { articleText: 'Stellantis, the multinational car company, has reported that it stands to lose over 300 million kroner due to new US tariffs.' }, // NEW NEGATIVE EXAMPLE
  { articleText: 'The family-owned conglomerate USTC, owned by the √òstergaard-Nielsen family, is disputing a multimillion-krone claim from the Nordic Waste bankruptcy trustee.' }, // NEW RICH LIST PROXIMITY EXAMPLE
  { articleText: 'CEO of family-owned Scandinavian tech firm, Anna Schmidt, sells for $120M' },
  { articleText: 'The Grundfos holding company, owned by the Due Jensen family, has announced a dividend of 300 million kroner to be distributed among family members.' },
  { articleText: 'Rockwool plans massive global expansions' },
];

export const shotsOutput = [
  // REFINED: Updated to new JSON structure with country
  JSON.stringify({
    country: 'Denmark',
    topic: 'Green hydrogen plant in Esbjerg',
    relevance_article: 10,
    assessment_article: 'Infrastructure project with no direct personal wealth transfer.',
    amount: 0,
    key_individuals: [],
    background: 'Public or corporate energy initiative.',
  }),
  // REFINED: Updated to new JSON structure with country and email inference
  JSON.stringify({
    country: 'Denmark',
    topic: 'Sale of Aarstiderne',
    relevance_article: 95,
    assessment_article: 'Clear private wealth event for Scandinavian founder.',
    amount: 150, // Assuming DKK millions -> USD
    key_individuals: [{
      "name": "S√∏ren Ejlersen",
      "role_in_event": "Founder & Seller",
      "company": "Aarstiderne",
      "email_suggestion": "soren.ejlersen@aarstiderne.com"
    }],
    background: 'Sale of private Scandinavian company.',
  }),
  // REFINED: Updated to new JSON structure with country
  JSON.stringify({
    country: 'Denmark',
    topic: 'Property tax cuts for homeowners',
    relevance_article: 15,
    assessment_article: 'General tax relief is not a substantial direct wealth event.',
    amount: 0,
    key_individuals: [],
    background: 'Policy affecting many, not enriching individuals.',
  }),
  // REFINED: Updated to new JSON structure with country and email inference
  JSON.stringify({
    country: 'Denmark',
    topic: 'Sale of NaviTech',
    relevance_article: 100,
    assessment_article: 'Substantial wealth event clearly benefiting a Scandinavian family.',
    amount: 500,
    key_individuals: [{
      "name": "M√∏ller family",
      "role_in_event": "Seller",
      "company": "NaviTech",
      "email_suggestion": "contact@navitech.com"
    }],
    background: 'Private business transaction.',
  }),
  // NEW: Output for the Stellantis negative example with country
  JSON.stringify({
    country: 'United States',
    topic: 'Tariff losses for Stellantis',
    relevance_article: 5,
    assessment_article: 'Irrelevant. Article describes financial losses for a foreign multinational corporation.',
    amount: -300,
    key_individuals: [],
    background: 'General automotive industry news.',
  }),
  // NEW: Output for the USTC Rich List Proximity example with country
  JSON.stringify({
    country: 'Denmark',
    topic: 'USTC legal dispute over Nordic Waste claim',
    relevance_article: 60,
    assessment_article: 'High relevance due to the involvement of a Rich List family (√òstergaard-Nielsen/USTC) in a significant financial event.',
    amount: 0,
    key_individuals: [{
        "name": "√òstergaard-Nielsen family",
        "role_in_event": "Owner",
        "company": "USTC",
        "email_suggestion": "contact@ustc.dk"
    }],
    background: 'Ongoing legal and financial issue for a major family holding company.',
  }),
  // REFINED: Updated to new JSON structure with country and email inference
  JSON.stringify({
    country: 'Denmark',
    topic: 'Sale of Scandinavian tech firm',
    relevance_article: 95,
    assessment_article: 'Substantial wealth event for private Scandinavian individual.',
    amount: 120,
    key_individuals: [{
      "name": "Anna Schmidt",
      "role_in_event": "CEO & Seller",
      "company": "Unknown Tech Firm",
      "email_suggestion": null
    }],
    background: 'Private tech company acquisition.',
  }),
  // REFINED: Updated to new JSON structure with country
  JSON.stringify({
    country: 'Denmark',
    topic: 'Grundfos family dividend',
    relevance_article: 95,
    assessment_article: 'Direct and substantial wealth transfer to a private Scandinavian family.',
    amount: 45, // 300M DKK -> USD
    key_individuals: [{
        "name": "Due Jensen family",
        "role_in_event": "Recipient",
        "company": "Grundfos",
        "email_suggestion": null
    }],
    background: 'Dividend from a family-owned holding company.',
  }),
  // REFINED: Updated to new JSON structure with country
  JSON.stringify({
    country: 'Denmark',
    topic: 'Rockwool global expansion',
    relevance_article: 10,
    assessment_article: 'Corporate strategy of a public company, no individual wealth generation.',
    amount: 0,
    key_individuals: [],
    background: 'Public company operations.',
  }),
];

# File: src/modules/assessments/shotsHeadlines.js
// src/modules/assessments/shotsHeadlines.js (version 2.1 - Add English Translation)
export const shotsInput = [
  [
    'Rockwool st√•r foran massive udvidelser over hele kloden',
    'Boeing henter 145 mia. kr.',
    'Boligejere med for stor grundskyldsregning har udsigt til hj√¶lp',
    'Aarstiderne solgt til gigant',
    'Scandinavian family sells company for $500M',
  ].join('\n- '),

  [
    "Egeria raises ‚Ç¨1.25 billion with new private equity fund",
    "Egeria enters new partnership with Junge Die B√§ckerei.",
    "FSN Capital VI acquires a majority stake in ilionx",
    "Egeria divests Dutch Bakery after a period of strong growth",
    "Axcel closes its seventh fund at EUR 1.3 billion"
  ].join('\n- '),

  [
    'A.P. Moller Foundation donates $100 million to charity',
    'LEGO family (KIRKBI A/S) in acquisition talks for rival toy company for DKK 5 billion',
    'Danfoss heir (Bitten & Mads Clausen Foundation) announces succession plan for family business leadership',
    'Widex and Demant plan to merge operations',
    '3Shape (privately owned) is working on an IPO',
  ].join('\n- '),

  [
    'N√•|Sp√•r milliard-smell fra toll', // Stellantis example
    'Familieejet koncern bestrider millionkrav efter Nordic Waste', // USTC example
    'Fynske bankers fusionsplaner skydes ned af storaktion√¶r' // Public bank merger
  ].join('\n- '),

  [
    'Grundfos owner (Poul Due Jensen Foundation) announces DKK 300 million dividend distribution to family members',
    'Bestseller owner Anders Holch Povlsen personally acquires Scottish estate for DKK 150 million',
    "Martin Thorborg's AI Startup Secures Funding",
    'Martin Thorborg giver et foredrag om iv√¶rks√¶tteri'
  ].join('\n- '),
];

export const shotsOutput = [
  // MODIFIED: Added headline_en to each object
  JSON.stringify({
    assessment: [
      { headline_en: 'Rockwool faces massive expansions across the globe', relevance_headline: 10, assessment_headline: 'Corporate expansion (Rockwool is public), no direct private wealth generation.' },
      { headline_en: 'Boeing raises DKK 145 billion', relevance_headline: 0, assessment_headline: 'Foreign corporate activity, no relevance.' },
      { headline_en: 'Homeowners with excessive property tax bills can expect help', relevance_headline: 15, assessment_headline: 'Tax relief provides benefit, but not a substantial direct wealth transfer.' },
      { headline_en: 'Aarstiderne sold to giant', relevance_headline: 95, assessment_headline: 'Acquisition likely results in substantial wealth for founders/owners.' },
      { headline_en: 'Scandinavian family sells company for $500M', relevance_headline: 100, assessment_headline: 'Clear substantial private wealth event for a family.' },
    ],
  }),
  // MODIFIED: Added headline_en to each object
  JSON.stringify({
    assessment: [
      { headline_en: "Egeria raises ‚Ç¨1.25 billion with new private equity fund", relevance_headline: 0, assessment_headline: "Irrelevant. PE firm fundraising is operational news, not a transaction." },
      { headline_en: "Egeria enters new partnership with Junge Die B√§ckerei.", relevance_headline: 90, assessment_headline: "High relevance. A PE firm 'partnership' is an investment, a direct wealth event for the target company's owners." },
      { headline_en: "FSN Capital VI acquires a majority stake in ilionx", relevance_headline: 95, assessment_headline: "High relevance. A PE firm acquiring a majority stake is a clear liquidity event for the sellers." },
      { headline_en: "Egeria divests Dutch Bakery after a period of strong growth", relevance_headline: 95, assessment_headline: "High relevance. A PE firm 'divestment' or 'sale' is a clear liquidity event." },
      { headline_en: "Axcel closes its seventh fund at EUR 1.3 billion", relevance_headline: 0, assessment_headline: "Irrelevant. PE firm operational news (fundraising)." }
    ]
  }),
  // MODIFIED: Added headline_en to each object
  JSON.stringify({
    assessment: [
      { headline_en: 'A.P. Moller Foundation donates $100 million to charity', relevance_headline: 0, assessment_headline: 'Foundation donation, no personal private wealth involved.' },
      { headline_en: 'LEGO family (KIRKBI A/S) in acquisition talks for rival toy company for DKK 5 billion', relevance_headline: 95, assessment_headline: "Significant acquisition by rich list family's holding company, impacting family's wealth." },
      { headline_en: 'Danfoss heir (Bitten & Mads Clausen Foundation) announces succession plan for family business leadership', relevance_headline: 30, assessment_headline: 'Succession planning is not an immediate substantial wealth event.' },
      { headline_en: 'Widex and Demant plan to merge operations', relevance_headline: 70, assessment_headline: 'Merger of two significant companies, potential for substantial wealth implications for any remaining private owners.' },
      { headline_en: '3Shape (privately owned) is working on an IPO', relevance_headline: 80, assessment_headline: 'Potential substantial private wealth event if IPO proceeds benefit founders/owners significantly.' },
    ],
  }),
  // MODIFIED: Added headline_en to each object
  JSON.stringify({
    assessment: [
        { headline_en: 'Now | Predicts billion-krone blow from tariffs', relevance_headline: 5, assessment_headline: "Irrelevant. News about a foreign multinational (Stellantis) and financial losses." },
        { headline_en: 'Family-owned conglomerate disputes million-krone claim after Nordic Waste', relevance_headline: 60, assessment_headline: "Relevant due to Rich List family involvement (USTC owners) in a significant legal/financial dispute." },
        { headline_en: "Funen banks' merger plans shot down by major shareholder", relevance_headline: 10, assessment_headline: "Irrelevant. Merger of publicly-listed, non-family-owned banks." }
    ]
  }),
  // MODIFIED: Added headline_en to each object
  JSON.stringify({
    assessment: [
      { headline_en: 'Grundfos owner (Poul Due Jensen Foundation) announces DKK 300 million dividend distribution to family members', relevance_headline: 95, assessment_headline: 'Clear substantial private wealth event for the family via distribution from their foundation.' },
      { headline_en: 'Bestseller owner Anders Holch Povlsen personally acquires Scottish estate for DKK 150 million', relevance_headline: 90, assessment_headline: 'Substantial personal acquisition by rich list individual Anders Holch Povlsen.' },
      { headline_en: "Martin Thorborg's AI Startup Secures Funding", relevance_headline: 85, assessment_headline: 'High relevance. A new venture by a known Rich List individual securing funding is a significant potential wealth event.' },
      { headline_en: 'Martin Thorborg gives a lecture on entrepreneurship', relevance_headline: 0, assessment_headline: "Irrelevant. Rich List individual's public appearance is not a wealth event." }
    ],
  }),
];

# File: src/modules/dataStore/index.js
// src/modules/dataStore/index.js (version 3.6 - Conditional Content Saving)
import { Pinecone } from '@pinecone-database/pinecone';
import Article from '../../../models/Article.js';
import SynthesizedEvent from '../../../models/SynthesizedEvent.js';
import { logger } from '../../utils/logger.js';
import { generateEmbedding } from '../../utils/vectorUtils.js';
import { PINECONE_API_KEY, PINECONE_INDEX_NAME } from '../../config/index.js';

if (!PINECONE_API_KEY) throw new Error('Pinecone API Key is missing!');
const pc = new Pinecone({ apiKey: PINECONE_API_KEY });
const pineconeIndex = pc.index(PINECONE_INDEX_NAME);

/**
 * Saves pipeline results to MongoDB and Pinecone.
 * @param {Array} articlesToSave - The array of all articles processed in the run.
 * @param {Array} eventsToSave - The array of synthesized events.
 * @returns {Promise<{success: boolean, savedEvents: Array<Object>}>} A promise that resolves with the success status and an array of the saved event plain objects.
 */
export async function savePipelineResults(articlesToSave, eventsToSave) {
    logger.info(`Committing pipeline results to databases (MongoDB & Pinecone)...`);
    
    let savedEvents = [];

    try {
        const articleOps = [];
        const pineconeVectors = [];

        if (articlesToSave && articlesToSave.length > 0) {
            for (const article of articlesToSave) {
                if (article.relevance_article && article.articleContent) {
                    const textToEmbed = `${article.headline}\n${article.assessment_article || ''}`;
                    article.embedding = await generateEmbedding(textToEmbed);
                }
                const articleId = article._id.toString(); 
                if (article.embedding) {
                    pineconeVectors.push({
                        id: articleId,
                        values: article.embedding,
                        metadata: {
                            headline: article.headline,
                            summary: article.assessment_article || 'No summary.',
                            newspaper: article.newspaper,
                            country: article.country
                        }
                    });
                }
                const { _id, ...dataToSet } = article;
                Object.keys(dataToSet).forEach(key => dataToSet[key] === undefined && delete dataToSet[key]);
                
                // --- DEFINITIVE FIX: CONDITIONAL CONTENT DELETION ---
                // To save database space, we only store the full article content if the article is
                // considered "relevant" enough to be displayed in the frontend UI. The frontend
                // filter is set to show articles where either score is greater than 25.
                // If an article does not meet this condition, we can safely discard its large content payload.
                const isRelevantForUI = (dataToSet.relevance_headline > 25) || (dataToSet.relevance_article > 25);
                if (!isRelevantForUI) {
                    delete dataToSet.articleContent;
                }
                // --- END DEFINITIVE FIX ---
                
                delete dataToSet.embedding; 
                articleOps.push({
                    updateOne: { filter: { link: article.link }, update: { $set: dataToSet }, upsert: true }
                });
            }
            await Article.bulkWrite(articleOps, { ordered: false });
            logger.info(`MongoDB Article commit complete. Upserted/Modified: ${articleOps.length}.`);
            if (pineconeVectors.length > 0) {
                await pineconeIndex.upsert(pineconeVectors);
                logger.info(`Pinecone commit complete. Upserted ${pineconeVectors.length} vectors.`);
            }
        }

        if (eventsToSave && eventsToSave.length > 0) {
            const eventOps = [];
            for (const event of eventsToSave) {
                const eventPayload = event.toObject ? event.toObject() : event;
                delete eventPayload._id;
                eventOps.push({
                    updateOne: { filter: { event_key: event.event_key }, update: { $set: { ...eventPayload, emailed: false } }, upsert: true }
                });
            }
            const eventResult = await SynthesizedEvent.bulkWrite(eventOps, { ordered: false });
            logger.info(`MongoDB Event commit complete. Upserted: ${eventResult.upsertedCount}, Modified: ${eventResult.modifiedCount}.`);
            
            const eventKeys = eventsToSave.map(e => e.event_key);
            savedEvents = await SynthesizedEvent.find({ event_key: { $in: eventKeys } }).lean();
        } else {
            logger.info('No new articles or events to commit.');
        }
        
        return { success: true, savedEvents };

    } catch (error) {
        logger.fatal({ err: error }, 'CRITICAL: Failed to commit pipeline results to the databases.');
        return { success: false, savedEvents: [] };
    }
}

export async function filterFreshArticles(articles, isRefreshMode = false) {
    if (!articles || articles.length === 0) return [];
    const scrapedLinks = articles.map(a => a.link);
    if (isRefreshMode) {
        logger.warn('REFRESH MODE: All scraped articles will be processed, pulling existing data from DB where available.');
        const existingDbArticles = await Article.find({ link: { $in: scrapedLinks } }).lean();
        const existingArticlesMap = new Map(existingDbArticles.map(a => [a.link, a._id]));
        const articlesForReprocessing = articles.map(scrapedArticle => existingArticlesMap.get(scrapedArticle.link) ? { ...scrapedArticle, _id: existingArticlesMap.get(scrapedArticle.link) } : scrapedArticle);
        logger.info(`REFRESH MODE: Prepared ${articlesForReprocessing.length} articles for full re-processing.`);
        return articlesForReprocessing;
    }
    const existingArticles = await Article.find({ link: { $in: scrapedLinks } }).select('link').lean();
    const existingLinks = new Set(existingArticles.map(a => a.link));
    const freshArticles = articles.filter(a => !existingLinks.has(a.link));
    logger.info(`Filtering complete. Found ${existingLinks.size} existing articles from previous runs, ${freshArticles.length} are fresh.`);
    return freshArticles;
}

# File: src/modules/email/components/articleFormatter.js
// src/modules/email/components/articleFormatter.js (version 2.0)
import { logger } from '../../../utils/logger.js';
import { truncateString } from '../../../utils/helpers.js';

function createArticleCard(article) {
    const {
        link,
        headline,
        source,
        contacts,
        summary,
        assessmentText,
        relevanceScore,
        callToActionText,
    } = article;

    const scoreColor = relevanceScore >= 80 ? '#27ae60' : relevanceScore >= 50 ? '#f39c12' : '#c0392b';

    const contactsHtml = (contacts && contacts.length > 0)
        ? `<p style="margin: 0 0 15px; font-size: 14px; color: #555;"><strong>Contacts:</strong> ${contacts.join(', ')}</p>`
        : '';

    return `
    <div style="border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 20px; padding: 20px; background-color: #ffffff; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
        <h3 style="margin-top: 0; margin-bottom: 10px; font-size: 18px; color: #333;">
            <a href="${link}" style="color: #007bff; text-decoration: none;">${headline}</a>
        </h3>
        <p style="margin: 0 0 15px; font-size: 14px; color: #777;"><strong>Source:</strong> ${source}</p>
        ${contactsHtml}
        <p style="margin: 0 0 15px; font-size: 15px; color: #555; line-height: 1.6;">${summary}</p>
        <div style="background-color: #f8f9fa; border: 1px solid #dee2e6; border-radius: 6px; padding: 15px; margin-bottom: 15px;">
            <p style="margin: 0; font-size: 14px; color: #333;">
                <strong>System Assessment:</strong> <span style="font-weight: bold; color: ${scoreColor};">[Score: ${relevanceScore}]</span> ${assessmentText}
            </p>
        </div>
        <a href="${link}" style="display: inline-block; background-color: #007bff; color: #ffffff; padding: 10px 15px; border-radius: 5px; text-decoration: none; font-weight: bold; font-size: 14px;">
            ${callToActionText}
        </a>
    </div>
    `;
}

export function formatArticleForEmail(article) {
    if (!article || typeof article !== 'object' || !article.link || !article.headline) {
        logger.warn(`formatArticleForEmail: Invalid article object provided.`, { articlePreview: article });
        return `<p style="color:red;">Error: Article data was invalid.</p>`;
    }

    const genericArticleData = {
        link: article.link,
        headline: article.headline,
        source: article.source || article.newspaper || 'N/A',
        contacts: article.contacts || [],
        summary: 'No summary available.',
        assessmentText: article.assessment_article || article.assessment_headline || 'Assessment not available.',
        relevanceScore: article.relevance_article ?? article.relevance_headline ?? 'N/A',
        callToActionText: 'Read Full Article ‚Üí',
    };

    if (article.articleContent && typeof article.articleContent === 'object') {
        const { contents } = article.articleContent;
        if (contents && Array.isArray(contents) && contents.length > 0) {
            genericArticleData.summary = truncateString(contents.join(' '), 250);
        }
    }
    
    if (genericArticleData.summary === 'No summary available.') {
      genericArticleData.summary = truncateString(genericArticleData.assessmentText, 250);
    }

    try {
        return createArticleCard(genericArticleData);
    } catch (error) {
        logger.error(`Error creating article card for email: "${article.headline}"`, { errorMessage: error.message });
        return `<p style="color:red;">Error formatting article: ${truncateString(article.headline, 50)}</p>`;
    }
}

# File: src/modules/email/components/emailBodyBuilder.js
// src/modules/email/components/emailBodyBuilder.js (version 2.1)
// src/modules/email/components/emailBodyBuilder.js
import { logger } from '../../../utils/logger.js'
import { EMAIL_CONFIG } from '../../../config/index.js'
import { LOGO_CID } from '../constants.js' // <-- MODIFIED: Import LOGO_CID
import { formatEventForEmail } from './eventFormatter.js'
import { countryNameToFlagMap } from '../../../config/sources.js'

function createEmailWrapper(bodyContent, subject) {
  // This is a comprehensive wrapper designed for maximum email client compatibility.
  // It includes a <style> block for modern clients and uses inline styles for fallbacks.
  return `
    <!DOCTYPE html>
    <html lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:o="urn:schemas-microsoft-com:office:office">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta name="x-apple-disable-message-reformatting">
        <title>${subject}</title>
        <!--[if mso]>
        <noscript>
            <xml>
                <o:OfficeDocumentSettings>
                    <o:PixelsPerInch>96</o:PixelsPerInch>
                </o:OfficeDocumentSettings>
            </xml>
        </noscript>
        <![endif]-->
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Lexend:wght@300;400;500;600;700&display=swap" rel="stylesheet">
        <style>
            table, td, div, h1, h2, h3, p { font-family: 'Lexend', sans-serif; }
            body { margin: 0; padding: 0; }
            .content-table { width: 100%; max-width: 640px; }
            .main-background { background-color: #1a1a1a; }
            .content-background { background-color: #2a2a2a; }
            .main-heading { color: #ffffff; font-weight: 600; }
            .paragraph { color: #cccccc; line-height: 1.7; }
            .footer-text { color: #888888; }
            .button { 
                background-color: #D4AF37 !important;
                color: #1a1a1a !important; 
                text-decoration: none;
                border-radius: 8px;
                font-weight: 600;
                display: inline-block;
                transition: opacity 0.3s ease;
            }
            .button a {
                color: #1a1a1a !important;
                text-decoration: none;
            }
            .button:hover {
                opacity: 0.85;
            }
            @media screen and (max-width: 600px) {
                .content-table { width: 100% !important; }
            }
        </style>
    </head>
    <body style="margin: 0; padding: 0;">
        <table role="presentation" style="width:100%;border-collapse:collapse;border:0;border-spacing:0;" class="main-background">
            <tr>
                <td align="center" style="padding:20px 0;">
                    ${bodyContent}
                </td>
            </tr>
        </table>
    </body>
    </html>`
}

export async function createPersonalizedEmailBody(user, eventsByCountry, subject) {
  if (!user || !eventsByCountry || Object.keys(eventsByCountry).length === 0) {
    logger.warn('createPersonalizedEmailBody: Missing user or events data.')
    return null
  }

  let formattedEventsHtml = ''
  for (const [country, events] of Object.entries(eventsByCountry)) {
    const flag = countryNameToFlagMap.get(country) || 'üåç'
    formattedEventsHtml += `
        <tr>
          <td style="padding: 30px 0 10px 0;">
            <h2 style="margin:0; font-size: 24px; font-weight: 500; color: #EAEAEA;">${flag} ${country}</h2>
          </td>
        </tr>
      `
    const eventPromises = events.map((event) => formatEventForEmail(event))
    const resolvedEventsHtml = await Promise.all(eventPromises)
    formattedEventsHtml += resolvedEventsHtml
      .map((html) => `<tr><td>${html}</td></tr>`)
      .join('')
  }

  const mainContent = `
    <!--[if mso | IE]>
    <table role="presentation" border="0" cellpadding="0" cellspacing="0" class="content-table" align="center">
    <tr>
      <td style="padding:40px 30px;">
    <![endif]-->
    <div class="content-table" style="margin:0 auto;">
      <table role="presentation" style="width:100%;border-collapse:collapse;border:0;border-spacing:0;">
          <!-- Header -->
          <tr>
              <td align="center" style="padding:20px 0;">
                  <img src="cid:${LOGO_CID}" alt="${EMAIL_CONFIG.brandName} Logo" width="60" style="height:auto;display:block;">
                  <p style="font-size: 14px; font-weight: 500; color: #D4AF37; margin-top: 10px; margin-bottom: 0;">WEALTH INSIGHT</p>
              </td>
          </tr>
          <!-- Body -->
          <tr>
              <td style="padding:36px 30px;" class="content-background">
                  <table role="presentation" style="width:100%;border-collapse:collapse;border:0;border-spacing:0;">
                      <tr>
                          <td>
                              <h1 class="main-heading" style="margin:0 0 20px 0; font-size: 28px;">${subject}</h1>
                              <p class="paragraph" style="margin:0 0 25px 0; font-size: 16px;">Hi ${user.firstName},</p>
                              <p class="paragraph" style="margin:0 0 25px 0; font-size: 16px;">Here are the latest relevant wealth events we have identified.</p>
                          </td>
                      </tr>
                      <tr>
                        <td align="center" style="padding: 10px 0 30px 0;">
                           <table role="presentation" border="0" cellspacing="0" cellpadding="0">
                              <tr>
                                 <td class="button" style="padding:14px 28px;">
                                    <a href="https://headlines-client.vercel.app" target="_blank" style="font-size: 16px;">View Full Dashboard</a>
                                 </td>
                              </tr>
                           </table>
                        </td>
                      </tr>
                      ${formattedEventsHtml}
                  </table>
              </td>
          </tr>
          <!-- Footer -->
          <tr>
              <td style="padding:30px;">
                  <table role="presentation" style="width:100%;border-collapse:collapse;border:0;border-spacing:0;">
                      <tr>
                          <td align="center">
                              <p class="footer-text" style="margin:0;font-size:12px;">${EMAIL_CONFIG.brandName} | ${EMAIL_CONFIG.companyAddress}</p>
                              <p class="footer-text" style="margin:10px 0 0 0;font-size:12px;"><a href="${EMAIL_CONFIG.unsubscribeUrl}" style="color:#888888;text-decoration:underline;">Unsubscribe</a></p>
                          </td>
                      </tr>
                  </table>
              </td>
          </tr>
      </table>
    </div>
    <!--[if mso | IE]>
      </td>
    </tr>
    </table>
    <![endif]-->
    `

  return createEmailWrapper(mainContent, subject)
}


# File: src/modules/email/components/eventFormatter.js
// File: src/modules/email/components/eventFormatter.js
// src/modules/email/components/eventFormatter.js (version 3.0)
import { logger } from '../../../utils/logger.js'
import Opportunity from '../../../../models/Opportunity.js'

async function getOpportunitiesForEvent(eventId) {
  if (!eventId) return []
  try {
    const opportunities = await Opportunity.find({ sourceEventId: eventId }).lean()
    return opportunities
  } catch (error) {
    logger.error({ err: error, eventId }, 'Failed to fetch opportunities for event.')
    return []
  }
}

async function createEventBriefCard(event) {
  const {
    _id,
    synthesized_headline,
    synthesized_summary,
    ai_assessment_reason,
    source_articles,
    highest_relevance_score,
  } = event

  const opportunities = await getOpportunitiesForEvent(_id)

  const scoreColor =
    highest_relevance_score >= 80
      ? '#4CAF50'
      : highest_relevance_score >= 50
        ? '#FFC107'
        : '#F44336'
  const scoreTextShadow = `0 0 8px ${scoreColor}40`

  const opportunitiesHtml =
    opportunities && opportunities.length > 0
      ? `<tr>
             <td style="padding: 16px 0 8px; border-top: 1px solid #444444;">
                 <p style="margin:0; font-size: 14px; color: #D4AF37; font-weight: 600;">Opportunities Identified</p>
                 <div style="padding-top: 10px;">
                    ${opportunities
                      .map(
                        (opp) => `
                        <div style="margin-bottom: 12px; font-size: 14px; color: #cccccc; line-height: 1.6;">
                            <strong>${opp.reachOutTo}</strong> (${opp.basedIn || 'N/A'})<br>
                            <span style="color:#a0a0a0;">${opp.contactDetails.role || 'N/A'}${opp.contactDetails.company ? ` at ${opp.contactDetails.company}` : ''}</span>
                            <span style="color:#a0a0a0; font-weight: bold;"> | Est. Wealth: $${opp.likelyMMDollarWealth}M</span>
                            ${opp.contactDetails.email ? `<br><a href="mailto:${opp.contactDetails.email}" style="color: #66b3ff; text-decoration:none;">${opp.contactDetails.email}</a>` : ''}
                        </div>
                    `
                      )
                      .join('')}
                 </div>
             </td>
           </tr>`
      : ''

  const reasoningHtml = ai_assessment_reason
    ? `<tr>
             <td style="padding-top: 16px;">
                <p style="margin:0; font-size: 13px; color: #a0a0a0; font-style: italic; line-height: 1.5; border-left: 2px solid #D4AF37; padding-left: 12px;">
                    <strong>AI Reasoning:</strong> ${ai_assessment_reason}
                </p>
             </td>
           </tr>`
    : ''

  const sourcesHtml = source_articles
    .map(
      (article) => `
        <tr style="vertical-align: top;">
            <td style="padding: 5px 0; border-bottom: 1px solid #383838;">
                <a href="${article.link}" target="_blank" style="color: #cccccc; text-decoration: none; font-size: 14px; display: block;">
                    <span style="font-weight: 500; color: #ffffff;">${article.headline}</span><br>
                    <span style="font-size: 12px; color: #a0a0a0;">${article.newspaper}</span>
                </a>
            </td>
        </tr>
    `
    )
    .join('')

  const disclaimerHtml = `
        <tr>
            <td style="padding-top: 20px;">
                <p style="margin: 0; font-size: 11px; color: #777777; line-height: 1.5; text-align: center; border-top: 1px solid #333; padding-top: 15px;">
                    <strong>Disclaimer:</strong> This intelligence is automatically generated by an AI pipeline. While we strive for accuracy, all information, especially contact details and financial estimates, is based on publicly available data and may contain inaccuracies. Please conduct your own due diligence.
                </p>
            </td>
        </tr>
    `

  return `
    <div style="background-color: #1E1E1E; border-radius: 12px; margin-bottom: 25px; padding: 25px; border: 1px solid #333333; box-shadow: 0 10px 25px rgba(0,0,0,0.3);">
        <table role="presentation" style="width:100%;border-collapse:collapse;border:0;border-spacing:0;">
            <!-- Score & Headline -->
            <tr>
                <td style="padding-bottom: 15px;">
                    <table role="presentation" style="width:100%;border-collapse:collapse;border:0;border-spacing:0;">
                        <tr>
                            <td style="width: 60px; vertical-align: top;" valign="top">
                                <p style="font-size: 28px; font-weight: 700; color: ${scoreColor}; margin: 0; text-shadow: ${scoreTextShadow};">${highest_relevance_score}</p>
                                <p style="font-size: 12px; color: #a0a0a0; margin: 0;">Score</p>
                            </td>
                            <td style="padding-left: 20px;">
                                <h2 style="margin:0; font-size: 20px; font-weight: 600; color: #EAEAEA; line-height: 1.4;">${synthesized_headline}</h2>
                            </td>
                        </tr>
                    </table>
                </td>
            </tr>
            <!-- Summary -->
            <tr>
                <td style="padding-bottom: 20px;">
                    <p style="margin:0; font-size: 16px; color: #cccccc; line-height: 1.7;">${synthesized_summary}</p>
                </td>
            </tr>
            
            ${opportunitiesHtml}
            
            <!-- Sources -->
            <tr>
                <td style="padding: 16px 0 8px; border-top: 1px solid #444444;">
                    <p style="margin:0; font-size: 14px; color: #D4AF37; font-weight: 600;">Source Articles</p>
                </td>
            </tr>
            <tr>
              <td>
                <table role="presentation" style="width:100%;border-collapse:collapse;border:0;border-spacing:0;">${sourcesHtml}</table>
              </td>
            </tr>

            ${reasoningHtml}
            ${disclaimerHtml}
        </table>
    </div>
    `
}

export async function formatEventForEmail(event) {
  if (!event || typeof event !== 'object' || !event.synthesized_headline) {
    logger.warn(`formatEventForEmail: Invalid event object provided.`, {
      eventPreview: event,
    })
    return `<p style="color:red;">Error: Event data was invalid.</p>`
  }

  try {
    return await createEventBriefCard(event)
  } catch (error) {
    logger.error(`Error creating event card for email: "${event.synthesized_headline}"`, {
      errorMessage: error.message,
    })
    return `<p style="color:red;">Error formatting event: ${event.synthesized_headline}</p>`
  }
}


# File: src/modules/email/components/supervisorEmailBodyBuilder.js
// src/modules/email/components/supervisorEmailBodyBuilder.js (version 2.1)
// src/modules/email/components/supervisorEmailBodyBuilder.js
import {
  SUPERVISOR_EMAIL_CONFIG,
  HEADLINES_RELEVANCE_THRESHOLD,
} from '../../../config/index.js'
import { LOGO_CID } from '../constants.js' // <-- MODIFIED: Import LOGO_CID
import { truncateString } from '../../../utils/helpers.js'
import Article from '../../../../models/Article.js'
import SynthesizedEvent from '../../../../models/SynthesizedEvent.js'
import Opportunity from '../../../../models/Opportunity.js'

function escapeHtml(unsafe) {
  if (unsafe === null || unsafe === undefined) return ''
  return String(unsafe)
    .replace(/&/g, '&amp;')
    .replace(/</g, '&lt;')
    .replace(/>/g, '&gt;')
    .replace(/"/g, '&quot;')
    .replace(/'/g, '&#039;')
}

function createSupervisorEmailWrapper(bodyContent, subject) {
  return `
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>${subject}</title>
        <style>
            body { margin: 0; padding: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif; background-color: #f8f9fa; color: #212529; }
            .container { max-width: 1200px; margin: 20px auto; background-color: #ffffff; padding: 40px; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.05); }
            h1, h2, h3, h4 { margin-top: 0; margin-bottom: 1rem; font-weight: 600; color: #343a40; }
            h1 { font-size: 28px; }
            h2 { font-size: 22px; border-bottom: 1px solid #dee2e6; padding-bottom: 10px; margin-top: 40px; }
            p { margin-top: 0; margin-bottom: 1rem; line-height: 1.6; }
            table { width: 100%; border-collapse: collapse; font-size: 14px; }
            th, td { padding: 12px 15px; text-align: left; border-bottom: 1px solid #dee2e6; }
            th { background-color: #f1f3f5; font-weight: 600; }
            tr:nth-child(even) { background-color: #f8f9fa; }
            tr:hover { background-color: #e9ecef; }
            a { color: #007bff; text-decoration: none; }
            a:hover { text-decoration: underline; }
            .alert-box { border: 1px solid; border-radius: 8px; padding: 20px; margin: 20px 0; }
            .alert-danger { background-color: #f8d7da; border-color: #f5c6cb; color: #721c24; }
            .alert-danger h2 { color: #721c24; }
            .card { border: 1px solid #dee2e6; border-radius: 8px; margin-bottom: 20px; background-color: #ffffff; }
            .card-header { padding: 15px; border-bottom: 1px solid #dee2e6; background-color: #f8f9fa; }
            .card-body { padding: 20px; }
            .status-success { color: #28a745; font-weight: bold; }
            .status-dropped { color: #dc3545; font-weight: bold; }
        </style>
    </head>
    <body>
        <div class="container">${bodyContent}</div>
    </body>
    </html>`
}

function createScraperFailureAlertHtml(enrichmentOutcomes) {
  if (!enrichmentOutcomes || enrichmentOutcomes.length === 0) return ''

  const scraperFailures = enrichmentOutcomes.filter(
    (item) =>
      item.outcome === 'Dropped' && item.assessment_article.includes('Enrichment Failed')
  )

  if (scraperFailures.length === 0) return ''

  let listItems = scraperFailures
    .map(
      (item) => `
        <li style="margin-bottom: 12px;">
            <strong>${escapeHtml(item.newspaper)}:</strong> 
            <a href="${item.link}" target="_blank">${escapeHtml(item.headline)}</a><br>
            <em style="font-size:13px; color: #555;">${escapeHtml(item.assessment_article)}</em>
        </li>
    `
    )
    .join('')

  return `
    <div class="alert-box alert-danger">
        <h2 style="margin-top:0;">‚ö†Ô∏è Scraper Action Required</h2>
        <p>The following relevant headlines failed the enrichment stage, likely due to an outdated or incorrect article text selector. Please review the selectors for these sources in <strong>src/config/sources.js</strong>.</p>
        <ul style="padding-left: 20px; margin-top: 15px; font-size: 14px;">${listItems}</ul>
    </div>`
}

function createScraperHealthTable(healthStats) {
  if (!healthStats || healthStats.length === 0)
    return '<h2>Scraper Health Check</h2><p>No health stats available.</p>'

  let tableRows = healthStats
    .sort((a, b) => a.source.localeCompare(b.source))
    .map((stat) => {
      const status = stat.success ? '‚úÖ OK' : '‚ùå FAILED'
      const statusColor = stat.success ? '#28a745' : '#dc3545'
      return `
            <tr>
                <td>${escapeHtml(stat.source)}</td>
                <td style="color: ${statusColor}; font-weight: bold;">${status}</td>
                <td>${stat.count}</td>
            </tr>`
    })
    .join('')

  return `
    <h2>Scraper Health Check</h2>
    <table>
        <thead><tr><th>Source</th><th>Status</th><th>Articles Found</th></tr></thead>
        <tbody>${tableRows}</tbody>
    </table>`
}

function createEnrichmentFunnelHtml(enrichmentOutcomes) {
  if (!enrichmentOutcomes || enrichmentOutcomes.length === 0) {
    return `<h2>Enrichment Funnel</h2><p>No headlines were relevant enough for enrichment (scored &lt; ${HEADLINES_RELEVANCE_THRESHOLD}).</p>`
  }

  const cardsHtml = enrichmentOutcomes
    .sort((a, b) => {
      if (a.outcome === 'Success' && b.outcome !== 'Success') return -1
      if (a.outcome !== 'Success' && b.outcome === 'Success') return 1
      return (b.headlineScore || 0) - (a.headlineScore || 0)
    })
    .map((item) => {
      const isSuccess = item.outcome === 'Success'
      const statusClass = isSuccess ? 'status-success' : 'status-dropped'
      const statusIcon = isSuccess ? '‚úÖ' : '‚ùå'

      return `
        <div class="card">
            <div class="card-header">
                <h4 style="margin:0; font-size: 16px;">
                    <a href="${item.link}" target="_blank">${escapeHtml(item.headline)}</a>
                </h4>
            </div>
            <div class="card-body">
                <p style="margin: 0 0 10px;"><strong>${statusIcon} Status:</strong> <span class="${statusClass}">${item.outcome}</span></p>
                <p style="margin: 0 0 5px; font-size: 13px; color: #495057;">
                    <strong>Stage 1 (Headline):</strong> Score [${item.headlineScore}] - <i>${escapeHtml(item.assessment_headline)}</i>
                </p>
                <p style="margin: 0 0 10px; font-size: 13px; color: #495057;">
                    <strong>Stage 2 (Content):</strong> Final Score [${item.finalScore ?? 'N/A'}] - <span style="font-style: italic;">${escapeHtml(item.assessment_article)}</span>
                </p>
                <div style="padding: 10px; background-color: #f8f9fa; border: 1px solid #dee2e6; border-radius: 4px; font-size: 12px; color: #495057; max-height: 100px; overflow-y: auto;">
                    <strong>Article Snippet:</strong>
                    <p style="margin-top: 5px; margin-bottom: 0; white-space: pre-wrap; font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;">${escapeHtml(item.content_snippet)}...</p>
                </div>
            </div>
        </div>`
    })
    .join('')

  return `<h2>Enrichment Funnel Audit Trail (Lifecycle of ${enrichmentOutcomes.length} relevant headlines)</h2>${cardsHtml}`
}

async function createEventsTableHtml(runStartDate) {
  const recentEvents = await SynthesizedEvent.find({ createdAt: { $gte: runStartDate } })
    .sort({ createdAt: -1 })
    .limit(50)
    .lean()
  if (recentEvents.length === 0)
    return `<h2>Synthesized Events from this Run</h2><p>No events were synthesized in this run.</p>`

  let tableRows = recentEvents
    .map(
      (event) => `
        <tr>
            <td>${truncateString(escapeHtml(event.synthesized_headline), 80)}</td>
            <td>${event.highest_relevance_score}</td>
            <td>${escapeHtml(event.source_articles.map((a) => a.newspaper).join(', '))}</td>
            <td>${escapeHtml(event.key_individuals.map((p) => p.name).join(', ') || 'N/A')}</td>
            <td>${event.emailed ? 'Yes' : 'No'}</td>
        </tr>
    `
    )
    .join('')

  return `
    <h2>Synthesized Events (${recentEvents.length})</h2>
    <table>
        <thead><tr><th>Synthesized Headline</th><th>Score</th><th>Sources</th><th>Key Individuals</th><th>Emailed?</th></tr></thead>
        <tbody>${tableRows}</tbody>
    </table>`
}

async function createArticlesTableHtml(runStartDate) {
  const freshArticles = await Article.find({ createdAt: { $gte: runStartDate } })
    .sort({ relevance_headline: -1 })
    .limit(500)
    .lean()
  if (freshArticles.length === 0)
    return `<h2>All Fresh Articles Processed</h2><p>No new raw articles were processed.</p>`

  const relevantFreshArticles = freshArticles.filter((a) => a.relevance_headline > 0)
  const irrelevantCount = freshArticles.length - relevantFreshArticles.length

  if (relevantFreshArticles.length === 0) {
    return `<h2>All Fresh Articles Processed (${freshArticles.length})</h2><p>No headlines were deemed relevant (all scored 0).</p>`
  }

  let tableRows = relevantFreshArticles
    .map((article) => {
      const status =
        article.relevance_headline >= HEADLINES_RELEVANCE_THRESHOLD
          ? 'Relevant for Enrichment'
          : 'Low Relevance'
      return `
            <tr>
                <td><a href="${article.link}" target="_blank">${truncateString(escapeHtml(article.headline), 80)}</a></td>
                <td>${escapeHtml(article.newspaper)}</td>
                <td>${article.relevance_headline}</td>
                <td>${status}</td>
            </tr>`
    })
    .join('')

  let footer = ''
  if (irrelevantCount > 0) {
    footer = `<p style="margin-top: 15px; font-size: 13px; color: #6c757d;">... plus ${irrelevantCount} other headlines that were deemed irrelevant (score 0).</p>`
  }

  return `
    <h2>All Fresh Articles Processed (${freshArticles.length})</h2>
    <table>
        <thead><tr><th>Headline</th><th>Source</th><th>HL Score</th><th>Status</th></tr></thead>
        <tbody>${tableRows}</tbody>
    </table>
    ${footer}`
}

export async function createSupervisorEmailBody(runStats) {
  const runTimestamp = new Date().toLocaleString('en-GB', {
    timeZone: 'Europe/Copenhagen',
  })
  const runStartDate = new Date(Date.now() - 10 * 60 * 1000) // Check for items created in the last 10 minutes

  const [newArticleCount, newEventCount, newOpportunityCount] = await Promise.all([
    Article.countDocuments({ createdAt: { $gte: runStartDate } }),
    SynthesizedEvent.countDocuments({ createdAt: { $gte: runStartDate } }),
    Opportunity.countDocuments({ createdAt: { $gte: runStartDate } }),
  ])

  let statsHtml = `<h2>Run Statistics</h2><ul>`
  const statOrder = [
    'headlinesScraped',
    'freshHeadlinesFound',
    'headlinesAssessed',
    'relevantHeadlines',
    'articlesEnriched',
    'relevantArticles',
  ]

  for (const key of statOrder) {
    if (runStats.hasOwnProperty(key)) {
      const value = runStats[key]
      const formattedKey = key
        .replace(/([A-Z])/g, ' $1')
        .replace(/^./, (str) => str.toUpperCase())
      statsHtml += `<li style="font-size: 15px; margin-bottom: 8px;"><strong>${formattedKey}:</strong> ${value}</li>`
    }
  }

  statsHtml += `<li style="font-size: 15px; margin-bottom: 8px; font-weight: bold; color: #0056b3;"><strong>New Articles Created:</strong> ${newArticleCount}</li>`
  statsHtml += `<li style="font-size: 15px; margin-bottom: 8px; font-weight: bold; color: #0056b3;"><strong>New Events Synthesized:</strong> ${newEventCount}</li>`
  statsHtml += `<li style="font-size: 15px; margin-bottom: 8px; font-weight: bold; color: #0056b3;"><strong>New Opportunities Generated:</strong> ${newOpportunityCount}</li>`
  statsHtml += `<li style="font-size: 15px; margin-bottom: 8px;"><strong>Events Emailed to Subscribers:</strong> ${runStats.eventsEmailed || 0}</li>`

  if (runStats.errors && runStats.errors.length > 0) {
    statsHtml += `<li style="font-size: 15px; margin-bottom: 8px; color: #721c24;"><strong>Errors:</strong> ${runStats.errors.join(', ')}</li>`
  }
  statsHtml += `</ul>`

  const scraperFailureAlertHtml = createScraperFailureAlertHtml(
    runStats.enrichmentOutcomes
  )
  const scraperHealthHtml = createScraperHealthTable(runStats.scraperHealth)
  const enrichmentFunnelHtml = createEnrichmentFunnelHtml(runStats.enrichmentOutcomes)

  const [eventsTableHtml, articlesTableHtml] = await Promise.all([
    createEventsTableHtml(runStartDate),
    createArticlesTableHtml(runStartDate),
  ])

  const bodyContent = `
        <div style="text-align:center; margin-bottom: 30px;">
            <img src="cid:${LOGO_CID}" alt="Logo" style="max-width:50px; filter: grayscale(1);">
            <h1>${SUPERVISOR_EMAIL_CONFIG.subject}</h1>
            <p style="font-size: 16px; color: #6c757d;">Run completed: ${runTimestamp}</p>
        </div>
        
        ${scraperFailureAlertHtml}
        ${statsHtml}
        ${enrichmentFunnelHtml}
        ${eventsTableHtml}
        ${articlesTableHtml}
        ${scraperHealthHtml}

        <div style="text-align: center; margin-top: 40px; padding-top: 20px; border-top: 1px solid #dee2e6; font-size: 12px; color: #6c757d;">
            <p>This is an automated report from the ${SUPERVISOR_EMAIL_CONFIG.brandName}.</p>
        </div>
    `

  return createSupervisorEmailWrapper(bodyContent, SUPERVISOR_EMAIL_CONFIG.subject)
}


# File: src/modules/email/constants.js
// src/modules/email/constants.js (version 2.1)
// src/modules/email/constants.js

// Define the Content-ID (CID) for the embedded logo.
// This acts as an internal URL within the email itself.
export const LOGO_CID = 'logo@wealthevents.email';

// Define the local path to the logo file.
export const LOGO_PATH = './public/bullion.png';

# File: src/modules/email/index.js
// src/modules/email/index.js (version 2.2)
import { logger } from '../../utils/logger.js'
import { performActualSupervisorEmailSend } from './mailer.js'
import Subscriber from '../../../models/Subscriber.js'

/**
 * DEPRECATED - This function is no longer used.
 * All user-facing email logic is now handled by the central notification orchestrator.
 * Kept for historical reference during transition, will be removed later.
 */
export async function sendWealthEventsEmail() {
  logger.warn(
    'DEPRECATED: sendWealthEventsEmail function was called. This should not happen.'
  )
  return { eventsSentCount: 0 }
}

/**
 * Coordinates sending the supervisor report email.
 * @param {Object} runStats - Statistics about the current pipeline run.
 */
export async function sendSupervisorReportEmail(runStats) {
  if (!runStats) {
    logger.error('No runStats provided for supervisor report. Skipping email.')
    return
  }

  logger.info('Preparing supervisor report email...')

  try {
    const superUsers = await Subscriber.find({
      isActive: true,
      role: 'admin',
    })
      .select('email')
      .lean()

    const superUserEmails = superUsers.map((user) => user.email)

    if (superUserEmails.length === 0) {
      logger.warn('No admin users found. Skipping supervisor report.')
      return
    }

    await performActualSupervisorEmailSend(runStats, superUserEmails)
    logger.info('‚úÖ Supervisor report email successfully sent/queued to all superusers.')
  } catch (error) {
    logger.error({ err: error }, 'üí• CRITICAL: Failed to send supervisor report email.')
  }
}


# File: src/modules/email/mailer.js
// src/modules/email/mailer.js (version 2.0)
import nodemailer from 'nodemailer'
import { logger } from '../../utils/logger.js'
import { safeExecute } from '../../utils/helpers.js'
import {
  SUPERVISOR_EMAIL_CONFIG,
  SMTP_CONFIG,
  IS_PRODUCTION,
  FORCE_EMAIL_SEND_DEV,
} from '../../config/index.js'
import { createSupervisorEmailBody } from './components/supervisorEmailBodyBuilder.js'
import { LOGO_CID, LOGO_PATH } from './constants.js' // <-- MODIFIED: Import CID and PATH

async function sendEmail(mailOptions, emailType) {
  if (!IS_PRODUCTION && !FORCE_EMAIL_SEND_DEV) {
    logger.warn(
      `[${emailType} Mailer] DEV MODE: Skipping actual email send to: ${mailOptions.to}`
    )
    return { skipped: true, reason: 'DEV mode' }
  }

  if (!SMTP_CONFIG?.auth?.user || !SMTP_CONFIG?.auth?.pass) {
    logger.error(`‚ùå [${emailType} Mailer] SMTP authentication not fully configured.`)
    return { error: 'SMTP authentication not fully configured.' }
  }

  logger.info(
    `üì§ [${emailType} Mailer] Sending email via Nodemailer to: ${mailOptions.to}.`
  )

  const transporter = nodemailer.createTransport(SMTP_CONFIG)

  // --- NEW: Add the logo as an embedded attachment to every email ---
  if (!mailOptions.attachments) {
    mailOptions.attachments = []
  }
  mailOptions.attachments.push({
    filename: 'bullion.png', // The name of the file
    path: LOGO_PATH, // The local path to the file
    cid: LOGO_CID, // The Content-ID to reference in the HTML
  })
  // --- END NEW ---

  const sendResult = await safeExecute(() => transporter.sendMail(mailOptions), {
    errorHandler: (error) => {
      logger.error(`‚ùå [${emailType} Mailer] Nodemailer SMTP error:`, {
        message: error.message,
        code: error.code,
      })
      return { errorOccurred: true, details: error.message }
    },
  })

  if (sendResult && sendResult.errorOccurred) {
    return { error: `SMTP Error: ${sendResult.details}` }
  }

  logger.info(`‚úÖ [${emailType} Mailer] Email sent successfully to ${mailOptions.to}.`)
  return { success: true }
}

export async function sendPersonalizedEmail({ user, subject, body }) {
  if (!user || !user.email) {
    logger.error(`‚ùå [Wealth Events Mailer] Invalid user object provided.`)
    return false
  }

  const mailOptions = {
    from: `"${SMTP_CONFIG.fromName}" <${SMTP_CONFIG.fromAddress}>`,
    to: user.email,
    bcc: 'reconozco@gmail.com',
    subject: subject,
    html: body,
  }

  const result = await sendEmail(mailOptions, 'Wealth Events')
  return result.success || false
}

export async function performActualSupervisorEmailSend(runStats, recipients) {
  if (!recipients || recipients.length === 0) {
    logger.warn(
      '[Supervisor Mailer] Skipping: No superusers configured to receive this report.'
    )
    return
  }

  const emailBodyHtml = await createSupervisorEmailBody(runStats)
  if (!emailBodyHtml) {
    logger.error('‚ùå [Supervisor Mailer] HTML email body generation failed.')
    throw new Error('Failed to generate supervisor email body')
  }

  const mailOptions = {
    from: `"${SMTP_CONFIG.fromName}" <${SMTP_CONFIG.fromAddress}>`,
    to: recipients.join(', '),
    subject: SUPERVISOR_EMAIL_CONFIG.subject,
    html: emailBodyHtml,
  }

  const result = await sendEmail(mailOptions, 'Supervisor Report')

  if (result.error) {
    throw new Error(`Failed to send supervisor email: ${result.error}`)
  }
}


# File: src/modules/notifications/emailService.js
// src/modules/notifications/emailService.js (version 1.0)
import nodemailer from 'nodemailer'
import { logger } from '../../utils/logger.js'
import { SMTP_CONFIG, IS_PRODUCTION, FORCE_EMAIL_SEND_DEV } from '../../config/index.js'
import { configStore } from '../../config/dynamicConfig.js'

const transporter =
  SMTP_CONFIG?.auth?.user && SMTP_CONFIG?.auth?.pass
    ? nodemailer.createTransport(SMTP_CONFIG)
    : null

function createEmailBody(user, events, opportunities) {
  let body = `
    <html><body>
    <p>Hi ${user.firstName},</p>
    <p>Here is your personalized intelligence briefing:</p>
  `

  if (events.length > 0) {
    body += '<h2>New Synthesized Events</h2>'
    events.forEach((event) => {
      const flag = configStore.countryNameToFlagMap.get(event.country) || 'üåç'
      body += `
        <div style="border: 1px solid #ccc; padding: 10px; margin-bottom: 10px;">
          <h3>${flag} ${event.synthesized_headline} [Score: ${event.highest_relevance_score}]</h3>
          <p><em>${event.synthesized_summary}</em></p>
          <p><strong>Source Articles:</strong></p>
          <ul>
            ${event.source_articles
              .map(
                (article) =>
                  `<li><a href="${article.link}">${article.headline}</a> (${article.newspaper})</li>`
              )
              .join('')}
          </ul>
        </div>
      `
    })
  }

  if (opportunities.length > 0) {
    body += '<h2>New Opportunities</h2>'
    opportunities.forEach((opp) => {
      const flag = configStore.countryNameToFlagMap.get(opp.basedIn) || 'üåç'
      body += `
        <div style="border: 1px solid #ccc; padding: 10px; margin-bottom: 10px;">
          <h3>${flag} Contact: ${opp.reachOutTo} (~$${opp.likelyMMDollarWealth}M)</h3>
          <p><strong>Reason:</strong> ${opp.whyContact[0]}</p>
          <p>Based in: ${opp.basedIn}</p>
          ${
            opp.sourceArticleId
              ? `<p><a href="${opp.sourceArticleId.link}">View Source Article</a></p>`
              : ''
          }
        </div>
      `
    })
  }

  body += '</body></html>'
  return body
}

export async function sendBulkEmails(emailQueue) {
  if (!transporter) {
    logger.error('SMTP transport not configured. Cannot send emails.')
    return 0
  }
  if (emailQueue.length === 0) return 0

  logger.info(`Dispatching ${emailQueue.length} personalized emails...`)
  let successCount = 0

  for (const { user, events, opportunities } of emailQueue) {
    const subject = `New Intelligence: ${events.length} Events, ${opportunities.length} Opportunities`
    const htmlBody = createEmailBody(user, events, opportunities)

    const mailOptions = {
      from: `"${SMTP_CONFIG.fromName}" <${SMTP_CONFIG.fromAddress}>`,
      to: user.email,
      subject,
      html: htmlBody,
    }

    if (!IS_PRODUCTION && !FORCE_EMAIL_SEND_DEV) {
      logger.warn(`[DEV MODE] Skipping actual email send to: ${user.email}`)
      successCount++
      continue
    }

    try {
      await transporter.sendMail(mailOptions)
      logger.info(`‚úÖ Email sent successfully to ${user.email}`)
      successCount++
    } catch (error) {
      logger.error({ err: error }, `‚ùå Failed to send email to ${user.email}`)
    }
  }

  return successCount
}


# File: src/modules/notifications/index.js
// src/modules/notifications/index.js (version 1.0)
import { logger } from '../../utils/logger.js'
import Subscriber from '../../../models/Subscriber.js'
import PushSubscription from '../../../models/PushSubscription.js'
import { sendBulkEmails } from './emailService.js'
import { sendBulkPushNotifications } from './pushService.js'

/**
 * Main orchestrator to send personalized notifications for new events and opportunities.
 * @param {Array<Object>} newEvents - Array of newly created SynthesizedEvent documents.
 * @param {Array<Object>} newOpportunities - Array of newly created Opportunity documents.
 */
export async function sendNotifications(newEvents, newOpportunities) {
  logger.info(
    `üìß Starting personalized notification dispatch for ${newEvents.length} events and ${newOpportunities.length} opportunities.`
  )

  // 1. Fetch all active subscribers and their push subscriptions in one go.
  const [activeSubscribers, allPushSubscriptions] = await Promise.all([
    Subscriber.find({ isActive: true }).lean(),
    PushSubscription.find().lean(),
  ])

  if (activeSubscribers.length === 0) {
    logger.info('No active subscribers found. Skipping notification dispatch.')
    return { emailSentCount: 0, pushSentCount: 0 }
  }

  // 2. Create a map for efficient lookup of push subscriptions per user.
  const pushSubsByUserId = allPushSubscriptions.reduce((acc, sub) => {
    const userId = sub.subscriberId.toString()
    if (!acc[userId]) acc[userId] = []
    acc[userId].push(sub)
    return acc
  }, {})

  // 3. Prepare data payloads grouped by country for efficient filtering.
  const eventsByCountry = groupItemsByCountry(newEvents, 'country')
  const opportunitiesByCountry = groupItemsByCountry(newOpportunities, 'basedIn')

  const emailQueue = []
  const pushQueue = []

  // 4. Iterate through each subscriber to build personalized notification payloads.
  for (const user of activeSubscribers) {
    const userCountries = new Set(user.countries || [])
    if (userCountries.size === 0) continue // Skip users with no subscribed countries.

    const userEvents = filterItemsForUser(eventsByCountry, userCountries)
    const userOpportunities = filterItemsForUser(opportunitiesByCountry, userCountries)

    if (userEvents.length === 0 && userOpportunities.length === 0) continue

    // 5. Queue emails for users with email notifications enabled.
    if (user.emailNotificationsEnabled) {
      emailQueue.push({
        user,
        events: userEvents,
        opportunities: userOpportunities,
      })
    }

    // 6. Queue push notifications for users with push enabled and active subscriptions.
    const userPushSubs = pushSubsByUserId[user._id.toString()] || []
    if (user.pushNotificationsEnabled && userPushSubs.length > 0) {
      pushQueue.push({
        subscriptions: userPushSubs,
        events: userEvents,
        opportunities: userOpportunities,
      })
    }
  }

  // 7. Dispatch notifications in bulk.
  const [emailSentCount, pushSentCount] = await Promise.all([
    sendBulkEmails(emailQueue),
    sendBulkPushNotifications(pushQueue),
  ])

  logger.info(
    `‚úÖ Notification dispatch complete. Emails Sent: ${emailSentCount}, Push Notifications Sent: ${pushSentCount}.`
  )
  return { emailSentCount, pushSentCount }
}

// --- Helper Functions ---

function groupItemsByCountry(items, countryField) {
  return items.reduce((acc, item) => {
    const country = item[countryField]
    if (country) {
      if (!acc[country]) acc[country] = []
      acc[country].push(item)
    }
    return acc
  }, {})
}

function filterItemsForUser(itemsByCountry, userCountries) {
  const userItems = []
  for (const country of userCountries) {
    if (itemsByCountry[country]) {
      userItems.push(...itemsByCountry[country])
    }
  }
  return userItems
}


# File: src/modules/notifications/pushService.js
// src/modules/notifications/pushService.js (version 1.0)
import webpush from 'web-push'
import { logger } from '../../utils/logger.js'
import PushSubscription from '../../../models/PushSubscription.js'

const VAPID_SUBJECT = process.env.VAPID_SUBJECT
const VAPID_PUBLIC_KEY = process.env.VAPID_PUBLIC_KEY
const VAPID_PRIVATE_KEY = process.env.VAPID_PRIVATE_KEY

let isPushConfigured = false
if (VAPID_PUBLIC_KEY && VAPID_PRIVATE_KEY && VAPID_SUBJECT) {
  webpush.setVapidDetails(VAPID_SUBJECT, VAPID_PUBLIC_KEY, VAPID_PRIVATE_KEY)
  isPushConfigured = true
} else {
  logger.warn('VAPID keys not configured. Push notifications will be disabled.')
}

function createPushPayload(events, opportunities) {
  let title = 'New Intelligence Alert'
  let body = ''
  let url = '/events' // Default URL

  const eventCount = events.length
  const oppCount = opportunities.length

  if (eventCount > 0 && oppCount > 0) {
    title = `${eventCount} New Event(s), ${oppCount} New Opportunity/ies`
    body = `Primary Event: ${events[0].synthesized_headline}`
    url = `/events`
  } else if (eventCount > 0) {
    title = `${eventCount} New Wealth Event(s) Detected`
    body = events[0].synthesized_headline
    url = `/events`
  } else if (oppCount > 0) {
    title = `${oppCount} New Opportunity/ies Identified`
    body = `New contact: ${opportunities[0].reachOutTo} (~$${opportunities[0].likelyMMDollarWealth}M)`
    url = `/opportunities`
  }

  return {
    title,
    body,
    url,
    icon: '/icons/icon-192x192.png',
  }
}

export async function sendBulkPushNotifications(pushQueue) {
  if (!isPushConfigured || pushQueue.length === 0) {
    return 0
  }

  logger.info(`Dispatching push notifications to ${pushQueue.length} user group(s)...`)
  let successCount = 0

  const allPromises = []

  for (const { subscriptions, events, opportunities } of pushQueue) {
    const payload = createPushPayload(events, opportunities)
    const notificationPayload = JSON.stringify(payload)

    for (const subscription of subscriptions) {
      const pushPromise = webpush
        .sendNotification(subscription, notificationPayload)
        .then(() => {
          successCount++
          logger.info(`‚úÖ Pushed to endpoint for user ${subscription.subscriberId}`)
        })
        .catch((error) => {
          if (error.statusCode === 410 || error.statusCode === 404) {
            logger.info(
              `Subscription expired or invalid for endpoint. Deleting: ${subscription.endpoint}`
            )
            return PushSubscription.deleteOne({ _id: subscription._id })
          } else {
            logger.error(
              { err: { message: error.message, statusCode: error.statusCode } },
              `Failed to send push notification to user ${subscription.subscriberId}`
            )
          }
        })
      allPromises.push(pushPromise)
    }
  }

  await Promise.all(allPromises)
  return successCount
}


# File: src/modules/realtime/index.js
// File: src/modules/realtime/index.js

// src/modules/realtime/index.js (version 2.0)
import Pusher from 'pusher';
import { logger } from '../../utils/logger.js';

const { PUSHER_APP_ID, PUSHER_KEY, PUSHER_SECRET, PUSHER_CLUSTER } = process.env;

let pusher;
const isRealtimeConfigured = PUSHER_APP_ID && PUSHER_KEY && PUSHER_SECRET && PUSHER_CLUSTER;

if (isRealtimeConfigured) {
    pusher = new Pusher({
        appId: PUSHER_APP_ID,
        key: PUSHER_KEY,
        secret: PUSHER_SECRET,
        cluster: PUSHER_CLUSTER,
        useTLS: true
    });
    logger.info('Real-time notification service (Pusher) configured.');
} else {
    logger.warn('Pusher credentials not fully configured. Real-time updates will be disabled.');
}

/**
 * A generic helper to stream a new data item to a specific channel.
 * @param {string} channel - The channel to publish on (e.g., 'articles-channel').
 * @param {string} event - The event name to trigger (e.g., 'new-article').
 * @param {object} data - The JSON payload to send.
 */
async function streamNewItem(channel, event, data) {
    if (!isRealtimeConfigured) {
        return;
    }
    try {
        logger.info(`üì¢ Streaming new item on channel '${channel}' with event '${event}'.`);
        await pusher.trigger(channel, event, data);
    } catch (error) {
        logger.error({ err: error, channel, event }, 'Failed to trigger Pusher real-time event.');
    }
}

/**
 * Streams a newly synthesized event to all connected clients.
 * @param {object} event - The full synthesized event object.
 */
export async function streamNewEvent(event) {
    await streamNewItem('events-channel', 'new-event', event);
}

/**
 * Streams a newly identified relevant article to all connected clients.
 * @param {object} article - The full article object.
 */
export async function streamNewArticle(article) {
    // --- FIX: Create a lightweight payload for Pusher to avoid exceeding the 10KB limit ---
    const lightweightArticle = {
        _id: article._id,
        headline: article.headline,
        headline_en: article.headline_en,
        link: article.link,
        newspaper: article.newspaper,
        country: article.country,
        topic: article.topic,
        relevance_article: article.relevance_article,
        assessment_article: article.assessment_article,
        key_individuals: (article.key_individuals || []).map(p => ({ name: p.name, role_in_event: p.role_in_event, company: p.company })),
        createdAt: article.createdAt,
        updatedAt: article.updatedAt,
    };
    // --- END FIX ---
    await streamNewItem('articles-channel', 'new-article', lightweightArticle);
}

# File: src/modules/scraper/extractor.js
// src/modules/scraper/extractors.js (version 1.0)
// This file contains a registry of custom data extraction functions for specific websites.

const simpleExtractor = (el, site) => {
  const headline = el.text().trim().replace(/\s+/g, ' ')
  const link = el.attr('href')
  if (headline && link) {
    return { headline, link, source: site.name, newspaper: site.newspaper || site.name }
  }
  return null
}

const kapitalWatchExtractor = (el, site) => {
  const headline = el.find('h1').text().trim().replace(/\s+/g, ' ')
  const link = el.attr('href')
  if (headline && link) {
    return { headline, link, source: site.name, newspaper: site.name }
  }
  return null
}

const insideBusinessExtractor = (el, site) => {
  const headlineElement = el.find('h2 a')
  const headline = headlineElement.text().trim().replace(/\s+/g, ' ')
  const link = headlineElement.attr('href')
  if (headline && link) {
    return { headline, link, source: site.name, newspaper: site.newspaper }
  }
  return null
}

const axcelExtractor = (el, site) => ({
  headline: el.find('h3').text().trim(),
  link: el.attr('href'),
  source: site.name,
  newspaper: site.name,
})

const polarisExtractor = (el, site) => {
  const linkEl = el.find('h3.fl-post-feed-title a')
  const headline = linkEl.text().trim()
  const href = linkEl.attr('href')
  if (headline && href) {
    return { headline, link: href, source: site.name, newspaper: site.name }
  }
  return null
}

const majInvestExtractor = (el, site) => {
  const headline = el.find('.news-list-item__title').text().trim()
  const link = el.attr('href')
  if (headline && link) {
    return { headline, link, source: site.name, newspaper: site.name }
  }
  return null
}

const groCapitalExtractor = (el, site) => {
  const headline = el.find('div[class^="heading-"]').text().trim().replace(/\s+/g, ' ')
  const link = el.attr('href')
  if (headline && link) {
    return { headline, link, source: site.name, newspaper: site.name }
  }
  return null
}

const eifoExtractor = (el, site) => {
  const headline = el.find('h4').text().trim()
  const link = el.attr('href')
  if (headline && link) {
    return { headline, link, source: site.name, newspaper: site.newspaper }
  }
  return null
}

const byFoundersExtractor = (el, site) => {
  const companyName = el.find('h3').text().trim()
  const link = el.attr('href')
  if (companyName && link && !companyName.includes('byFounders')) {
    return {
      headline: `byFounders Investment: ${companyName}`,
      link,
      source: site.name,
      newspaper: site.name,
    }
  }
  return null
}

const clearwaterExtractor = (el, site) => {
  const headline = el.find('h3.transaction-list-page__resource-title').text().trim()
  const link = el.attr('href')
  if (headline && link) {
    return { headline, link, source: site.name, newspaper: site.newspaper }
  }
  return null
}

const finansDkExtractor = (el, site) => ({
  headline: el.text().trim(),
  link: el.closest('a').attr('href'),
  source: site.name,
  newspaper: site.name,
})

const politikenExtractor = (el, site) => {
  const h = el.find('h2, h3, h4').first().text().trim()
  const a = el.find('a[href*="/art"]').first().attr('href')
  return h && a ? { headline: h, link: a, source: site.name, newspaper: site.name } : null
}

const e24Extractor = (el, site) => {
  const headlineEl = el.find('h3._mainTitle_qsmm2_16').clone()
  headlineEl.find('style').remove()
  const headline = headlineEl.text().trim()
  const href = el.attr('href')
  if (headline && href) {
    return { headline, link: href, source: site.name, newspaper: site.newspaper }
  }
  return null
}

const fsnCapitalExtractor = (el, site) => {
  const linkEl = el.find('h4.title a')
  return {
    headline: linkEl.text().trim(),
    link: linkEl.attr('href'),
    source: site.name,
    newspaper: site.newspaper,
  }
}

const verdaneExtractor = (el, site) => {
  const linkEl = el.find('a.wp-block-klingit-the-product-block-link')
  const companyName = linkEl.find('h3.wp-block-post-title').text().trim()
  if (companyName) {
    return {
      headline: `Verdane invests in ${companyName}`,
      link: linkEl.attr('href'),
      source: site.name,
      newspaper: site.newspaper,
    }
  }
  return null
}

const quoteNlExtractor = (el, site) => {
  const headline = el.find('h3[data-theme-key="custom-item-title"]').text().trim()
  const link = el.attr('href')
  if (headline && link) {
    return { headline, link, source: site.name, newspaper: site.name }
  }
  return null
}

const deVolkskrantExtractor = (el, site) => {
  const link = el.attr('href')
  const headline = el.find('h3, h4, h2').first().text().trim()
  if (headline && link) {
    return { headline, link, source: site.name, newspaper: site.name }
  }
  return null
}

const algemeenDagbladExtractor = (el, site) => {
  const headline = el.find('div.ankeiler__title').text().trim().replace(/\s+/g, ' ')
  const link = el.attr('href')
  if (headline && link) {
    return { headline, link, source: site.name, newspaper: site.name }
  }
  return null
}

const egeriaExtractor = (el, site) => {
  const headline = el.find('.item-content h3').text().trim()
  const link = el.find('.item-footer a').attr('href')
  if (headline && link) {
    return { headline, link, source: site.name, newspaper: site.name }
  }
  return null
}

const ikPartnersExtractor = (el, site) => ({
  headline: el.find('h3').text().trim(),
  link: el.attr('href'),
  source: site.name,
  newspaper: site.name,
})

const bridgepointExtractor = (el, site) => ({
  headline: el.find('h3').text().trim(),
  link: el.attr('href'),
  source: site.name,
  newspaper: site.name,
})

export const extractorRegistry = {
  simple: simpleExtractor,
  kapitalwatch: kapitalWatchExtractor,
  insidebusiness_ma: insideBusinessExtractor,
  insidebusiness_business: insideBusinessExtractor,
  axcel: axcelExtractor,
  polaris: polarisExtractor,
  maj_invest: majInvestExtractor,
  gro_capital: groCapitalExtractor,
  eifo_dk: eifoExtractor,
  byfounders: byFoundersExtractor,
  clearwater_dk: clearwaterExtractor,
  finans_dk: finansDkExtractor,
  politiken: politikenExtractor,
  e24: e24Extractor,
  fsn_capital: fsnCapitalExtractor,
  verdane: verdaneExtractor,
  quotenet_nl: quoteNlExtractor,
  de_volkskrant: deVolkskrantExtractor,
  trouw_nl: deVolkskrantExtractor, // Reuses de_volkskrant logic
  algemeen_dagblad: algemeenDagbladExtractor,
  egeria: egeriaExtractor,
  ik_partners_news: ikPartnersExtractor,
  bridgepoint_news: bridgepointExtractor,
}


# File: src/modules/scraper/index.js
// src/modules/scraper/index.js (version 3.4)
import * as cheerio from 'cheerio'
import pLimit from 'p-limit'
import playwright from 'playwright'
import { logger } from '../../utils/logger.js'
import { truncateString } from '../../utils/helpers.js'
import { CONCURRENCY_LIMIT, MIN_ARTICLE_CHARS } from '../../config/index.js'
import { extractorRegistry } from './extractors.js'
import Source from '../../../models/Source.js'

const limit = pLimit(CONCURRENCY_LIMIT)

const BROWSER_HEADERS = {
  Accept:
    'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
  'Accept-Encoding': 'gzip, deflate, br',
  'Accept-Language': 'en-US,en;q=0.9',
  'User-Agent':
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36',
}

async function fetchPage(browser, url) {
  let page
  try {
    const context = await browser.newContext({ userAgent: BROWSER_HEADERS['User-Agent'] })
    page = await context.newPage()

    await page.goto(url, { waitUntil: 'domcontentloaded', timeout: 60000 })
    await page.waitForTimeout(2000)

    const consentSelectors = [
      'button:has-text("Accept all")',
      'button:has-text("Godkend alle")',
      'button:has-text("Tillad alle")',
      'button:has-text("Accepteer alles")',
      'button:has-text("I accept")',
    ]

    for (const selector of consentSelectors) {
      try {
        const button = page.locator(selector).first()
        if (await button.isVisible({ timeout: 1000 })) {
          await button.click({ timeout: 2000 })
          logger.debug(`Clicked consent button on ${url}`)
          await page.waitForTimeout(1000)
          break
        }
      } catch (e) {
        /* Ignore */
      }
    }

    await page.evaluate(() => window.scrollBy(0, 500))
    await page.waitForTimeout(500)

    return await page.content()
  } catch (error) {
    logger.error(`[Playwright] Fetch failed for ${url}: ${error.message.split('\n')[0]}`)
    return null
  } finally {
    if (page) await page.close()
  }
}

export async function scrapeSite(browser, source) {
  const selectorUsed =
    source.extractionMethod === 'json-ld' ? 'JSON-LD' : source.headlineSelector
  logger.debug(
    { source: source.name, url: source.sectionUrl, selector: selectorUsed },
    `Scraping initiated...`
  )

  const html = await fetchPage(browser, source.sectionUrl)

  if (!html) return { source: source.name, articles: [], success: false }

  const $ = cheerio.load(html)
  let articles = []

  const extractFunction =
    extractorRegistry[source.extractorKey] || extractorRegistry['simple']

  if (source.extractionMethod === 'json-ld') {
    $('script[type="application/ld+json"]').each((_, el) => {
      try {
        const jsonData = JSON.parse($(el).html())
        const potentialLists = [jsonData, ...(jsonData['@graph'] || [])]
        potentialLists.forEach((list) => {
          const items = list?.itemListElement
          if (items && Array.isArray(items)) {
            items.forEach((item) => {
              const headline = item.name || item.item?.name
              const url = item.url || item.item?.url
              if (headline && url) {
                articles.push({
                  headline: headline.trim(),
                  link: new URL(url, source.sectionUrl).href,
                  source: source.name,
                  newspaper: source.name,
                  country: source.country,
                  headline_selector: selectorUsed,
                })
              }
            })
          }
        })
      } catch (e) {
        /* Ignore parsing errors */
      }
    })
  } else {
    $(source.headlineSelector).each((_, el) => {
      const articleData = extractFunction($(el), {
        name: source.name,
        newspaper: source.name,
      })
      if (articleData && articleData.headline && articleData.link) {
        articleData.link = new URL(articleData.link, source.sectionUrl).href
        articleData.newspaper = source.name
        articleData.country = source.country
        articleData.headline_selector = selectorUsed
        articles.push(articleData)
      }
    })
  }

  const uniqueArticles = Array.from(new Map(articles.map((a) => [a.link, a])).values())
  return { source: source.name, articles: uniqueArticles, success: true }
}

export async function scrapeAllHeadlines() {
  logger.info('üì∞ Fetching active sources from database to begin scraping...')
  const sourcesToScrape = await Source.find({ status: 'active' }).lean()

  if (sourcesToScrape.length === 0) {
    logger.warn('No active sources found in the database. Halting scraping.')
    return { allArticles: [], scraperHealth: [] }
  }

  logger.info(`Pipeline will now scrape ${sourcesToScrape.length} active sources.`)

  const allArticles = []
  const scraperHealth = []

  let browser = null
  try {
    logger.info('[Playwright] Launching shared browser instance for this run...')
    browser = await playwright.chromium.launch()

    const promises = sourcesToScrape.map((source) =>
      limit(async () => {
        const result = await scrapeSite(browser, source)
        if (result.articles.length === 0) {
          logger.warn(`Scraped 0 unique headlines from ${result.source}.`)
        } else {
          logger.info(
            `Scraped ${result.articles.length} unique headlines from ${result.source}.`
          )
        }
        allArticles.push(...result.articles)
        scraperHealth.push({
          source: result.source,
          success: result.articles.length > 0,
          count: result.articles.length,
        })
        await Source.updateOne(
          { _id: source._id },
          {
            $set: {
              lastScrapedAt: new Date(),
              ...(result.success && { lastSuccessAt: new Date() }),
            },
          }
        )
      })
    )
    await Promise.all(promises)
  } catch (error) {
    logger.fatal({ err: error }, 'A critical error occurred during the scraping stage.')
  } finally {
    if (browser) {
      logger.info('[Playwright] Closing shared browser instance.')
      await browser.close()
    }
  }

  logger.info(`Scraping complete. Found a total of ${allArticles.length} headlines.`)
  return { allArticles, scraperHealth }
}

export async function scrapeArticleContent(article, source) {
  let browser = null
  try {
    browser = await playwright.chromium.launch()
    const html = await fetchPage(browser, article.link)
    if (!html) return { ...article, enrichment_error: 'Failed to fetch page' }

    const $ = cheerio.load(html)
    let contentText = ''

    // Image URL Extraction
    if (source && source.imageUrlSelector) {
      let imageUrl = $(source.imageUrlSelector).first().attr('src')
      if (imageUrl) {
        article.imageUrl = new URL(imageUrl, source.baseUrl).href
      }
    }

    // Special Handlers
    if (article.newspaper === 'B√∏rsen') {
      const nextDataScript = $('script[id="__NEXT_DATA__"]').html()
      if (nextDataScript) {
        try {
          const jsonData = JSON.parse(nextDataScript)
          const articleBodyHtml = jsonData?.props?.pageProps?.article?.body
          if (articleBodyHtml) {
            contentText = cheerio.load(articleBodyHtml).text().replace(/\s+/g, ' ').trim()
          }
        } catch (e) {
          /* Ignore */
        }
      }
    }

    if (article.newspaper === 'Finansavisen') {
      const nextDataScript = $('script[id="__NEXT_DATA__"]').html()
      if (nextDataScript) {
        try {
          const jsonData = JSON.parse(nextDataScript)
          contentText = jsonData?.props?.pageProps?.article?.article?.body
            ? cheerio
                .load(jsonData.props.pageProps.article.article.body)
                .text()
                .replace(/\s+/g, ' ')
                .trim()
            : ''
        } catch (e) {
          /* Ignore */
        }
      }
      if (contentText.length < MIN_ARTICLE_CHARS) {
        contentText =
          $('meta[name="description"]').attr('content')?.replace(/\s+/g, ' ').trim() || ''
      }
    }

    // Generic Selector Logic
    if (contentText.length < MIN_ARTICLE_CHARS && source && source.articleSelector) {
      const selectors = source.articleSelector.split(',').map((s) => s.trim())
      for (const selector of selectors) {
        if (selector.startsWith('meta[')) {
          contentText = $(selector).attr('content')?.replace(/\s+/g, ' ').trim() || ''
        } else {
          contentText = $(selector).text().replace(/\s+/g, ' ').trim()
        }
        if (contentText.length >= MIN_ARTICLE_CHARS) {
          break
        }
      }
    }

    if (contentText.length >= MIN_ARTICLE_CHARS) {
      article.articleContent = { contents: [contentText] }
      logger.debug(
        {
          headline: truncateString(article.headline, 40),
          chars: contentText.length,
          imageUrl: article.imageUrl,
          snippet: `${contentText.substring(0, 100)}...`,
        },
        `‚úÖ Enrichment successful.`
      )
    } else {
      article.enrichment_error = 'Content not found or too short'
      logger.warn(
        {
          headline: truncateString(article.headline, 60),
          newspaper: article.newspaper,
          chars: contentText.length,
          selectors_tried: source?.articleSelector || 'N/A',
          link: article.link,
        },
        `‚ùå Enrichment failed.`
      )
    }
    return article
  } finally {
    if (browser) await browser.close()
  }
}


# File: src/pipeline/1_preflight.js
// src/pipeline/1_preflight.js (version 1.1)
import { logger } from '../utils/logger.js'
import { connectDatabase } from '../database.js'
import { performAiSanityCheck, checkModelPermissions } from '../modules/ai/index.js'
import { LLM_MODEL_TRIAGE, LLM_MODEL_ARTICLES } from '../config/index.js'
import { initializeConfig } from '../config/dynamicConfig.js'

/**
 * Stage 1: Performs pre-flight checks, connects to the database, and initializes dynamic config.
 * @param {object} pipelinePayload - The main pipeline payload object.
 * @returns {Promise<{success: boolean, payload: object}>}
 */
export async function runPreFlightChecks(pipelinePayload) {
  logger.info('--- STAGE 1: PRE-FLIGHT ---')

  // AI Sanity Checks
  const requiredModels = [...new Set([LLM_MODEL_TRIAGE, LLM_MODEL_ARTICLES])]
  if (!(await performAiSanityCheck()) || !(await checkModelPermissions(requiredModels))) {
    logger.fatal('AI service checks failed. Aborting pipeline.')
    return { success: false, payload: pipelinePayload }
  }

  // Database Connection
  const isDbConnected = await connectDatabase()
  if (!isDbConnected) {
    logger.fatal('Database connection failed. Aborting pipeline.')
    return { success: false, payload: pipelinePayload }
  }
  pipelinePayload.dbConnection = true

  // Dynamic Configuration Initialization from Database
  await initializeConfig()

  return { success: true, payload: pipelinePayload }
}


# File: src/pipeline/2_scrapeAndFilter.js
// src/pipeline/2_scrapeAndFilter.js (version 1.1 - Add Fresh Headline Logging)
import { logger } from '../utils/logger.js';
import { scrapeAllHeadlines } from '../modules/scraper/index.js';
import { filterFreshArticles } from '../modules/dataStore/index.js';
import mongoose from 'mongoose';
import { generateEmbedding } from '../utils/vectorUtils.js';
import { truncateString } from '../utils/helpers.js';

/**
 * Stage 2: Scrapes all configured sources for headlines and filters out existing ones.
 * @param {object} pipelinePayload - The main pipeline payload object.
 * @returns {Promise<{success: boolean, payload: object}>}
 */
export async function runScrapeAndFilter(pipelinePayload) {
    logger.info('--- STAGE 2: SCRAPE & FILTER ---');
    
    const { allArticles: scrapedHeadlines, scraperHealth } = await scrapeAllHeadlines();
    pipelinePayload.runStats.scraperHealth = scraperHealth;
    pipelinePayload.runStats.headlinesScraped = scrapedHeadlines.length;

    const articlesToProcess = await filterFreshArticles(scrapedHeadlines, pipelinePayload.isRefreshMode);
    pipelinePayload.runStats.freshHeadlinesFound = articlesToProcess.length;

    if (articlesToProcess.length === 0) {
        logger.info('No new or refreshed articles to process. Ending run.');
        return { success: false, payload: pipelinePayload };
    }
    
    // --- NEW: Log a sample of fresh headlines for quality control ---
    const freshHeadlinesSample = articlesToProcess.slice(0, 5).map(a => 
        `  - "${truncateString(a.headline, 70)}" (${a.newspaper})`
    ).join('\n');
    logger.info(`Found ${articlesToProcess.length} fresh articles to process. Sample:\n${freshHeadlinesSample}`);
    // --- END NEW LOGGING ---

    // Prepare articles for the next stage by creating in-memory representations
    const articlesForPipeline = [];
    for (const article of articlesToProcess) {
        const embedding = await generateEmbedding(article.headline);
        articlesForPipeline.push({
            ...article,
            _id: new mongoose.Types.ObjectId(),
            embedding,
            relevance_headline: 0,
            assessment_headline: 'Awaiting assessment',
        });
    }

    pipelinePayload.articlesForPipeline = articlesForPipeline;
    pipelinePayload.assessedCandidates = articlesForPipeline; // Pre-populate for Stage 5

    return { success: true, payload: pipelinePayload };
}

# File: src/pipeline/3_assessAndEnrich.js
// src/pipeline/3_assessAndEnrich.js (version 1.1)
import { logger } from '../utils/logger.js'
import {
  assessHeadlinesInBatches,
  assessArticleContent,
  extractKeyContacts,
  enrichContact,
  generateOpportunitiesFromArticle,
} from '../modules/ai/index.js'
import { synthesizeFromHeadline } from '../modules/ai/eventProcessing.js'
import { scrapeArticleContent } from '../modules/scraper/index.js'
import {
  ARTICLES_RELEVANCE_THRESHOLD,
  HEADLINES_RELEVANCE_THRESHOLD,
} from '../config/index.js'
import { findAlternativeSources } from '../utils/serpapi.js'
import Source from '../../models/Source.js'

const HIGH_SIGNAL_THRESHOLD = 85
const SOURCE_BLACKLIST = ['twitter.com', 'facebook.com', 'linkedin.com']
const MIN_WEALTH_THRESHOLD_MM = 30
const VAGUE_NAME_STOP_WORDS = [
  'the sellers',
  'the founders',
  'shareholders',
  'the owners',
  'management team',
]

// Cache for source documents to reduce DB queries
const sourceCache = new Map()
async function getSource(newspaperName) {
  if (sourceCache.has(newspaperName)) {
    return sourceCache.get(newspaperName)
  }
  const source = await Source.findOne({ name: newspaperName }).lean()
  if (source) {
    sourceCache.set(newspaperName, source)
  }
  return source
}

async function attemptVerificationAndEnrichment(article) {
  logger.info(
    `[Verification Agent] Triggered for high-signal headline (Score: ${article.relevance_headline}).`
  )
  const searchResult = await findAlternativeSources(article.headline)
  if (!searchResult.success || searchResult.results.length === 0) {
    logger.warn(`[Verification Agent] No alternative sources found.`)
    return null
  }
  for (const alternative of searchResult.results) {
    const sourceName =
      typeof alternative.source === 'object' && alternative.source.name
        ? alternative.source.name
        : alternative.source
    if (typeof sourceName !== 'string') continue
    const isBlacklisted = SOURCE_BLACKLIST.some((domain) =>
      alternative.link.includes(domain)
    )
    const isSameSource = article.newspaper && sourceName.includes(article.newspaper)
    if (isBlacklisted || isSameSource) continue

    const alternativeSource = await getSource(sourceName)
    if (!alternativeSource) continue

    const alternativeArticle = {
      ...article,
      link: alternative.link,
      newspaper: sourceName,
      source: sourceName,
    }
    const enrichedAlternative = await scrapeArticleContent(
      alternativeArticle,
      alternativeSource
    )
    if (enrichedAlternative.articleContent) {
      logger.info(
        `[Verification Agent] SUCCESS! Scraped content from new source: ${sourceName}`
      )
      return enrichedAlternative
    }
  }
  logger.warn(
    `[Verification Agent] All filtered alternative sources failed to provide content.`
  )
  return null
}

async function processSingleArticle(article, candidatesMap, runStats) {
  try {
    logger.info(`\n--- [ ENRICHING: "${article.headline}" ] ---`)
    const source = await getSource(article.newspaper)
    if (!source) {
      logger.error(
        `No source configuration found for "${article.newspaper}". Skipping article.`
      )
      return null
    }

    let finalEnrichedArticle = await scrapeArticleContent(article, source)

    if (
      !finalEnrichedArticle.articleContent &&
      article.relevance_headline >= HIGH_SIGNAL_THRESHOLD
    ) {
      const verifiedArticle = await attemptVerificationAndEnrichment(article)
      if (verifiedArticle) finalEnrichedArticle = verifiedArticle
    }

    if (finalEnrichedArticle.articleContent) {
      const finalAssessment = await assessArticleContent(finalEnrichedArticle)
      const originalArticleToUpdate = candidatesMap.get(article._id.toString())
      if (originalArticleToUpdate) {
        Object.assign(originalArticleToUpdate, finalAssessment)
      }

      if (finalAssessment.relevance_article >= ARTICLES_RELEVANCE_THRESHOLD) {
        const initialContactData = await extractKeyContacts(finalAssessment)
        if (initialContactData.key_individuals.length > 0) {
          const enrichedContactPromises = initialContactData.key_individuals.map(
            (contact) => enrichContact(contact, finalAssessment)
          )
          const enrichedContactsArrays = await Promise.all(enrichedContactPromises)
          finalAssessment.key_individuals = enrichedContactsArrays.flat()
        }

        const rawOpportunities = await generateOpportunitiesFromArticle(finalAssessment)
        const validOpportunities = (rawOpportunities || []).filter((opp) => {
          const nameIsValid =
            opp.reachOutTo &&
            !VAGUE_NAME_STOP_WORDS.some((phrase) =>
              opp.reachOutTo.toLowerCase().includes(phrase)
            )
          const wealthIsValid = opp.likelyMMDollarWealth >= MIN_WEALTH_THRESHOLD_MM
          return nameIsValid && wealthIsValid
        })

        logger.info(
          `[Opportunity Agent] Generated ${rawOpportunities.length} raw opportunities, kept ${validOpportunities.length} after filtering.`
        )

        const opportunitiesWithSource = validOpportunities.map((opp) => ({
          ...opp,
          sourceArticleId: finalAssessment._id,
        }))

        runStats.articlesEnriched++
        return { article: finalAssessment, opportunities: opportunitiesWithSource }
      }
    } else {
      logger.warn(`Enrichment failed for "${article.headline}". Attempting to salvage.`)
      const salvagedData = await synthesizeFromHeadline(article)
      if (salvagedData && salvagedData.headline) {
        const promotedArticle = {
          ...article,
          relevance_article: article.relevance_headline,
          assessment_article: salvagedData.summary,
          topic: salvagedData.headline,
          key_individuals: salvagedData.key_individuals || [],
          articleContent: { contents: [salvagedData.summary] },
        }
        logger.info(
          `Salvage successful. Promoting article "${promotedArticle.headline}" for clustering.`
        )
        Object.assign(candidatesMap.get(article._id.toString()), promotedArticle)

        runStats.articlesEnriched++
        return { article: promotedArticle, opportunities: [] }
      }
    }
  } catch (error) {
    logger.error(
      { err: error, article: article.headline },
      'A critical error occurred while processing a single article. Skipping it.'
    )
    return null
  }
  return null
}

export async function runAssessAndEnrich(pipelinePayload) {
  logger.info('--- STAGE 3: ASSESS & ENRICH ---')
  const { articlesForPipeline, runStats } = pipelinePayload

  const assessedCandidates = await assessHeadlinesInBatches(articlesForPipeline)
  runStats.headlinesAssessed = assessedCandidates.length

  const candidatesMap = new Map(assessedCandidates.map((a) => [a._id.toString(), a]))
  const relevantCandidates = assessedCandidates.filter(
    (a) => a.relevance_headline >= HEADLINES_RELEVANCE_THRESHOLD
  )
  runStats.relevantHeadlines = relevantCandidates.length

  // Clear the cache at the start of each enrichment run
  sourceCache.clear()

  if (relevantCandidates.length === 0) {
    logger.info('No headlines were relevant enough for full enrichment.')
    pipelinePayload.assessedCandidates = assessedCandidates
    return { success: false, payload: pipelinePayload }
  }

  const processingPromises = relevantCandidates.map((article) =>
    processSingleArticle(article, candidatesMap, runStats)
  )

  const results = await Promise.allSettled(processingPromises)

  const enrichedArticles = []
  const opportunitiesToSave = []

  results.forEach((result) => {
    if (result.status === 'fulfilled' && result.value) {
      enrichedArticles.push(result.value.article)
      if (result.value.opportunities && result.value.opportunities.length > 0) {
        opportunitiesToSave.push(...result.value.opportunities)
      }
    } else if (result.status === 'rejected') {
      logger.error(
        { reason: result.reason },
        'A promise was rejected during article enrichment.'
      )
    }
  })

  runStats.relevantArticles = enrichedArticles.length

  const fullArticleMap = new Map()
  enrichedArticles.forEach((article) => {
    fullArticleMap.set(article._id.toString(), article)
  })

  pipelinePayload.enrichedArticles = enrichedArticles
  pipelinePayload.fullArticleMap = fullArticleMap
  pipelinePayload.assessedCandidates = Array.from(candidatesMap.values())
  pipelinePayload.opportunitiesToSave = opportunitiesToSave

  const success = enrichedArticles.length > 0
  return { success, payload: pipelinePayload }
}


# File: src/pipeline/4_clusterAndSynthesize.js
// src/pipeline/4_clusterAndSynthesize.js (version 2.1)
import { logger } from '../utils/logger.js'
import {
  clusterArticlesIntoEvents,
  synthesizeEvent,
  extractEntities,
} from '../modules/ai/eventProcessing.js'
import { findSimilarArticles } from '../modules/ai/rag.js'
import SynthesizedEvent from '../../models/SynthesizedEvent.js'
import { fetchWikipediaSummary } from '../utils/wikipedia.js'
import { truncateString } from '../utils/helpers.js'

export async function runClusterAndSynthesize(pipelinePayload) {
  logger.info('--- STAGE 4: CLUSTER & SYNTHESIZE ---')
  const {
    enrichedArticles,
    fullArticleMap,
    runStats,
    synthesizedEventsToSave = [],
  } = pipelinePayload

  if (!enrichedArticles || enrichedArticles.length === 0) {
    logger.info(
      'No relevant articles were enriched, skipping cluster and synthesis stage.'
    )
    pipelinePayload.synthesizedEventsToSave = synthesizedEventsToSave
    return { success: true, payload: pipelinePayload }
  }

  const articlesForClustering = enrichedArticles.map((a) => ({
    _id: a._id.toString(),
    headline: a.headline,
    source: a.newspaper,
    summary: a.topic || a.assessment_article,
  }))

  const eventClusters = await clusterArticlesIntoEvents(articlesForClustering)
  runStats.eventsClustered = eventClusters.length

  if (eventClusters.length === 0) {
    logger.info('No unique events were clustered from the relevant articles.')
    pipelinePayload.synthesizedEventsToSave = synthesizedEventsToSave
    return { success: false, payload: pipelinePayload }
  }
  logger.info(
    `Clustered ${enrichedArticles.length} articles into ${eventClusters.length} unique events.`
  )

  for (const [index, cluster] of eventClusters.entries()) {
    const articlesInCluster = cluster.article_ids
      .map((id) => fullArticleMap.get(id))
      .filter(Boolean)
    if (articlesInCluster.length === 0) continue

    const primaryHeadline = articlesInCluster[0]?.headline || cluster.event_key
    logger.info(
      `\n--- [ Synthesizing Event ${index + 1} of ${eventClusters.length}: "${truncateString(primaryHeadline, 70)}" ] ---`
    )

    const uniqueArticlesInCluster = Array.from(
      new Map(articlesInCluster.map((a) => [a.link, a])).values()
    )

    const combinedTextForEntityExtraction = uniqueArticlesInCluster
      .map((a) => {
        const contentSnippet = (a.articleContent?.contents || [])
          .join(' ')
          .substring(0, 1500)
        return `${a.headline}\n${a.assessment_article}\n${contentSnippet}`
      })
      .join('\n\n')

    const entities = await extractEntities(combinedTextForEntityExtraction)

    let wikipediaContext = 'Not available.'
    if (entities.length > 0) {
      logger.info(
        `[Query Planner Agent] Decided to query Wikipedia for: [${entities.join(', ')}]`
      )
      const wikiPromises = entities.map((e) => fetchWikipediaSummary(e))
      const wikiResults = await Promise.all(wikiPromises)
      const summaries = wikiResults.filter((r) => r.success).map((r) => r.summary)
      if (summaries.length > 0) {
        wikipediaContext = summaries.join('\n---\n')
      } else {
        logger.warn(
          'Query Planner identified entities, but no Wikipedia summaries could be fetched.'
        )
      }
    } else {
      logger.info(
        'Query Planner Agent found no high-value entities for Wikipedia lookup.'
      )
    }

    const historicalContext = await findSimilarArticles(uniqueArticlesInCluster)

    const payloadForLogging = {
      todays_articles: uniqueArticlesInCluster.map((a) => ({
        headline: a.headline,
        content_snippet: `${(a.articleContent?.contents?.join(' ') || '[NO CONTENT]').substring(0, 100)}...`,
      })),
      historical_articles_found: historicalContext.length,
      wikipedia_context_chars: wikipediaContext.length,
    }
    logger.info(payloadForLogging, 'Preparing payload for Synthesis Agent...')

    const synthesizedData = await synthesizeEvent(
      uniqueArticlesInCluster,
      historicalContext,
      wikipediaContext
    )

    if (synthesizedData && !synthesizedData.error) {
      runStats.eventsSynthesized++
      const highestScoringArticle = uniqueArticlesInCluster.reduce(
        (max, current) =>
          current.relevance_article > max.relevance_article ? current : max,
        uniqueArticlesInCluster[0]
      )

      const eventToSave = new SynthesizedEvent({
        event_key: cluster.event_key,
        synthesized_headline: synthesizedData.headline,
        synthesized_summary: synthesizedData.summary,
        ai_assessment_reason:
          highestScoringArticle.assessment_article ||
          highestScoringArticle.assessment_headline,
        country: highestScoringArticle.country,
        highest_relevance_score: Math.max(
          ...uniqueArticlesInCluster.map((a) => a.relevance_article)
        ),
        key_individuals: synthesizedData.key_individuals || [],
        // MODIFIED: Include imageUrl in the source article data
        source_articles: uniqueArticlesInCluster.map((a) => ({
          headline: a.headline,
          link: a.link,
          newspaper: a.newspaper,
          imageUrl: a.imageUrl,
        })),
      })
      synthesizedEventsToSave.push(eventToSave)
      runStats.synthesizedEventsForReport.push({
        synthesized_headline: eventToSave.synthesized_headline,
        highest_relevance_score: eventToSave.highest_relevance_score,
      })
    }
  }

  pipelinePayload.synthesizedEventsToSave = synthesizedEventsToSave

  return { success: true, payload: pipelinePayload }
}


# File: src/pipeline/5_commitAndNotify.js
// src/pipeline/5_commitAndNotify.js (version 4.1)
import { logger } from '../utils/logger.js'
import { savePipelineResults } from '../modules/dataStore/index.js'
import { sendSupervisorReportEmail } from '../modules/email/index.js'
import { streamNewEvent, streamNewArticle } from '../modules/realtime/index.js'
import SynthesizedEvent from '../../models/SynthesizedEvent.js'
import Opportunity from '../../models/Opportunity.js'
import { ARTICLES_RELEVANCE_THRESHOLD } from '../config/index.js'
import { sendNotifications } from '../modules/notifications/index.js'

/**
 * Stage 5: Commits all results to the database and sends notifications.
 * @param {object} pipelinePayload - The main pipeline payload object.
 * @returns {Promise<{success: boolean, payload: object}>}
 */
export async function runCommitAndNotify(pipelinePayload) {
  logger.info('--- STAGE 5: COMMIT & NOTIFY ---')
  const {
    assessedCandidates,
    synthesizedEventsToSave,
    opportunitiesToSave,
    runStats,
    dbConnection,
  } = pipelinePayload

  let savedEvents = []
  let savedOpportunities = []

  if (dbConnection && (!runStats.errors || runStats.errors.length === 0)) {
    // --- DATABASE COMMIT PHASE ---
    const commitResult = await savePipelineResults(
      assessedCandidates,
      synthesizedEventsToSave || []
    )

    if (commitResult.success) {
      savedEvents = commitResult.savedEvents

      // --- UPSERT and LINK opportunities ---
      if (
        opportunitiesToSave &&
        opportunitiesToSave.length > 0 &&
        savedEvents.length > 0
      ) {
        logger.info('Upserting and linking opportunities...')
        const articleToEventMap = new Map()
        savedEvents.forEach((event) => {
          ;(event.source_articles || []).forEach((article) => {
            articleToEventMap.set(article.link, event._id)
          })
        })

        const articleIdToLinkMap = new Map()
        ;(assessedCandidates || []).forEach((article) => {
          articleIdToLinkMap.set(article._id.toString(), article.link)
        })

        const ops = opportunitiesToSave
          .map((opp) => {
            const articleLink = articleIdToLinkMap.get(opp.sourceArticleId.toString())
            const eventId = articleToEventMap.get(articleLink)
            if (!eventId) {
              logger.warn(
                { opp },
                'Could not find parent event for opportunity. Skipping event link.'
              )
              return null // Skip this operation
            }

            const updatePayload = {
              $set: {
                contactDetails: opp.contactDetails,
                basedIn: opp.basedIn,
                sourceArticleId: opp.sourceArticleId,
                sourceEventId: eventId,
              },
              $push: { whyContact: { $each: [opp.whyContact].flat(), $position: 0 } },
              $max: { likelyMMDollarWealth: opp.likelyMMDollarWealth },
            }

            return {
              updateOne: {
                filter: { reachOutTo: opp.reachOutTo },
                update: updatePayload,
                upsert: true,
              },
            }
          })
          .filter(Boolean) // Filter out null operations

        if (ops.length > 0) {
          try {
            const result = await Opportunity.bulkWrite(ops)
            const opportunityNames = opportunitiesToSave.map((o) => o.reachOutTo)
            savedOpportunities = await Opportunity.find({
              reachOutTo: { $in: opportunityNames },
            })
              .populate('sourceArticleId', 'link')
              .lean()
            logger.info(
              `Opportunities processed. Created: ${result.upsertedCount}, Updated: ${result.modifiedCount}.`
            )
          } catch (error) {
            logger.error({ err: error }, 'Failed to save/update opportunities.')
          }
        }
      }

      // --- REALTIME STREAMING PHASE ---
      if (savedEvents.length > 0) {
        for (const event of savedEvents) await streamNewEvent(event)
      }
      if (assessedCandidates && assessedCandidates.length > 0) {
        const relevantArticles = assessedCandidates.filter(
          (article) =>
            article.relevance_article &&
            article.relevance_article >= ARTICLES_RELEVANCE_THRESHOLD
        )
        for (const article of relevantArticles) await streamNewArticle(article)
      }

      // --- PERSONALIZED NOTIFICATION PHASE ---
      if (savedEvents.length > 0 || savedOpportunities.length > 0) {
        const { emailSentCount, pushSentCount } = await sendNotifications(
          savedEvents,
          savedOpportunities
        )
        runStats.eventsEmailed = emailSentCount // Keep this stat for supervisor report consistency

        if (emailSentCount > 0) {
          const eventIds = savedEvents.map((e) => e._id)
          await SynthesizedEvent.updateMany(
            { _id: { $in: eventIds } },
            { $set: { emailed: true, email_sent_at: new Date() } }
          )
        }
      }
    } else {
      runStats.errors.push('CRITICAL: Failed to commit pipeline results.')
    }
  }

  // --- SUPERVISOR REPORT PHASE ---
  await sendSupervisorReportEmail(runStats)

  return { success: true, payload: pipelinePayload }
}


# File: src/utils/helpers.js
// src/utils/helpers.js (version 1.0)
import { logger } from './logger.js';

/**
 * Truncates a string to a specified length, adding an ellipsis if truncated.
 * @param {string} str The string to truncate.
 * @param {number} maxLength The maximum length of the string.
 * @returns {string} The truncated string.
 */
export function truncateString(str, maxLength = 100) {
    if (typeof str !== 'string' || str.length <= maxLength) {
        return str;
    }
    return str.substring(0, maxLength) + '...';
}

/**
 * Executes an async function and handles errors gracefully.
 * @param {() => Promise<any>} asyncFn The async function to execute.
 * @param {{errorHandler: (error: Error) => any}} options Error handling options.
 * @returns {Promise<any>} The result of the function or the error handler.
 */
export async function safeExecute(asyncFn, { errorHandler } = {}) {
    try {
        return await asyncFn();
    } catch (error) {
        if (errorHandler) {
            return errorHandler(error);
        }
        logger.error({ err: error }, 'An unexpected error occurred in a safeExecute block.');
        return null; // Default fallback
    }
}

# File: src/utils/logger.js
// src/utils/logger.js
import pino from 'pino';
import { LOG_LEVEL, IS_PRODUCTION } from '../config/index.js';

const pinoConfig = {
    level: LOG_LEVEL || 'info',
    // More concise logging by default, removing pid and hostname
    base: undefined, 
};

if (!IS_PRODUCTION) {
    pinoConfig.transport = {
        target: 'pino-pretty',
        options: {
            colorize: true,
            translateTime: 'HH:MM:ss',
            ignore: 'pid,hostname,runStats', // MODIFIED: Ignore the verbose runStats object in console output
        },
    };
}

export const logger = pino(pinoConfig);

# File: src/utils/pipelineLogger.js
// File: src/utils/pipelineLogger.js
// src/utils/pipelineLogger.js (version 2.1 - Cleaner Report)
import { logger } from './logger.js'
import Article from '../../models/Article.js'
import SynthesizedEvent from '../../models/SynthesizedEvent.js'
import { truncateString } from './helpers.js'
import { disconnectDatabase } from '../database.js'
import {
  ARTICLES_RELEVANCE_THRESHOLD,
  HEADLINES_RELEVANCE_THRESHOLD,
} from '../config/index.js'
// REMOVED: import { USERS } from '../config/users.js';
import Subscriber from '../../models/Subscriber.js' // ADDED
import { COUNTRIES_CONFIG } from '../config/sources.js'

// --- Console Colors for Readability ---
const colors = {
  reset: '\x1b[0m',
  red: '\x1b[31m',
  green: '\x1b[32m',
  yellow: '\x1b[33m',
  cyan: '\x1b[36m',
  magenta: '\x1b[35m',
  grey: '\x1b[90m',
}

/**
 * Truncates long source names for cleaner display in the final report.
 * @param {string} name The full newspaper name.
 * @returns {string} The truncated name.
 */
function truncateSourceName(name) {
  if (!name) return 'N/A'
  const stopChars = ['(', '-']
  let stopIndex = name.length
  for (const char of stopChars) {
    const index = name.indexOf(char)
    if (index !== -1 && index < stopIndex) {
      stopIndex = index
    }
  }
  return name.substring(0, stopIndex).trim()
}

/**
 * Fetches and calculates comprehensive statistics from the database.
 * @returns {Promise<Object>} An object containing various database stats.
 */
async function getDatabaseStats() {
  try {
    const [totalArticles, totalEvents, topRelevantSelectors, allSourceStats] =
      await Promise.all([
        Article.countDocuments(),
        SynthesizedEvent.countDocuments(),
        Article.aggregate([
          { $match: { relevance_article: { $gte: ARTICLES_RELEVANCE_THRESHOLD } } },
          {
            $group: {
              _id: { newspaper: '$newspaper', selector: '$headline_selector' },
              count: { $sum: 1 },
            },
          },
          { $sort: { count: -1 } },
          { $limit: 15 },
        ]),
        // REVISED: This aggregation now uses relevance_headline for a more accurate 'hit rate'.
        Article.aggregate([
          {
            $group: {
              _id: '$newspaper',
              totalCount: { $sum: 1 },
              relevantCount: {
                $sum: {
                  $cond: [
                    { $gte: ['$relevance_headline', HEADLINES_RELEVANCE_THRESHOLD] },
                    1,
                    0,
                  ],
                },
              },
            },
          },
          { $sort: { totalCount: -1 } },
        ]),
      ])

    return {
      totalArticles,
      totalEvents,
      allSourceStats,
      topRelevantSelectors,
    }
  } catch (error) {
    logger.error({ err: error }, 'Failed to fetch database statistics.')
    return null
  }
}

/**
 * The main function to log the final, comprehensive report for a pipeline run.
 * @param {Object} runStats - The statistics collected during the pipeline run.
 * @param {number} duration - The duration of the pipeline run in seconds.
 */
export async function logFinalReport(runStats, duration) {
  const dbStats = await getDatabaseStats()

  let report = `\n\n${colors.cyan}=============================================================${colors.reset}\n`
  report += `${colors.cyan} üöÄ PIPELINE RUN SUMMARY${colors.reset}\n`
  report += `${colors.cyan}=============================================================${colors.reset}\n\n`
  report += `  ${colors.magenta}Duration:${colors.reset} ${duration} seconds\n\n`

  // --- Current Run Funnel ---
  report += `  ${colors.yellow}--- Funnel (This Run) ---${colors.reset}\n`
  report += `  ${'Headlines Scraped:'.padEnd(25)} ${runStats.headlinesScraped}\n`
  report += `  ${'Fresh/Refreshed Articles:'.padEnd(25)} ${runStats.freshHeadlinesFound}\n`
  report += `  ${'Headlines Assessed:'.padEnd(25)} ${runStats.headlinesAssessed}\n`
  report += `  ${'  > Relevant (>=20):'.padEnd(25)} ${runStats.relevantHeadlines}\n`
  report += `  ${'Articles Enriched:'.padEnd(25)} ${runStats.articlesEnriched}\n`
  report += `  ${'  > Relevant (>=50):'.padEnd(25)} ${runStats.relevantArticles}\n`
  report += `  ${'Events Clustered:'.padEnd(25)} ${runStats.eventsClustered}\n`
  report += `  ${'Events Synthesized:'.padEnd(25)} ${runStats.eventsSynthesized}\n`
  report += `  ${colors.green}${'Events Emailed:'.padEnd(25)} ${runStats.eventsEmailed}${colors.reset}\n`
  if (runStats.errors && runStats.errors.length > 0) {
    report += `  ${colors.red}${'Errors Encountered:'.padEnd(25)} ${runStats.errors.length}${colors.reset}\n`
  }
  report += '\n'

  // --- Top Synthesized Events from this Run ---
  if (
    runStats.synthesizedEventsForReport &&
    runStats.synthesizedEventsForReport.length > 0
  ) {
    report += `  ${colors.yellow}--- Top Synthesized Events (This Run) ---${colors.reset}\n`
    runStats.synthesizedEventsForReport.slice(0, 5).forEach((event) => {
      report += `  ${colors.green}[${String(event.highest_relevance_score).padStart(3)}]${colors.reset} "${truncateString(event.synthesized_headline, 70)}"\n`
    })
    report += '\n'
  }

  // --- Database Statistics ---
  if (dbStats) {
    report += `  ${colors.yellow}--- Database Statistics (Overall) ---${colors.reset}\n`
    report += `  ${'Total Articles:'.padEnd(25)} ${dbStats.totalArticles}\n`
    report += `  ${'Total Synthesized Events:'.padEnd(25)} ${dbStats.totalEvents}\n\n`

    // --- Struggling Sources Report ---
    // MODIFIED: Fetch active subscriber countries from the database
    const activeSubscribers = await Subscriber.find({ isActive: true })
      .select('countries')
      .lean()
    const subscribedCountries = new Set(activeSubscribers.flatMap((s) => s.countries))
    // END MODIFICATION

    const subscribedNewspapers = new Set()
    COUNTRIES_CONFIG.forEach((country) => {
      if (subscribedCountries.has(country.countryName)) {
        country.sites.forEach((site) =>
          subscribedNewspapers.add(site.newspaper || site.name)
        )
      }
    })

    const strugglingSources = new Map()

    // Check 1: Scraped 0 headlines in this run
    runStats.scraperHealth.forEach((health) => {
      if (health.count === 0 && subscribedNewspapers.has(health.source)) {
        if (!strugglingSources.has(health.source))
          strugglingSources.set(health.source, [])
        strugglingSources.get(health.source).push('Scraped 0 headlines this run')
      }
    })

    // Check 2: Failed enrichment in this run
    const enrichmentFailures = new Map()
    runStats.enrichmentOutcomes.forEach((outcome) => {
      if (
        outcome.outcome === 'Dropped' &&
        outcome.assessment_article.includes('Enrichment Failed')
      ) {
        enrichmentFailures.set(
          outcome.newspaper,
          (enrichmentFailures.get(outcome.newspaper) || 0) + 1
        )
      }
    })
    enrichmentFailures.forEach((count, newspaper) => {
      if (subscribedNewspapers.has(newspaper)) {
        if (!strugglingSources.has(newspaper)) strugglingSources.set(newspaper, [])
        strugglingSources
          .get(newspaper)
          .push(`Had ${count} enrichment failure(s) this run`)
      }
    })

    // Check 3: Low relevance hit-rate from database history
    dbStats.allSourceStats.forEach((source) => {
      const relevancePercentage =
        source.totalCount > 0 ? (source.relevantCount / source.totalCount) * 100 : 0
      if (
        source.totalCount > 20 &&
        relevancePercentage < 1 &&
        subscribedNewspapers.has(source._id)
      ) {
        if (!strugglingSources.has(source._id)) strugglingSources.set(source._id, [])
        strugglingSources
          .get(source._id)
          .push(`Low lead rate (<1%): ${source.relevantCount}/${source.totalCount} leads`)
      }
    })

    report += `  ${colors.magenta}Struggling Sources (for subscribed countries):${colors.reset}\n`
    if (strugglingSources.size > 0) {
      strugglingSources.forEach((reasons, source) => {
        const sourceStr = `  - ${truncateSourceName(source)}:`.padEnd(25)
        report += `  ${colors.red}${sourceStr}${reasons.join(', ')}${colors.reset}\n`
      })
    } else {
      report += `  ${colors.green}  No struggling sources identified.${colors.reset}\n`
    }
    report += '\n'

    if (dbStats.topRelevantSelectors && dbStats.topRelevantSelectors.length > 0) {
      report += `  ${colors.magenta}Top Sources for Relevant Articles (Score >= ${ARTICLES_RELEVANCE_THRESHOLD}):${colors.reset}\n`
      dbStats.topRelevantSelectors.forEach((item) => {
        const countStr = `[${item.count}]`.padEnd(6)
        const sourceStr = `${item._id.newspaper}`.padEnd(35)
        // --- FIX: Add fallback for undefined selectors ---
        const selectorStr = item._id.selector || 'JSON-LD / Manual'
        report += `  ${countStr}${sourceStr} > ${colors.grey}${selectorStr}${colors.reset}\n`
      })
      report += '\n'
    }

    const top10Sources = dbStats.allSourceStats.slice(0, 10)
    report += `  ${colors.magenta}Top 10 Article Sources (All Time):${colors.reset}\n`
    top10Sources.forEach((source) => {
      const truncatedName = truncateSourceName(source._id)
      const totalCount = `${source.totalCount} articles`.padEnd(16)
      report += `  ${`  ${truncatedName}:`.padEnd(25)} ${totalCount} (of which ${source.relevantCount} were relevant leads)\n`
    })
  }

  report += `\n${colors.cyan}=============================================================${colors.reset}\n`

  logger.info(report)

  await disconnectDatabase()
}


# File: src/utils/serpapi.js
// File: src/utils/serpapi.js

// src/utils/serpapi.js (version 3.0)
import { getJson } from 'serpapi'
import { SERPAPI_API_KEY } from '../config/index.js'
import { logger } from './logger.js'
import { truncateString } from './helpers.js'

if (!SERPAPI_API_KEY) {
  logger.warn(
    'SERPAPI_API_KEY not found in .env. The verification and enrichment agents will be disabled.'
  )
}

/**
 * Searches Google News for alternative articles based on a headline.
 * @param {string} headline - The headline to use as a search query.
 * @returns {Promise<{success: boolean, results: Array<{title: string, link: string, source: object | string}>}>}
 */
export async function findAlternativeSources(headline) {
  if (!SERPAPI_API_KEY) return { success: false, results: [] }
  try {
    const response = await getJson({
      engine: 'google_news',
      q: headline,
      api_key: SERPAPI_API_KEY,
    })
    if (response.error) {
      // --- FIX: If the error is just "no results", it's a warning, not a critical error.
      if (response.error.includes("Google News hasn't returned any results")) {
        logger.warn(
          `[SERPAPI] No Google News results found for query: "${truncateString(headline, 60)}"`
        )
        return { success: false, results: [] }
      }
      throw new Error(response.error)
    }
    if (response.news_results && response.news_results.length > 0) {
      return {
        success: true,
        results: response.news_results.map((res) => ({
          title: res.title,
          link: res.link,
          source: res.source,
        })),
      }
    }
    return { success: false, results: [] }
  } catch (error) {
    logger.error({ err: error }, 'A critical SERPAPI news search failed.')
    return { success: false, results: [] }
  }
}

/**
 * Performs a general Google search for contact enrichment research.
 * @param {string} query - The research query (e.g., "founders of Eliantie").
 * @returns {Promise<{success: boolean, snippets: string}>} A string of concatenated search result snippets.
 */
export async function performGoogleSearch(query) {
  if (!SERPAPI_API_KEY)
    return { success: false, snippets: 'SERPAPI_API_KEY not configured.' }
  try {
    logger.info(`[Research Agent] Executing Google search for: "${query}"`)
    const response = await getJson({
      engine: 'google',
      q: query,
      api_key: SERPAPI_API_KEY,
    })
    if (response.error) throw new Error(response.error)

    const organicResults = response.organic_results || []
    if (organicResults.length > 0) {
      const snippets = organicResults
        .slice(0, 5) // Use top 5 results
        .map((res) => `- ${res.title}: ${res.snippet}`)
        .join('\n')
      logger.info(
        `[Research Agent] Found ${organicResults.length} results. Synthesizing snippets for AI analysis.`
      )
      return { success: true, snippets }
    }
    logger.warn(`[Research Agent] No organic Google results found for query: "${query}"`)
    return { success: false, snippets: 'No search results found.' }
  } catch (error) {
    logger.error({ err: error }, 'SERPAPI general search failed.')
    return { success: false, snippets: `Search failed: ${error.message}` }
  }
}


# File: src/utils/vectorUtils.js
// src/utils/vectorUtils.js
import { pipeline } from '@xenova/transformers';

// Use a singleton pattern to ensure we only load the model once.
class EmbeddingPipeline {
    static task = 'feature-extraction';
    static model = 'Xenova/all-MiniLM-L6-v2';
    static instance = null;

    static async getInstance(progress_callback = null) {
        if (this.instance === null) {
            this.instance = pipeline(this.task, this.model, { progress_callback });
        }
        return this.instance;
    }
}

/**
 * Generates an embedding for a given text.
 * @param {string} text The text to embed.
 * @returns {Promise<Array<number>>} A promise that resolves to the embedding vector.
 */
export async function generateEmbedding(text) {
    const extractor = await EmbeddingPipeline.getInstance();
    const output = await extractor(text, { pooling: 'mean', normalize: true });
    return Array.from(output.data);
}

/**
 * Calculates the cosine similarity between two vectors.
 * @param {Array<number>} vecA The first vector.
 * @param {Array<number>} vecB The second vector.
 * @returns {number} The cosine similarity score (between -1 and 1).
 */
export function cosineSimilarity(vecA, vecB) {
    let dotProduct = 0.0;
    let normA = 0.0;
    let normB = 0.0;
    for (let i = 0; i < vecA.length; i++) {
        dotProduct += vecA[i] * vecB[i];
        normA += vecA[i] * vecA[i];
        normB += vecB[i] * vecB[i];
    }
    return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}

# File: src/utils/wikipedia.js
// src/utils/wikipedia.js (version 3.1 - Hardened Disambiguation)
import { logger } from './logger.js';
import client from '../modules/ai/client.js'; // Use the central AI client
import { LLM_MODEL } from '../config/index.js';

const WIKI_API_ENDPOINT = "https://en.wikipedia.org/w/api.php";
const WIKI_SUMMARY_LENGTH = 750;
const DISAMBIGUATION_MODEL = LLM_MODEL;

// --- REVISED: Hardened Domain-Constrained Disambiguation Prompt ---
const DISAMBIGUATION_PROMPT = `You are a Wikipedia search disambiguation agent for a wealth management firm. Your task is to find the most relevant Wikipedia page title from a list of search results that matches the "Original Query".

**CRITICAL Instructions:**
1.  Your focus is exclusively on **wealth management intelligence**.
2.  Analyze the "Original Query" to understand the user's intent, which will be a person, company, or financial entity.
3.  Review the "Search Results" and their snippets (descriptions).
4.  Choose the title that is the most direct and relevant match for an **individual, company, private equity firm, or major financial transaction.**
5.  You are FORBIDDEN from choosing a page if its snippet clearly indicates it is a **song, film, video game, fictional character, fashion brand, or generic concept.** For example, for the query "Chrome", you must not select "Chrome Hearts" (a fashion brand).
6.  If no result is a good match for a financial or corporate entity, you MUST respond with "null".

Respond ONLY with a valid JSON object: { "best_title": "The Most Relevant Page Title" | null }`;

/**
 * Uses a multi-step, AI-powered process to find the correct Wikipedia page and fetch its summary.
 * @param {string} query - The search term (e.g., a person or company name).
 * @returns {Promise<{success: boolean, summary?: string, error?: string}>}
 */
export async function fetchWikipediaSummary(query) {
    if (!query) return { success: false, error: "Query cannot be empty." };
    try {
        // Step 1: Search for potential pages
        const searchParams = new URLSearchParams({ action: "query", list: "search", srsearch: query, srlimit: "5", format: "json" });
        logger.info(`Querying Wikipedia for: "${query}"`);
        const searchResponse = await fetch(`${WIKI_API_ENDPOINT}?${searchParams.toString()}`);
        if (!searchResponse.ok) throw new Error(`Search API returned status ${searchResponse.status}`);
        const searchData = await searchResponse.json();
        const searchResults = searchData.query.search;
        if (!searchResults || searchResults.length === 0) throw new Error(`No search results found for query "${query}".`);

        // Step 2: Use an AI agent to disambiguate
        const disambiguationResponse = await client.chat.completions.create({
            model: DISAMBIGUATION_MODEL,
            messages: [
                { role: 'system', content: DISAMBIGUATION_PROMPT },
                { role: 'user', content: `Original Query: "${query}"\n\nSearch Results:\n${JSON.stringify(searchResults.map(r => ({title: r.title, snippet: r.snippet})))}` }
            ],
            response_format: { type: 'json_object' },
        });
        const { best_title } = JSON.parse(disambiguationResponse.choices[0].message.content);
        
        if (!best_title) throw new Error(`AI agent could not disambiguate a relevant page for "${query}".`);
        
        const queryWords = new Set(query.toLowerCase().split(' '));
        const titleWords = new Set(best_title.toLowerCase().split(' '));
        const intersection = new Set([...queryWords].filter(word => titleWords.has(word)));
        if (intersection.size === 0) {
            throw new Error(`Rejected irrelevant AI choice: "${best_title}" has no overlap with original query "${query}".`);
        }

        logger.info(`[Disambiguation Agent] Chose best page title: "${best_title}"`);

        // Step 3: Fetch the summary for the verified page title
        const summaryParams = new URLSearchParams({ action: "query", prop: "extracts", exintro: "true", explaintext: "true", titles: best_title, format: "json", redirects: "1" });
        const summaryResponse = await fetch(`${WIKI_API_ENDPOINT}?${summaryParams.toString()}`);
        if (!summaryResponse.ok) throw new Error(`Summary API returned status ${summaryResponse.status}`);
        const summaryData = await summaryResponse.json();
        const pages = summaryData.query.pages;
        const pageId = Object.keys(pages)[0];
        if (!pages[pageId] || pages[pageId].missing) throw new Error(`Page "${best_title}" does not exist.`);
        const summary = pages[pageId].extract;
        if (!summary) throw new Error(`Could not extract summary for page "${best_title}".`);
        
        const conciseSummary = summary.length > WIKI_SUMMARY_LENGTH ? summary.substring(0, WIKI_SUMMARY_LENGTH) + '...' : summary;
        logger.info(`Successfully fetched and summarized Wikipedia content for "${best_title}".`);
        return { success: true, summary: conciseSummary };

    } catch (error) {
        logger.warn(`Wikipedia lookup for "${query}" failed: ${error.message}`);
        return { success: false, error: error.message };
    }
}
