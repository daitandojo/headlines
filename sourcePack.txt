
# File: .claude/settings.local.json
{
  "permissions": {
    "allow": [
      "Bash(rm:*)"
    ],
    "deny": []
  }
}

# File: .dockerignore
# File: .dockerignore (version 1.01)
/.git
/node_modules
.dockerignore
.env

# Explicitly include package-lock.json to ensure it's in the build context,
# overriding any other potential ignore rules.
!package-lock.json

# File: .env.template
      
# .env.template
# This file provides a template for the required environment variables.
# Copy this file to .env and fill in your actual values.
# DO NOT COMMIT THE .env FILE TO VERSION CONTROL.

# --- Core Application Behavior ---
NODE_ENV=development # 'development' or 'production'
LOG_LEVEL=debug      # 'debug', 'info', 'warn', 'error'
CONCURRENCY_LIMIT=3  # Number of parallel network operations (scraping, AI calls)
FORCE_EMAIL_SEND_DEV=true # Set to 'true' to force emails to be sent even if NODE_ENV is 'development'

# --- MongoDB Configuration ---
MONGO_URI="mongodb+srv://user:password@cluster.mongodb.net/database?retryWrites=true&w=majority"

# --- AI API Configuration ---
OPENAI_API_KEY=sk-proj-....
# The model to be used for all AI tasks (triage, analysis, synthesis).
# The officially supported identifier
LLM_MODEL="gpt-5-mini"

# --- Email Sending Configuration (via Nodemailer) ---
SMTP_HOST=smtp.gmail.com
SMTP_PORT=465
SMTP_SECURE=true # true for 465, false for other ports
SMTP_USER="your-email@gmail.com"
SMTP_PASS="your-app-password" # Use an App Password for Gmail
SMTP_FROM_ADDRESS="your-email@gmail.com"
SMTP_FROM_NAME="Wealth Events Bot"

# --- Email Recipients ---
# All user and supervisor email recipients are now managed in ./src/config/users.js
# No environment variables are needed for recipients.

    

# File: .github/workflows/fly-deploy.yml
# See https://fly.io/docs/app-guides/continuous-deployment-with-github-actions/

name: Fly Deploy
on:
  push:
    branches:
      - main
jobs:
  deploy:
    name: Deploy app
    runs-on: ubuntu-latest
    concurrency: deploy-group
    steps:
      - uses: actions/checkout@v4
      
      # Step 1: Install flyctl using the official installer.
      - name: Install flyctl
        run: |
          curl -L https://fly.io/install.sh | sh
          # Step 2: Add flyctl to the PATH for subsequent steps.
          # This is the officially recommended and robust method.
          echo "/home/runner/.fly/bin" >> $GITHUB_PATH

      - name: Deploy to Fly.io
        # Now 'flyctl' can be called directly because its location is in the PATH.
        run: flyctl deploy --remote-only
        env:
          FLY_API_TOKEN: ${{ secrets.FLY_API_TOKEN }}

# File: .github/workflows/run-pipeline.yml
name: Run Pipeline on Schedule

on:
  workflow_dispatch: # Allows you to run this workflow manually from the Actions tab
  schedule:
    # IMPORTANT: GitHub schedules run on UTC time.
    # 10:00 Copenhagen (CEST, UTC+2) is 08:00 UTC
    # 16:30 Copenhagen (CEST, UTC+2) is 14:30 UTC
    - cron: '25 11 * * *'
    - cron: '25 12 * * *'
    - cron: '25 13 * * *'
    - cron: '25 16 * * *'

jobs:
  run-on-fly:
    name: Start a Fly Machine to Run the Pipeline
    runs-on: ubuntu-latest

    steps:
      # Step 1: Check out your repository's code
      - uses: actions/checkout@v4
      
      # Step 2: Install flyctl and add it to the PATH.
      - name: Install flyctl
        run: |
          curl -L https://fly.io/install.sh | sh
          echo "/home/runner/.fly/bin" >> $GITHUB_PATH
        
      # Step 3: Run the machine command.
      - name: Start a temporary machine and wait for completion
        env:
          FLY_API_TOKEN: ${{ secrets.FLY_API_TOKEN }}
        run: |
          # 'flyctl' can now be called directly.
          # MODIFIED: Replaced --autodestroy with --rm, the original and more compatible flag.
          # This ensures the machine is automatically destroyed server-side upon completion.
          flyctl machine run . --region lhr --memory 2048 --rm
          
          echo "The machine has completed its run and has been destroyed."

# File: .gitignore
/node_modules
/.pnpm
/debug
.pnp.*
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/versions
# data only
papers.json
/scripts
# misc
.DS_Store
*.pem
# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*
# env files
.env*
!/.env.template
# vercel
.vercel
# typescript
*.tsbuildinfo
next-env.d.ts


# File: .nvmrc
20.15.1


# File: CLAUDE.md
# File: CLAUDE.md (version 1.02)
# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

**Headlines-Mongo** is a news processing application that scrapes Danish business news (BÃ¸rsen, Berlingske, Politiken, Finans.dk), assesses relevance using AI/LLM, and sends curated newsletters via email. The application is deployed on Fly.io and is designed to be triggered by a scheduler.

## Architecture

The application is architected as a **script-based, scheduled task** that runs its data pipeline once and then exits. It is not a web server.

1.  **Trigger**: The application is triggered directly by a scheduler (e.g., Fly.io's `schedule` attribute in `fly.toml` or a local cron job) which executes the `npm start` command.
2.  **Scraping**: Fetch headlines from configured sources.
3.  **Filtering**: Skip articles already in the database.
4.  **AI Assessment (Headlines)**: LLM evaluates headline relevance (threshold: 10).
5.  **Enrichment**: Extract full article content for relevant headlines.
6.  **AI Assessment (Content)**: LLM evaluates article content quality (threshold: 10).
7.  **Storage**: Store relevant articles in MongoDB.
8.  **Email**: Send curated newsletters and a supervisor report directly via a configured SMTP service.

All processing is done within the `runPipeline` function call.

## Core Components

### Key Files
- `app.js`: Main application entry point. Sets up the environment and triggers the pipeline.
- `app-logic.js`: Contains the `runPipeline` function which orchestrates the entire data processing flow from start to finish.
- `src/config/sources.js`: Web scraping configuration for Danish news sites.
- `src/config/env.js`: Centralized module for reading and exporting all environment variables.
- `src/config/email.js`: SMTP and email content configuration.

### Pipeline Modules
- `src/modules/scraping/fetchHeadlines.js`: Multi-source headline extraction.
- `src/modules/assessments/assessHeadlines.js`: AI relevance scoring for headlines.
- `src/modules/assessments/assessArticles.js`: AI content quality scoring.
- `src/modules/scraping/enrichWithBody.js`: Full article content extraction.
- `src/modules/email/index.js`: Email composition and delivery coordination.
- `src/modules/mongoStore/articleOperations.js`: MongoDB CRUD operations.

### Models
- `models/Article.js`: MongoDB schema with comprehensive fields for AI scoring and processing metadata.

## Development Commands

### Core Operations
```bash
# Run the pipeline script locally
npm start

# Run in test mode, re-processing articles from the current scrape
node app.js --refresh

# Run the Jest test suite
npm test

# File: Dockerfile
# File: Dockerfile (version 1.02)
# syntax = docker/dockerfile:1

ARG NODE_VERSION=20.15.1
FROM node:${NODE_VERSION}-slim AS base

WORKDIR /app

# --- Build Stage ---
FROM base AS build
RUN apt-get update -qq && apt-get install -y --no-install-recommends build-essential python-is-python3
COPY package-lock.json package.json ./

# Switch to `npm install` which is more robust than `npm ci` in complex scenarios,
# especially with `file:` dependencies that might exist locally but not in the build context.
# Using --omit=dev is equivalent to --production, ensuring dev dependencies are not installed.
RUN npm install --omit=dev

COPY . .

# --- Final Production Image ---
FROM base
COPY --from=build --chown=node:node /app /app
USER node

# This is no longer a web server, so no EXPOSE needed.
# It runs the pipeline script once and then exits.
CMD [ "node", "app.js" ]

# File: app-logic.js
// app-logic.js (version 2.0)
import mongoose from 'mongoose';
import { connectDatabase } from './src/database.js';
import { scrapeAllHeadlines, scrapeArticleContent } from './src/modules/scraper/index.js';
import { filterFreshArticles, savePipelineResults } from './src/modules/mongoStore/index.js';
import { assessHeadlinesInBatches, assessArticleContent, performAiSanityCheck, checkModelPermissions } from './src/modules/ai/index.js';
import { clusterArticlesIntoEvents, synthesizeEvent } from './src/modules/ai/eventProcessing.js';
import { findSimilarArticles } from './src/modules/ai/rag.js';
import SynthesizedEvent from './models/SynthesizedEvent.js';
import { logger } from './src/utils/logger.js';
import { logFinalReport } from './src/utils/pipelineLogger.js'; 
import { ARTICLES_RELEVANCE_THRESHOLD, HEADLINES_RELEVANCE_THRESHOLD, LLM_MODEL_TRIAGE, LLM_MODEL_ARTICLES } from './src/config/index.js';
import { sendWealthEventsEmail, sendSupervisorReportEmail } from './src/modules/email/index.js';
import { generateEmbedding } from './src/utils/vectorUtils.js';

export async function runPipeline(isRefreshMode = false) {
    const runStartTime = Date.now();
    logger.info('ðŸš€ STARTING SYNTHESIS PIPELINE (Transactional Mode)...');
    const runStats = {
        headlinesScraped: 0,
        scraperHealth: [],
        freshHeadlinesFound: 0,
        headlinesAssessed: 0,
        relevantHeadlines: 0,
        enrichmentOutcomes: [],
        articlesEnriched: 0,
        relevantArticles: 0, 
        enrichedBySource: {},
        eventsClustered: 0,
        eventsSynthesized: 0,
        synthesizedEventsForReport: [], 
        eventsEmailed: 0,
        errors: [],
    };

    let dbConnected = false;
    let assessedCandidates = []; // Hold all processed articles here
    let synthesizedEventsToSave = []; // Hold all synthesized events

    try {
        // --- STEP 1: PRE-FLIGHT CHECKS & DB CONNECTION ---
        const requiredModels = [...new Set([LLM_MODEL_TRIAGE, LLM_MODEL_ARTICLES])];
        if (!await performAiSanityCheck() || !await checkModelPermissions(requiredModels)) {
            logger.fatal('AI service checks failed. Aborting pipeline.');
            return;
        }
        await connectDatabase();
        dbConnected = true;

        // --- STEP 2: SCRAPE & FILTER ARTICLES ---
        const { allArticles: scrapedHeadlines, scraperHealth } = await scrapeAllHeadlines();
        runStats.scraperHealth = scraperHealth;
        runStats.headlinesScraped = scrapedHeadlines.length;
        
        const articlesToProcess = await filterFreshArticles(scrapedHeadlines, isRefreshMode);
        runStats.freshHeadlinesFound = articlesToProcess.length;

        if (articlesToProcess.length === 0) {
            logger.info('No new or refreshed articles to process. Ending run.');
            return;
        }
        
        // --- STEP 3: PREPARE ARTICLES IN-MEMORY ---
        const articlesForPipeline = [];
        for (const article of articlesToProcess) {
            const embedding = await generateEmbedding(article.headline);
            articlesForPipeline.push({
                ...article,
                _id: new mongoose.Types.ObjectId(),
                embedding,
                relevance_headline: 0,
                assessment_headline: 'Awaiting assessment',
            });
        }
        
        // --- STEP 4: HEADLINE ASSESSMENT ---
        assessedCandidates = await assessHeadlinesInBatches(articlesForPipeline);
        runStats.headlinesAssessed = assessedCandidates.length;

        const relevantCandidates = assessedCandidates.filter(a => a.relevance_headline >= HEADLINES_RELEVANCE_THRESHOLD);
        runStats.relevantHeadlines = relevantCandidates.length;

        if (relevantCandidates.length === 0) {
            logger.info('No headlines met the relevance threshold for event synthesis.');
            // Go to 'finally' block to save the non-relevant headlines
            return; 
        }
        logger.info(`Found ${relevantCandidates.length} relevant headlines. Proceeding to enrichment...`);
        
        // --- STEP 5: ENRICHMENT & ARTICLE ASSESSMENT ---
        const enrichedArticles = [];
        for (const article of relevantCandidates) {
            const enriched = await scrapeArticleContent(article);
            
            if (enriched.articleContent && enriched.articleContent.contents.join('').length > 150) {
                const finalAssessment = await assessArticleContent(enriched);
                const contentSnippet = (finalAssessment.articleContent?.contents || []).join(' ').substring(0, 300);

                if (finalAssessment.relevance_article >= ARTICLES_RELEVANCE_THRESHOLD) {
                    enrichedArticles.push(finalAssessment);
                    runStats.articlesEnriched++;
                    runStats.enrichedBySource[article.source] = (runStats.enrichedBySource[article.source] || 0) + 1;
                    runStats.enrichmentOutcomes.push({
                        headline: article.headline, link: article.link, newspaper: article.newspaper, outcome: 'Success',
                        headlineScore: article.relevance_headline, assessment_headline: article.assessment_headline,
                        finalScore: finalAssessment.relevance_article, assessment_article: finalAssessment.assessment_article,
                        content_snippet: contentSnippet,
                    });
                } else {
                    runStats.enrichmentOutcomes.push({
                        headline: article.headline, link: article.link, newspaper: article.newspaper, outcome: 'Dropped',
                        headlineScore: article.relevance_headline, assessment_headline: article.assessment_headline,
                        finalScore: finalAssessment.relevance_article, assessment_article: `Score was below threshold [${ARTICLES_RELEVANCE_THRESHOLD}]. AI Reason: ${finalAssessment.assessment_article}`,
                        content_snippet: contentSnippet,
                    });
                }
            } else {
                runStats.enrichmentOutcomes.push({
                    headline: article.headline, link: article.link, newspaper: article.newspaper, outcome: 'Dropped',
                    headlineScore: article.relevance_headline, assessment_headline: article.assessment_headline,
                    finalScore: null, assessment_article: `Enrichment Failed. Reason: ${enriched.enrichment_error || 'Scraped content was too short (< 150 chars)'}`,
                    content_snippet: 'Could not retrieve article content.',
                });
            }
        }
        runStats.relevantArticles = enrichedArticles.length;
        logger.info(`Enriched and assessed ${enrichedArticles.length} full articles meeting the relevance threshold.`);

        if (enrichedArticles.length === 0) {
            logger.info('No articles met the full article relevance threshold for event synthesis.');
            return;
        }

        // --- STEP 6: CLUSTERING & SYNTHESIS ---
        const eventClusters = await clusterArticlesIntoEvents(enrichedArticles);
        runStats.eventsClustered = eventClusters.length;
        if (eventClusters.length === 0) {
            logger.info('No unique events were clustered from the relevant articles.');
            return;
        }
        logger.info(`Clustered ${enrichedArticles.length} articles into ${eventClusters.length} unique events.`);

        for (const cluster of eventClusters) {
            const articlesInCluster = enrichedArticles.filter(a => cluster.article_ids.includes(a._id.toString()));
            if (articlesInCluster.length === 0) continue;

            const historicalContext = await findSimilarArticles(articlesInCluster);
            const synthesizedEvent = await synthesizeEvent(articlesInCluster, historicalContext);

            if (synthesizedEvent && !synthesizedEvent.error) {
                runStats.eventsSynthesized++;
                const highestScoringArticle = articlesInCluster.reduce((max, current) => (current.relevance_article > max.relevance_article) ? current : max, articlesInCluster[0]);
                const aggregatedIndividuals = articlesInCluster.flatMap(a => a.key_individuals || []);
                const uniqueIndividuals = Array.from(new Map(aggregatedIndividuals.map(p => [p.name, p])).values());

                const eventToSave = new SynthesizedEvent({
                    event_key: cluster.event_key,
                    synthesized_headline: synthesizedEvent.headline,
                    synthesized_summary: synthesizedEvent.summary,
                    ai_assessment_reason: highestScoringArticle.assessment_article || highestScoringArticle.assessment_headline,
                    highest_relevance_score: Math.max(...articlesInCluster.map(a => a.relevance_article)),
                    key_individuals: uniqueIndividuals,
                    source_articles: articlesInCluster.map(a => ({ headline: a.headline, link: a.link, newspaper: a.newspaper })),
                });
                synthesizedEventsToSave.push(eventToSave);
                runStats.synthesizedEventsForReport.push({ synthesized_headline: eventToSave.synthesized_headline, highest_relevance_score: eventToSave.highest_relevance_score });
            }
        }
        
    } catch (error) {
        logger.fatal({ err: error }, 'A critical error occurred in the main pipeline. No data will be committed.');
        runStats.errors.push(`CRITICAL: ${error.message}`);
        // Clear the arrays to prevent partial data save in 'finally' block
        assessedCandidates = [];
        synthesizedEventsToSave = [];
    } finally {
        // --- FINAL STEP: COMMIT & REPORT ---
        const runEndTime = Date.now();
        const duration = ((runEndTime / 1000) - (runStartTime / 1000)).toFixed(2);
        
        if (dbConnected && runStats.errors.length === 0) {
            // Only commit if the pipeline ran without critical errors.
            // The list of articles to save is now `assessedCandidates`, which includes ALL fresh articles from this run.
            if (assessedCandidates.length > 0) {
                const success = await savePipelineResults(assessedCandidates, synthesizedEventsToSave);
                if (success) {
                    logger.info(`Successfully committed ${assessedCandidates.length} articles and ${synthesizedEventsToSave.length} events to the database.`);
                    // Now that data is saved, trigger email.
                    const emailResult = await sendWealthEventsEmail();
                    runStats.eventsEmailed = emailResult.eventsSentCount;
                } else {
                     runStats.errors.push("CRITICAL: Failed to commit pipeline results to the database.");
                }
            }
            await sendSupervisorReportEmail(runStats);
        } else if (dbConnected) {
            // If there were errors, still send a supervisor report but don't commit data.
            await sendSupervisorReportEmail(runStats);
        } else {
             logger.warn('Pipeline halted before DB connection. No supervisor report or final stats will be generated.');
        }
       
        await logFinalReport(runStats, duration);
    }
}

# File: app.js
// app.js

// --- CRITICAL: Set environment based on command-line args BEFORE any other imports ---
// This ensures that all modules, especially the config, see the correct environment state
// from the very beginning of the application lifecycle.
const isRefreshMode = process.argv.includes('--refresh');
if (isRefreshMode) {
    process.env.REFRESH_MODE = 'true';
}

import 'dotenv/config'; // Load environment variables from .env file
import { logger } from './src/utils/logger.js';
import { runPipeline } from './app-logic.js';

// Now that the logger has been initialized (with the correct mode), we can safely log the warning.
if (isRefreshMode) {
    logger.warn('ðŸš€ REFRESH MODE ACTIVATED: Previously processed articles from this scrape will be treated as fresh.');
}

async function start() {
    try {
        // Pass the determined mode directly to the pipeline.
        await runPipeline(isRefreshMode);
        // The process will exit naturally after the pipeline completes.
    } catch (error) {
        logger.fatal({ err: error }, 'A top-level, unhandled exception occurred in the application. The pipeline did not complete.');
        // Exit with a failure code to signal an issue to the scheduler (e.g., Fly.io).
        process.exit(1);
    }
}

start();

# File: data/facts.json
[
  {
    "headline": "Wealth Profile: Anders Holch Povlsen Confirmed as Denmark's Richest Individual",
    "link": "https://www.goodreturns.in/billionaires-in-denmark.html#fact1-povlsen",
    "newspaper": "Wealth Intelligence Briefing",
    "source": "Internal Fact Sheet",
    "relevance_article": 100,
    "assessment_article": "Core intelligence on a top-tier Scandinavian Rich List individual's net worth.",
    "articleContent": {
      "contents": [
        "Anders Holch Povlsen is the richest person in Denmark, with an estimated net worth of $12.36 billion. His wealth is primarily derived from his ownership of the fashion retail company Bestseller and significant shareholdings in companies like ASOS and Zalando."
      ]
    },
    "key_individuals": [
      {
        "name": "Anders Holch Povlsen",
        "role_in_event": "Subject of Wealth Analysis",
        "company": "Bestseller"
      }
    ]
  },
  {
    "headline": "Industry Analysis: Manufacturing Sector Dominates Danish Billionaire List",
    "link": "https://www.goodreturns.in/billionaires-in-denmark.html#fact2-industry-dominance",
    "newspaper": "Wealth Intelligence Briefing",
    "source": "Internal Fact Sheet",
    "relevance_article": 100,
    "assessment_article": "Strategic analysis of wealth origins among Denmark's UHNW individuals, crucial for sector-based prospecting.",
    "articleContent": {
      "contents": [
        "An analysis of the top billionaires in Denmark reveals that the majority originate from the Manufacturing industry. This sector accounts for 57% (4 out of 7) of the country's wealthiest individuals, indicating its foundational role in large-scale wealth creation in the region."
      ]
    }
  },
  {
    "headline": "Wealth Profile: Niels Peter Louis-Hansen, Denmark's Oldest Top Billionaire",
    "link": "https://www.goodreturns.in/billionaires-in-denmark.html#fact3-louis-hansen",
    "newspaper": "Wealth Intelligence Briefing",
    "source": "Internal Fact Sheet",
    "relevance_article": 100,
    "assessment_article": "Core intelligence on a top-tier Scandinavian Rich List individual from the Healthcare sector.",
    "articleContent": {
      "contents": [
        "Denmark's oldest billionaire in the top list is Niels Peter Louis-Hansen, aged 77. His fortune is associated with the Healthcare industry, primarily through his stake in the medical device company Coloplast."
      ]
    },
    "key_individuals": [
      {
        "name": "Niels Peter Louis-Hansen",
        "role_in_event": "Subject of Wealth Analysis",
        "company": "Coloplast"
      }
    ]
  },
  {
    "headline": "Sector Breakdown: Denmark's Top Billionaires Represent Four Key Industries",
    "link": "https://www.goodreturns.in/billionaires-in-denmark.html#fact4-sector-breakdown",
    "newspaper": "Wealth Intelligence Briefing",
    "source": "Internal Fact Sheet",
    "relevance_article": 100,
    "assessment_article": "Market intelligence report identifying the primary sectors for wealth creation in Denmark.",
    "articleContent": {
      "contents": [
        "The top billionaires in Denmark derive their wealth from four primary industries: Healthcare, Manufacturing, Logistics, and Fashion & Retail. This highlights the key sectors driving significant private wealth in the country."
      ]
    }
  },
  {
    "headline": "Wealth Profile: Agnete Kirk Thinggaard, Denmark's Youngest Top Billionaire",
    "link": "https://www.goodreturns.in/billionaires-in-denmark.html#fact5-kirk-thinggaard",
    "newspaper": "Wealth Intelligence Briefing",
    "source": "Internal Fact Sheet",
    "relevance_article": 100,
    "assessment_article": "Core intelligence on a key member of the Kirk Kristiansen (LEGO) family, a top-tier Rich List entity.",
    "articleContent": {
      "contents": [
        "The youngest person among Denmark's top billionaires is Agnete Kirk Thinggaard, at 42 years old. She is one of the heirs to the LEGO fortune, founded by her great-grandfather."
      ]
    },
    "key_individuals": [
      {
        "name": "Agnete Kirk Thinggaard",
        "role_in_event": "Subject of Wealth Analysis",
        "company": "LEGO (Kirk Kristiansen family)"
      }
    ]
  }
]

# File: data/rich1.json
[
  {
    "headline": "Wealth Profile #33: Hans Carl BÃ¸gh-SÃ¸rensen & Family (Orifarm) Fortune at DKK 6.4 Billion",
    "link": "https://www.okonomiskugebrev.dk/danmarks-100-rigeste-2024#fact-bogh-sorensen-33-final",
    "newspaper": "Ã˜konomisk Ugebrev - Danmarks 100 Rigeste 2024",
    "source": "Wealth Intelligence Briefing",
    "relevance_article": 100,
    "assessment_article": "Intelligence on the family behind Orifarm, a major parallel importer of pharmaceuticals, noting a modest wealth increase based on an 18% profit rise.",
    "articleContent": {
      "contents": [
        "Hans Carl BÃ¸gh-SÃ¸rensen and family are ranked #33 with a fortune of DKK 6.4 billion, a modest increase from DKK 6.3 billion. Their company, Orifarm Group, is one of Europe's largest in the parallel import of medicine. The family's wealth grew on the back of an 18% increase in company profits."
      ]
    },
    "key_individuals": [
      {
        "name": "Hans Carl BÃ¸gh-SÃ¸rensen",
        "role_in_event": "Owner",
        "company": "Orifarm / Habico Holding"
      }
    ]
  },
  {
    "headline": "Wealth Profile #93: Grunnet Family (Primo) Fortune at DKK 2.2 Billion",
    "link": "https://www.okonomiskugebrev.dk/danmarks-100-rigeste-2024#fact-grunnet-93-final",
    "newspaper": "Ã˜konomisk Ugebrev - Danmarks 100 Rigeste 2024",
    "source": "Wealth Intelligence Briefing",
    "relevance_article": 100,
    "assessment_article": "Intelligence on the family behind the plastics manufacturing company Inter Primo Group, whose fortune saw a slight increase.",
    "articleContent": {
      "contents": [
        "The Grunnet family, owners of the plastics extrusion company Inter Primo Group, is ranked #93 with a fortune of DKK 2.2 billion, a slight increase from DKK 2.1 billion. Although the company's operating profit saw a decline, the family's overall fortune was supported by positive returns on their financial investments."
      ]
    },
    "key_individuals": [
      {
        "name": "Flemming Grunnet",
        "role_in_event": "Chairman",
        "company": "Inter Primo Group"
      }
    ]
  }
]

# File: docker-compose.yml
# docker-compose.yml (version 1.03)
# This file is for LOCAL DEVELOPMENT and TESTING ONLY.
# It allows us to reliably run the application in a container,
# mimicking the production environment.

services:
  app:
    # Build the image from the Dockerfile in the current directory.
    build: .
    # Use the .env file to supply environment variables to the container.
    # docker-compose has a robust parser that handles special characters correctly.
    env_file:
      - .env
    # The application is a script, not a web server, so no port mapping is needed.
    # Give the container a friendly name.
    container_name: headlines_local

# File: fly.toml
app = 'headlines-polished-sea-1731'
primary_region = 'lhr'

# This empty [processes] block tells flyctl to use the modern Machines platform
# and not look for a long-running web service.
# This is now the ONLY machine-related configuration in this file.
[processes]

# File: models/Article.js
// models/Article.js
import mongoose from 'mongoose';

const { Schema, model, models } = mongoose;

const ArticleSchema = new Schema(
  {
    headline: {
      type: String,
      required: true,
      trim: true,
      minlength: 10,
      maxlength: 500,
    },
    link: { type: String, required: true, unique: true, trim: true },
    newspaper: { type: String, required: true, trim: true },
    source: { type: String, required: true, trim: true },
    section: { type: String, required: false, trim: true },
    author: { type: String, required: false, trim: true },
    published: { type: String, required: false, trim: true },
    position: { type: String, required: false, trim: true },
    raw: { type: Schema.Types.Mixed, required: false },
    relevance_headline: { type: Number, required: true, min: 0, max: 100 },
    assessment_headline: { type: String, required: true, trim: true },
    articleContent: {
      headlines: { type: [String], required: false, default: [] },
      subheadings: { type: [String], required: false, default: [] },
      captions: { type: [String], required: false, default: [] },
      contents: { type: [String], required: false, default: [] },
    },
    topic: { type: String, required: false, trim: true },
    relevance_article: { type: Number, required: false, min: 0, max: 100 },
    assessment_article: { type: String, required: false, trim: true },
    amount: { type: Number, required: false },
    key_individuals: [{
        name: String,
        role_in_event: String,
        company: String,
        email_suggestion: { type: String, required: false }, // NEW FIELD
    }],
    background: { type: String, required: false, trim: true },
    error: { type: String, required: false, trim: true, default: null },
    enrichment_error: { type: String, required: false, trim: true, default: null },
    storage_error_initial_headline_data: { type: String, required: false, trim: true, default: null },
    db_operation_status: { type: String, required: false, trim: true },
    db_error_reason: { type: String, required: false, trim: true },
    emailed: { type: Boolean, default: false },
    email_error: { type: String, required: false, trim: true, default: null },
    email_skipped_reason: { type: String, required: false, trim: true, default: null },
    embedding: { type: [Number], required: false },
  },
  {
    timestamps: true,
    collection: 'articles',
  }
);

ArticleSchema.index({ headline: 1 });
ArticleSchema.index({ newspaper: 1, createdAt: -1 });
ArticleSchema.index({ relevance_article: -1, createdAt: -1 });
ArticleSchema.index({ relevance_headline: -1, createdAt: -1 });

export default models.Article || model('Article', ArticleSchema);

# File: models/SynthesizedEvent.js
// models/SynthesizedEvent.js
import mongoose from 'mongoose';

const { Schema, model, models } = mongoose;

const SourceArticleSchema = new Schema({
  article_id: { type: Schema.Types.ObjectId, ref: 'Article', required: true },
  headline: { type: String, required: true },
  link: { type: String, required: true },
  newspaper: { type: String, required: true },
}, { _id: false });

const KeyIndividualSchema = new Schema({
    name: String,
    role_in_event: String,
    company: String,
    email_suggestion: { type: String, required: false },
}, { _id: false });

const SynthesizedEventSchema = new Schema(
  {
    event_key: {
      type: String,
      required: true,
      unique: true,
      trim: true,
      index: true,
      description: "A unique key for the event, e.g., 'acquisition-visma-innovateai-2024-05-20'",
    },
    synthesized_headline: { type: String, required: true, trim: true },
    synthesized_summary: { type: String, required: true, trim: true },
    ai_assessment_reason: { type: String, required: false }, // NEW FIELD
    source_articles: { type: [SourceArticleSchema], required: true },
    highest_relevance_score: { type: Number, required: true },
    key_individuals: { type: [KeyIndividualSchema], required: true },
    event_date: { type: Date, default: Date.now },
    emailed: { type: Boolean, default: false },
    email_sent_at: { type: Date },
  },
  {
    timestamps: true,
    collection: 'synthesized_events',
  }
);

SynthesizedEventSchema.index({ event_date: -1 });

export default models.SynthesizedEvent || model('SynthesizedEvent', SynthesizedEventSchema);

# File: norway.js
import axios from 'axios';
import * as cheerio from 'cheerio';

const url = 'https://www.finansavisen.no/kapital';

/**
 * Fetches the HTML content of the target website.
 * @returns {Promise<string>} The HTML content as a string.
 */
async function downloadWebsite() {
  try {
    console.log(`Downloading HTML from ${url}...`);
    const response = await axios.get(url);
    return response.data;
  } catch (error) {
    console.error(`Error downloading the website: ${error.message}`);
    process.exit(1);
  }
}

/**
 * Parses the HTML to extract headlines and their hyperlinks.
 * @param {string} html - The HTML content of the website.
 * @returns {Array<Object>} A list of article objects with headlines and hyperlinks.
 */
function listHeadlines(html) {
  const articles = [];
  const $ = cheerio.load(html);
  const baseUrl = 'https://www.finansavisen.no';

  // Each article seems to be within an <article> tag with the class 'dre-item'
  $('article.dre-item').each((index, element) => {
    // The headline text and link are within an <a> tag with the class 'dre-item__title'
    const titleElement = $(element).find('a.dre-item__title');
    
    if (titleElement.length > 0) {
      // Extract the raw text and clean it up by removing extra whitespace/newlines
      const headline = titleElement.text().trim().replace(/\s+/g, ' ');
      const relativeLink = titleElement.attr('href');

      if (headline && relativeLink) {
        articles.push({
          headline: headline,
          hyperlink: `${baseUrl}${relativeLink}`
        });
      }
    }
  });
  
  return articles;
}

/**
 * Main function to run the scraper.
 */
async function main() {
  const html = await downloadWebsite();
  const headlines = listHeadlines(html);
  
  console.log('Successfully scraped the following headlines:');
  console.log(JSON.stringify(headlines, null, 2));
}

main();

# File: package.json
{
  "name": "headlines-pipeline",
  "version": "3.0.0",
  "description": "A Node.js pipeline to scrape, analyze, and store news articles about wealth events.",
  "main": "app.js",
  "type": "module",
  "scripts": {
    "start": "node app.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [
    "scraper",
    "axios",
    "cheerio",
    "nodejs",
    "openai",
    "mongoose"
  ],
  "author": "The Driver",
  "license": "ISC",
  "dependencies": {
    "@xenova/transformers": "^2.17.2",
    "axios": "^1.7.2",
    "cheerio": "^1.0.0-rc.12",
    "dotenv": "^16.4.5",
    "https-proxy-agent": "^7.0.6",
    "mongoose": "^8.4.1",
    "nodemailer": "^6.9.13",
    "openai": "^4.47.3",
    "p-limit": "^5.0.0",
    "pino": "^9.1.0",
    "pino-pretty": "^11.1.0",
    "playwright": "^1.45.1"
  }
}

# File: scrape.js
// scrape.js
// A utility script to perform a diagnostic scrape on configured sources.
// This is useful for testing, debugging, and adding new newspapers.
//
// Usage:
//   - Test all sources: `node scrape.js`
//   - Test a single source: `node scrape.js <site_key>`
//     (e.g., `node scrape.js borsen_frontpage`)

import 'dotenv/config';
import pLimit from 'p-limit';
// MODIFIED: Import the new country-based config
import { COUNTRIES_CONFIG } from './src/config/sources.js';
import { scrapeSite, scrapeArticleContent } from './src/modules/scraper/index.js';
import { CONCURRENCY_LIMIT } from './src/config/index.js';
import { logger } from './src/utils/logger.js';

// --- Configuration ---
logger.level = 'info';

// --- Console Colors for Readability ---
const colors = {
    reset: "\x1b[0m",
    red: "\x1b[31m",
    green: "\x1b[32m",
    yellow: "\x1b[33m",
    cyan: "\x1b[36m",
    grey: "\x1b[90m",
};

const log = (msg) => console.log(msg);

/**
 * Runs a diagnostic test on a single site configuration.
 * @param {object} site The site configuration from COUNTRIES_CONFIG.
 * @returns {Promise<{success: boolean, message: string}>} The result of the test.
 */
async function testSite(site) {
    const statusLine = [`${colors.cyan}${site.name.padEnd(25)}${colors.reset}`];

    try {
        const { articles, success: headlineSuccess } = await scrapeSite(site);
        const headlineCount = articles.length;
        
        if (!headlineSuccess || headlineCount === 0) {
            statusLine.push(`${String(headlineCount).padStart(3)} headlines scraped`);
            statusLine.push(`${colors.red}Headline scraping FAILED or returned zero articles.${colors.reset}`);
            return { success: false, message: statusLine.join(' > ') };
        }
        
        statusLine.push(`${colors.green}${String(headlineCount).padStart(3)} headlines scraped${colors.reset}`);

        const firstArticle = articles[0];
        const articleWithContent = await scrapeArticleContent(firstArticle);

        const content = articleWithContent.articleContent?.contents?.join('') || '';
        const contentLength = content.length;

        if (contentLength > 150) {
            statusLine.push(`${colors.green}First article OK (${contentLength} chars)${colors.reset}`);
            return { success: true, message: statusLine.join(' > ') };
        } else {
            const reason = articleWithContent.enrichment_error || `Content too short (< 150 chars)`;
            const failedLink = `(Link: ${firstArticle.link})`;
            statusLine.push(`${colors.red}Content FAILED: ${reason}${colors.reset} ${colors.grey}${failedLink}${colors.reset}`);
            return { success: false, message: statusLine.join(' > ') };
        }
    } catch (error) {
        statusLine.push(`${colors.red}FATAL SCRIPT ERROR: ${error.message}${colors.reset}`);
        return { success: false, message: statusLine.join(' > ') };
    }
}

/**
 * Main function to orchestrate the diagnostic scrape.
 */
async function main() {
    const siteKey = process.argv[2];
    
    // MODIFIED: Flatten the new structure to get a list of all sites.
    const allSites = COUNTRIES_CONFIG.flatMap(country => country.sites);
    let sitesToTest = allSites;

    const limit = pLimit(CONCURRENCY_LIMIT);

    if (siteKey) {
        // MODIFIED: Find the specific site by its key in the flattened list.
        const targetSite = allSites.find(site => site.key === siteKey);
        if (targetSite) {
            sitesToTest = [targetSite];
            log(`${colors.yellow}ðŸš€ Starting targeted diagnostic scrape for: ${siteKey}${colors.reset}`);
        } else {
            log(`${colors.red}Error: Site key "${siteKey}" not found in COUNTRIES_CONFIG.${colors.reset}`);
            return;
        }
    } else {
        log(`${colors.yellow}ðŸš€ Starting full diagnostic scrape for all ${sitesToTest.length} sources...${colors.reset}`);
    }
    
    log('-----------------------------------------------------------------------------------------');

    const promises = sitesToTest.map(site => limit(() => testSite(site)));
    const results = await Promise.all(promises);

    let successCount = 0;
    let failureCount = 0;

    results.forEach(result => {
        log(result.message);
        if (result.success) {
            successCount++;
        } else {
            failureCount++;
        }
    });

    log('-----------------------------------------------------------------------------------------');
    const summaryColor = failureCount > 0 ? colors.red : colors.green;
    log(`${summaryColor}âœ… Diagnostic finished. Passed: ${successCount}, Failed: ${failureCount}${colors.reset}`);
}

// --- Execute Script ---
main().catch(err => {
    console.error(`${colors.red}A critical, unhandled error occurred in the scrape script:${colors.reset}`, err);
    process.exit(1);
});

# File: src/config/index.js
// src/config/index.js (version 2.2)
import dotenv from 'dotenv';

dotenv.config();

/**
 * Helper function to safely read and clean string environment variables.
 * It trims whitespace and removes surrounding quotes.
 * @param {string} key The environment variable key.
 * @param {string} defaultValue The default value if the key is not found.
 * @returns {string} The cleaned environment variable value.
 */
function getCleanStringEnv(key, defaultValue = '') {
    let value = process.env[key] || defaultValue;
    value = value.trim();
    if ((value.startsWith('"') && value.endsWith('"')) || (value.startsWith("'") && value.endsWith("'"))) {
        return value.slice(1, -1);
    }
    return value;
}


// --- Core App Behavior ---
export const NODE_ENV = getCleanStringEnv('NODE_ENV', 'development');
export const IS_PRODUCTION = NODE_ENV === 'production';
export const LOG_LEVEL = getCleanStringEnv('LOG_LEVEL', 'info');
export const CONCURRENCY_LIMIT = parseInt(process.env.CONCURRENCY_LIMIT, 10) || 3;
export const FORCE_EMAIL_SEND_DEV = process.env.FORCE_EMAIL_SEND_DEV === 'true';
export const IS_REFRESH_MODE = process.env.REFRESH_MODE === 'true';

// --- Database ---
export const MONGO_URI = getCleanStringEnv('MONGO_URI');

// --- LLM Configuration ---
export const OPENAI_API_KEY = getCleanStringEnv('OPENAI_API_KEY');
// All AI tasks are unified to use a single, powerful model as per the new strategy.
export const LLM_MODEL = getCleanStringEnv('LLM_MODEL', 'gpt-5-mini');
export const LLM_MODEL_TRIAGE = LLM_MODEL;
export const LLM_MODEL_HEADLINES = LLM_MODEL;
export const LLM_MODEL_ARTICLES = LLM_MODEL;

// --- Scraper Configuration ---
export const SCRAPER_PROXY_URL = getCleanStringEnv('SCRAPER_PROXY_URL') || null;


// --- Thresholds ---
export const HEADLINES_RELEVANCE_THRESHOLD = 20;
export const ARTICLES_RELEVANCE_THRESHOLD = 50;
export const MIN_ARTICLE_CHARS = 150;
export const MAX_ARTICLE_CHARS = 100000;
export const MIN_HEADLINE_CHARS = 5;
export const MAX_HEADLINE_CHARS = 500;
export const AI_BATCH_SIZE = 6;

// --- Email Configuration ---
export const SMTP_CONFIG = {
    host: getCleanStringEnv('SMTP_HOST'),
    port: parseInt(process.env.SMTP_PORT, 10) || 587,
    secure: process.env.SMTP_SECURE === 'true',
    auth: {
        user: getCleanStringEnv('SMTP_USER'),
        pass: getCleanStringEnv('SMTP_PASS'),
    },
    fromAddress: getCleanStringEnv('SMTP_FROM_ADDRESS') || getCleanStringEnv('SMTP_USER'),
    fromName: getCleanStringEnv('SMTP_FROM_NAME', 'Headlines Bot'),
};

// REMOVED: All recipient logic is now handled by the email module via src/config/users.js.
// export const HEADLINE_RECIPIENTS_STR = getCleanStringEnv('HEADLINE_RECIPIENTS');
// export const HEADLINE_RECIPIENTS = HEADLINE_RECIPIENTS_STR.split(',').map(e => e.trim()).filter(Boolean);


// --- Email Template Config ---
export const EMAIL_CONFIG = {
  templateName: 'wealthEvents',
  subject: 'New Nordic Banking Opportunities Detected', // This will be customized per user
  language: 'en',
  brandName: 'Your Wealth Watch',
  companyAddress: 'Wealth Watch Inc., Paris, France',
  unsubscribeUrl: '#',
};

export const SUPERVISOR_EMAIL_CONFIG = {
  templateName: 'supervisorReport',
  subject: 'âš™ï¸ Hourly Headlines Processing Run Summary',
  language: 'en',
  brandName: 'Headlines Processing Bot',
};

# File: src/config/sources.js
// src/config/sources.js
// Centralized configuration for web scraping sources, now grouped by country.

export const COUNTRIES_CONFIG = [
  {
    countryName: 'Denmark',
    flag: 'ðŸ‡©ðŸ‡°',
    sites: [
      { key: 'berlingske', name: 'Berlingske', url: 'https://www.berlingske.dk/business', selector: 'h4.teaser__title a.teaser__title-link', extract: (el, site) => ({ headline: el.text().trim(), link: new URL(el.attr('href'), site.url).href, source: site.name, newspaper: site.name }) },
      { key: 'borsen_frontpage', name: 'BÃ¸rsen Frontpage', newspaper: 'BÃ¸rsen', url: 'https://borsen.dk/', useJsonLd: true },
      { key: 'borsen_nyheder', name: 'BÃ¸rsen Nyheder', newspaper: 'BÃ¸rsen', url: 'https://borsen.dk/nyheder', useJsonLd: true },
      { key: 'borsen_finans', name: 'BÃ¸rsen Finans', newspaper: 'BÃ¸rsen', url: 'https://borsen.dk/nyheder/finans', useJsonLd: true },
      { key: 'borsen_virksomheder', name: 'BÃ¸rsen Virksomheder', newspaper: 'BÃ¸rsen', url: 'https://borsen.dk/nyheder/virksomheder', useJsonLd: true },
      { key: 'borsen_investor', name: 'BÃ¸rsen Investor', newspaper: 'BÃ¸rsen', url: 'https://borsen.dk/nyheder/investor', useJsonLd: true },
      { key: 'politiken', name: 'Politiken', url: 'https://politiken.dk/danmark/oekonomi/', selector: 'article', extract: (el, site) => { const h = el.find('h2, h3, h4').first().text().trim(); const a = el.find('a[href*="/art"]').first().attr('href'); return h && a ? { headline: h, link: new URL(a, site.url).href, source: site.name, newspaper: site.name } : null; } },
      { key: 'finans_dk', name: 'Finans.dk', url: 'https://finans.dk/seneste-nyt', selector: 'article a h3', extract: (el, site) => ({ headline: el.text().trim(), link: el.closest('a').attr('href'), source: site.name, newspaper: site.name }) },
      { key: 'axcel', name: 'Axcel', url: 'https://axcel.com/news', selector: 'div.news-mask a', extract: (el, site) => ({ headline: el.find('h3').text().trim(), link: new URL(el.attr('href'), site.url).href, source: site.name, newspaper: site.name }) },
      { key: 'polaris', name: 'Polaris', url: 'https://polarisequity.dk/news', selector: 'div.fl-post-feed-post', extract: (el, site) => { const linkEl = el.find('h3.fl-post-feed-title a'); const headline = linkEl.text().trim(); const href = linkEl.attr('href'); if (headline && href) { return { headline, link: new URL(href, site.url).href, source: site.name, newspaper: site.name }; } return null; } },
    ]
  },
  {
    countryName: 'Norway',
    flag: 'ðŸ‡³ðŸ‡´',
    sites: [
      {
        key: 'finansavisen', name: 'Finansavisen', url: 'https://www.finansavisen.no/', newspaper: 'Finansavisen', selector: 'script',
        extract: (el, site) => { /* ... existing extraction logic ... */ }
      },
      { key: 'e24', name: 'E24', url: 'https://e24.no/', newspaper: 'E24', selector: 'a._teaser_bizto_1', extract: (el, site) => { const headlineEl = el.find('h3._mainTitle_qsmm2_16').clone(); headlineEl.find('style').remove(); const headline = headlineEl.text().trim(); const href = el.attr('href'); if (headline && href) { return { headline, link: new URL(href, site.url).href, source: site.name, newspaper: site.newspaper }; } return null; } },
      { key: 'fsn_capital', name: 'FSN Capital', url: 'https://fsncapital.com/en/news/', newspaper: 'FSN Capital', selector: 'div.newsitem', extract: (el, site) => { const linkEl = el.find('h4.title a'); return { headline: linkEl.text().trim(), link: linkEl.attr('href'), source: site.name, newspaper: site.newspaper, } } },
      { key: 'verdane', name: 'Verdane', url: 'https://verdane.com/portfolio/', newspaper: 'Verdane', selector: 'li.wp-block-post.portfolio', extract: (el, site) => { const linkEl = el.find('a.wp-block-klingit-the-product-block-link'); const companyName = linkEl.find('h3.wp-block-post-title').text().trim(); if (companyName) { return { headline: `Verdane invests in ${companyName}`, link: linkEl.attr('href'), source: site.name, newspaper: site.newspaper, }; } return null; } },
    ]
  },
  {
    countryName: 'Pan-Nordic',
    flag: 'ðŸ‡ªðŸ‡º',
    sites: [
      { key: 'nordic_capital', name: 'Nordic Capital', url: 'https://www.nordiccapital.com/news-views/', newspaper: 'Nordic Capital', selector: 'article.masonry-card--component a', extract: (el, site) => { const headline = el.find('h3').text().trim(); const href = el.attr('href'); if (headline && href) { return { headline, link: new URL(href, site.url).href, source: site.name, newspaper: site.newspaper }; } return null; } },
      { key: 'altor', name: 'Altor', url: 'https://www.altor.com/news/', newspaper: 'Altor', selector: 'a.g-content-card.g-news__item', extract: (el, site) => ({ headline: el.find('p.g-content-card__header').text().trim(), link: new URL(el.attr('href'), site.url).href, source: site.name, newspaper: site.newspaper, }) },
    ]
  }
  // Add other countries like Finland, Netherlands, Belgium here...
];

// --- NEW: Create and export maps for use in the email module ---
export const newspaperToCountryMap = new Map();
export const countryNameToFlagMap = new Map();

COUNTRIES_CONFIG.forEach(country => {
  countryNameToFlagMap.set(country.countryName, country.flag);
  country.sites.forEach(site => {
    // A newspaper can appear in multiple site configs (e.g., BÃ¸rsen), but will map to the same country.
    if (!newspaperToCountryMap.has(site.newspaper || site.name)) {
      newspaperToCountryMap.set(site.newspaper || site.name, country.countryName);
    }
  });
});


export const TEXT_SELECTORS = {
  'Berlingske': '.article-body p',
  'BÃ¸rsen': [ '.article-content', 'meta[name="description"]' ],
  'Politiken': 'section#js-article-body .font-serif-body-20 p',
  'Finans.dk': 'p.container-text:not([class*="italic"])',
  'DN.no': '.dn-article-top .lead, .dn-content .dn-text p',
  'Axcel': 'div.article-content p',
  'Polaris': 'div.fl-module-fl-post-content p',
  'Finansavisen': [ '.c-article-regular__body__preamble, .c-article-regular__body p', 'meta[name="description"]' ],
  'Kapital': [ '.c-article-regular__body__preamble, .c-article-regular__body p', 'meta[name="description"]' ],
  'E24': 'article p[data-test-tag="lead-text"], article p.hyperion-css-1lemvax',
  'Nordic Capital': '.multi-column-rich-text--content-block .block-content p',
  'EQT': '.body-l-body-m p', 
  'FSN Capital': 'div.newspage__content p',
  'Altor': 'div.g-wysiwyg p',
  'Verdane': '.entry-content p',
};

# File: src/config/users.js
// src/config/users.js
// This file contains the list of users and their email notification subscriptions.

export const USERS = [
  {
    firstName: 'Alexandra',
    email: 'christiansenalexandra@gmail.com',
    countries: ['Denmark'],
  },
  {
    firstName: 'Mark',
    superUser: true,
    email: 'reconozco@gmail.com',
    countries: ['Denmark', 'Norway', 'Finland', 'Netherlands', 'Belgium', 'Pan-Nordic'],
  },
  // Add more users here in the future
];

# File: src/database.js
// src/database.js (version 1.0)
import mongoose from 'mongoose';
import { MONGO_URI } from './config/index.js';
import { logger } from './utils/logger.js';

export async function connectDatabase() {
    if (!MONGO_URI) {
        logger.fatal('MONGO_URI is not defined in environment variables. Exiting.');
        process.exit(1);
    }

    try {
        logger.info('Attempting to connect to MongoDB...');
        await mongoose.connect(MONGO_URI, {
            serverSelectionTimeoutMS: 5000,
        });
        logger.info('âœ… MongoDB connection successful.');
    } catch (error) {
        logger.fatal({ err: error }, 'âŒ CRITICAL: Failed to establish MongoDB connection.');
        process.exit(1);
    }
}

export async function disconnectDatabase() {
    try {
        await mongoose.disconnect();
        logger.info('MongoDB connection closed.');
    } catch (error) {
        logger.error({ err: error }, 'Error disconnecting from MongoDB.');
    }
}

# File: src/modules/ai/client.js
// src/modules/ai/client.js (version 2.0)
import OpenAI from 'openai';
import { OPENAI_API_KEY } from '../../config/index.js';
import { logger } from '../../utils/logger.js';

if (!OPENAI_API_KEY) {
    throw new Error('OPENAI_API_KEY is not defined in the environment variables.');
}

logger.info('ðŸ¤– Initializing OpenAI AI client...');

// The timeout and maxRetries are configured for robustness, suitable for production use.
const client = new OpenAI({
    apiKey: OPENAI_API_KEY,
    // BaseURL is omitted to use the official OpenAI endpoint by default.
    timeout: 90 * 1000, // 90 seconds
    maxRetries: 3,
});

export default client;

# File: src/modules/ai/eventProcessing.js
// src/modules/ai/eventProcessing.js (version 2.1)
import client from './client.js'; // Use the new centralized client
import { LLM_MODEL_ARTICLES, CONCURRENCY_LIMIT } from '../../config/index.js';
import { logger } from '../../utils/logger.js';
import { instructionCluster } from '../assessments/instructionCluster.js';
import { instructionSynthesize } from '../assessments/instructionSynthesize.js';
import { safeExecute } from '../../utils/helpers.js';

async function generateJsonResponse(model, instructions, userContent, temperature = 0.1) {
    const messages = [
        { role: 'system', content: JSON.stringify(instructions) },
        { role: 'user', content: userContent },
    ];

    const result = await safeExecute(() => client.chat.completions.create({
        model,
        messages,
        response_format: { type: "json_object" },
        // temperature,
        // This prevents the API from truncating the JSON response when clustering many articles.
        // max_tokens: 8192, 
    }));

    if (!result) return { error: 'API call failed' };

    try {
        return JSON.parse(result.choices[0].message.content);
    } catch (parseError) {
        logger.error({ err: parseError, content: result.choices[0].message.content }, "JSON Parsing Error in AI response");
        return { error: "JSON Parsing Error" };
    }
}

export async function clusterArticlesIntoEvents(articles) {
    logger.info(`Clustering ${articles.length} articles into unique events...`);
    const articlePayload = articles.map(a => ({
        id: a._id.toString(),
        headline: a.headline,
        source: a.newspaper,
        summary: (a.articleContent?.contents || []).join(' ').substring(0, 400),
    }));

    const userContent = JSON.stringify(articlePayload);
    const response = await generateJsonResponse(LLM_MODEL_ARTICLES, instructionCluster, userContent);

    if (response.error || !response.events) {
        logger.error('Failed to cluster articles.', { response });
        return [];
    }

    return response.events; // Expected format: [{ event_key: "...", article_ids: ["...", "..."] }]
}


export async function synthesizeEvent(articlesInCluster, historicalContext) {
    logger.info(`Synthesizing event for cluster with ${articlesInCluster.length} articles.`);

    const todayPayload = articlesInCluster.map(a => ({
        headline: a.headline,
        source: a.newspaper,
        full_text: (a.articleContent?.contents || []).join('\n'),
    }));

    const historyPayload = historicalContext.map(h => ({
        headline: h.headline,
        source: h.newspaper,
        published: h.createdAt,
        summary: (h.articleContent?.contents || []).join(' ').substring(0, 500),
    }));

    const userContent = JSON.stringify({
        todays_articles: todayPayload,
        historical_articles: historyPayload,
    });

    const response = await generateJsonResponse(LLM_MODEL_ARTICLES, instructionSynthesize, userContent, 0.2);

    if (response.error) {
        logger.error('Failed to synthesize event.', { response });
        return { error: 'Synthesis failed' };
    }
    
    // Expected format: { headline: "...", summary: "...", key_individuals: [...] }
    return response;
}

# File: src/modules/ai/index.js
// src/modules/ai/index.js (version 2.1)
import pLimit from 'p-limit';
import client from './client.js'; // Use the new centralized client
import { LLM_MODEL_TRIAGE, LLM_MODEL_ARTICLES, AI_BATCH_SIZE, CONCURRENCY_LIMIT, HEADLINES_RELEVANCE_THRESHOLD } from '../../config/index.js';
import { logger } from '../../utils/logger.js';
import { instructionHeadlines } from '../assessments/instructionHeadlines.js';
import { shotsInput as shotsInputHeadlines, shotsOutput as shotsOutputHeadlines } from '../assessments/shotsHeadlines.js';
import { instructionArticle } from '../assessments/instructionArticle.js';
import { shotsInput as shotsInputArticle, shotsOutput as shotsOutputArticle } from '../assessments/shotsArticle.js';
import { safeExecute, truncateString } from '../../utils/helpers.js';

const limit = pLimit(CONCURRENCY_LIMIT);
let isApiKeyInvalid = false;

/**
 * Performs a sanity check against the configured AI service (OpenAI).
 * @returns {Promise<boolean>}
 */
export async function performAiSanityCheck() {
    try {
        logger.info('ðŸ”¬ Performing AI service sanity check (OpenAI)...');
        const response = await client.chat.completions.create({
            model: "gpt-3.5-turbo", // Use a known, stable model for the check
            messages: [{ role: 'user', content: 'What is in one word the name of the capital of France' }],
            temperature: 0,
        }, { timeout: 20 * 1000 });
        const answer = response.choices[0].message.content.trim().toLowerCase();
        if (answer.includes('paris')) {
            logger.info('âœ… AI service sanity check passed.');
            return true;
        } else {
            logger.fatal(`OpenAI sanity check failed. Expected a response containing "Paris", but got: "${answer}".`);
            return false;
        }
    } catch (error) {
        if (error.status === 401) {
            logger.fatal(`OpenAI sanity check failed due to INVALID API KEY (401). Please verify your OPENAI_API_KEY in the .env file.`);
        } else {
            logger.fatal({ err: error }, 'OpenAI sanity check failed with an unexpected API error.');
        }
        isApiKeyInvalid = true;
        return false;
    }
}

/**
 * Verifies that the configured LLM models are available via the AI provider.
 * @param {string[]} requiredModels - An array of model ID strings to check.
 * @returns {Promise<boolean>}
 */
export async function checkModelPermissions(requiredModels) {
    logger.info('ðŸ”¬ Verifying permissions for configured OpenAI models...');
    try {
        const response = await client.models.list();
        const availableModels = new Set(response.data.map(model => model.id));
        for (const model of requiredModels) {
            if (!availableModels.has(model)) {
                logger.fatal(`Model validation failed. The configured model "${model}" is not available on OpenAI or you don't have permission. Please check your .env file.`);
                logger.info({ availableModels: [...availableModels] }, 'Available models for your API key:');
                return false;
            }
        }
        logger.info('âœ… All configured models are available.');
        return true;
    } catch (error) {
        logger.fatal({ err: error }, 'Failed to retrieve model list from OpenAI API.');
        isApiKeyInvalid = true;
        return false;
    }
}

async function generateAssessment(model, instructions, userContent, fewShotInputs = [], fewShotOutputs = []) {
    if (isApiKeyInvalid) { return { error: 'API Key is invalid. Halting further AI assessments.' }; }
    const messages = [ { role: 'system', content: JSON.stringify(instructions) } ];
    fewShotInputs.forEach((input, i) => {
        let shotContent = (typeof input === 'string') ? input : (input && input.articleText);
        if (shotContent && typeof shotContent === 'string') {
            messages.push({ role: 'user', content: shotContent });
            messages.push({ role: 'assistant', content: fewShotOutputs[i] });
        }
    });
    messages.push({ role: 'user', content: userContent });
    const apiCallPromise = safeExecute(() => client.chat.completions.create({
        model, messages, response_format: { type: "json_object" }, temperature: 1,
    }), {
        errorHandler: (err) => {
            if (err.status === 401) {
                isApiKeyInvalid = true;
                logger.fatal('OPENAI API KEY IS INVALID. Halting all AI requests.');
                return { error: 'Invalid OpenAI API Key' };
            }
            logger.error(`OpenAI API Error: ${err.name} - ${err.message}`);
            return { error: `OpenAI API Error: ${err.message}` };
        }
    });
    let timeoutHandle;
    const timeoutPromise = new Promise((resolve) => {
        timeoutHandle = setTimeout(() => resolve({ error: 'External watchdog timed out after 100s' }), 100 * 1000);
    });
    const result = await Promise.race([apiCallPromise, timeoutPromise]);
    clearTimeout(timeoutHandle);
    if (result.error) return result;
    try {
        return JSON.parse(result.choices[0].message.content);
    } catch (parseError) {
        logger.error(`JSON Parse Error: ${parseError.message}`);
        return { error: "JSON Parsing Error" };
    }
}


export async function assessHeadlinesInBatches(articles) {
    const batches = [];
    for (let i = 0; i < articles.length; i += AI_BATCH_SIZE) {
        batches.push(articles.slice(i, i + AI_BATCH_SIZE));
    }
    logger.info(`Assessing ${articles.length} headlines in ${batches.length} batches...`);
    const allAssessedPromises = [];
    let completedBatches = 0;

    for (const batch of batches) {
        allAssessedPromises.push(
            limit(async () => {
                const headlinesText = batch.map(a => a.headline).join('\n- ');
                const response = await generateAssessment(LLM_MODEL_TRIAGE, instructionHeadlines, headlinesText, shotsInputHeadlines, shotsOutputHeadlines);
                
                completedBatches++;
                
                // --- FIX: Restore detailed per-headline logging for debugging ---
                if (response && response.assessment && Array.isArray(response.assessment)) {
                    logger.info(`--- Batch ${completedBatches}/${batches.length} Results ---`);
                    batch.forEach((article, i) => {
                        const assessment = response.assessment[i];
                        if (assessment && typeof assessment.relevance_headline === 'number') {
                            const score = assessment.relevance_headline;
                            const comment = assessment.assessment_headline || 'No comment.';
                            const emoji = score >= HEADLINES_RELEVANCE_THRESHOLD ? 'âœ…' : 'âŒ';
                            const source = article.source || 'Unknown';
                            logger.info(`${emoji} [${String(score).padStart(3)}] "${truncateString(article.headline, 60)}" (${source}) | ${truncateString(comment, 45)}`);
                        } else {
                            const source = article.source || 'Unknown';
                            logger.warn(`- Malformed assessment for: "${truncateString(article.headline, 70)}" (${source})`);
                        }
                    });
                } else {
                    logger.error(`âŒ Headline assessment failed for batch ${completedBatches}/${batches.length}. Reason: ${response.error || 'Malformed response'}`);
                }
                // --- END FIX ---

                if (response.error || !response.assessment || !Array.isArray(response.assessment) || response.assessment.length !== batch.length) {
                    return batch.map(article => ({ ...article, relevance_headline: 0, assessment_headline: response.error || 'AI assessment failed.' }));
                }

                return batch.map((article, i) => ({ ...article, ...response.assessment[i] }));
            })
        );
    }
    
    const assessedBatches = await Promise.all(allAssessedPromises);
    logger.info('Finished assessing all headline batches.');
    return assessedBatches.flat();
}

export async function assessArticleContent(article) {
    logger.info(`Assessing content for: "${truncateString(article.headline, 60)}"`);
    
    // --- FIX: Combine headline and body to give the AI full context ---
    const articleText = `HEADLINE: ${article.headline}\n\nBODY:\n${article.articleContent.contents.join('\n')}`;
    
    const response = await generateAssessment(LLM_MODEL_ARTICLES, instructionArticle, articleText, shotsInputArticle, shotsOutputArticle);
    
    if (response.error) {
        logger.error(`Article assessment failed for ${article.link}.`);
        return { ...article, error: `AI Error: ${response.error}` };
    }
    return { ...article, ...response, error: null };
}

# File: src/modules/ai/rag.js
// src/modules/ai/rag.js
import Article from '../../../models/Article.js';
import { logger } from '../../utils/logger.js';
import { generateEmbedding, cosineSimilarity } from '../../utils/vectorUtils.js';

const SIMILARITY_THRESHOLD = 0.65; // Tune this threshold as needed
const MAX_CONTEXT_ARTICLES = 3;

/**
 * Finds historical articles similar to a given set of new articles.
 * @param {Array<Object>} articlesInCluster - The new articles forming an event.
 * @returns {Promise<Array<Object>>} A promise that resolves to an array of relevant historical articles.
 */
export async function findSimilarArticles(articlesInCluster) {
    logger.info('RAG: Searching for historical context...');
    if (!articlesInCluster || articlesInCluster.length === 0) return [];

    // 1. Create a query embedding from the new event's content
    const queryText = articlesInCluster.map(a => a.headline).join('\n');
    const queryEmbedding = await generateEmbedding(queryText);

    // 2. Fetch all historical articles with embeddings from the database
    // In a large-scale app, you'd add filters (e.g., date range) here.
    const historicalCandidates = await Article.find({
        embedding: { $exists: true, $ne: null }
    }).lean();

    if (historicalCandidates.length === 0) {
        logger.warn('RAG: No historical articles with embeddings found to search against.');
        return [];
    }

    // 3. Calculate similarity for each candidate
    const scoredArticles = [];
    for (const candidate of historicalCandidates) {
        const similarity = cosineSimilarity(queryEmbedding, candidate.embedding);
        if (similarity >= SIMILARITY_THRESHOLD) {
            scoredArticles.push({ ...candidate, similarity });
        }
    }
    
    // 4. Sort by similarity and return the top N
    scoredArticles.sort((a, b) => b.similarity - a.similarity);
    const topContext = scoredArticles.slice(0, MAX_CONTEXT_ARTICLES);
    
    logger.info(`RAG: Found ${topContext.length} relevant historical articles.`);
    return topContext;
}

# File: src/modules/assessments/instructionArticle.js
// src/modules/assessments/instructionArticle.js
export const instructionArticle = {
  whoYouAre:
    'You are a private wealth relevance analyst specialized in scouring newspapers and other media.',

  whatYouDo:
    'You analyze full-text articles. Your primary goal is to identify if they report a direct, substantial private wealth event (over $30 million) benefiting private individuals, families, their holding companies, or family offices/foundations. Additionally, you flag articles discussing significant business activities by known Rich List individuals.',

  writingStyle:
    'Use concise, factual English. Avoid speculation. Maintain a formal tone.',

  outputFormatDescription:
    'Respond only with a valid JSON object using this structure: { "topic": "Short summary of the event", "relevance_article": 95, "assessment_article": "Rationale for you giving the score", "amount": 500, "key_individuals": [{"name": "Name", "role_in_event": "Founder", "company": "Company Name", "email_suggestion": "name@company.com"}], "background": "Contextual info with a focus on the recipient of the wealth" }',

guidelines: `
Focus on:
1.  **Direct Wealth Events**: Articles involving direct wealth transfers (company sales, IPOs, M&A, inheritances, significant asset sales) to named individuals/families, their holding companies, or family offices/foundations, where the new wealth clearly exceeds $30 million. Obituaries of very wealthy individuals are also key.

2.  **Rich List Individual Activity**: Articles featuring prominent Rich List individuals (e.g., Martin Thorborg, Anders Holch Povlsen, Kirk Kristiansen family members, etc.) discussing:
    *   Significant strategic decisions for their main businesses.
    *   Major investments or divestments, even if the article doesn't explicitly state a >$30M personal gain but the context implies substantial financial activity.
    *   Interviews where they speak at length about their company's performance or future plans that could significantly impact their wealth.

3.  **High-Value Strategic Intelligence**: News concerning major strategic developments at large, publicly-listed companies that are central to the region's wealth creation landscape (e.g., DSV, Maersk, Novo Nordisk), especially when quoting C-level executives. While not a direct private wealth event, this is crucial context.

Exclude any articles primarily about:
-   A Private Equity or Venture Capital firm's own operational news, such as fundraising or closing a new fund. Focus on their *transactions*.
-   Investment decisions made by large institutional pension funds (like ATP).
-   Companies or projects without a clearly identified private individual/family beneficiary (unless it's a known Rich List holding or a key company from Guideline #3).
-   Foreign or institutional beneficiaries (unless it's an acquisition *from* a private owner).
-   Routine company performance reports *unless* they directly quote a Rich List owner or CEO discussing significant strategic implications.
-   Minor news or public appearances not related to core business strategy.
-   Philanthropy.
`,

  scoring: `
  Score 95-100 for:
  -   **Direct Wealth Events (Guideline #1).** Confirmed, direct, substantial wealth transfers to private individuals/families. Assessment must state "Direct wealth event."

  Score 75-94 for:
  -   **Rich List Individual Activity (Guideline #2).** A known Rich List person making significant business moves or statements. Assessment must state "High relevance due to [Rich List Person]'s strategic involvement."
  -   **High-Value Strategic Intelligence (Guideline #3).** A major update on a key company like DSV or Maersk. Assessment must state "Strategic intelligence on a key wealth-generating entity."

  Score 50-74 for:
  -   Strongly implied but unconfirmed wealth events, smaller transactions (<$30M), or news about Rich List individuals that is business-related but less impactful.

  Score 0-49 for:
  -   Irrelevant news, general company news without significant strategic input from top leadership, or anything from the 'Exclude' list.
  `,

  vitals:
    `Pay extremely close attention to articles involving known Rich List individuals and their core business activities.
     An interview with a founder of a large family company for example (e.g. John Blem being interviewed to tell about Milestone) should score 100.
    `,

  reiteration:
    'Only respond with a properly formatted JSON object. If an article is about a Rich List person discussing their business significantly, assign a relevance score (typically 70+) reflecting this importance. Clearly state the reason in the assessment.',
};

# File: src/modules/assessments/instructionCluster.js
// src/modules/assessments/instructionCluster.js

export const instructionCluster = {
  whoYouAre: "You are a news clustering analyst. Your goal is to identify which news articles are reporting on the exact same real-world event.",
  whatYouDo: "You will receive a JSON array of articles, each with an ID, headline, and summary. You must group articles that describe the same underlying event (e.g., the same company sale, the same IPO, the same investment).",
  guidelines: `
    1.  **Analyze Content:** Read the headline and summary of each article to understand the core event it describes.
    2.  **Group by Event:** If two or more articles are about the same event (e.g., 'Visma buys InnovateAI'), they belong in the same group. Articles about different events (e.g., 'Polaris invests in NewCo', 'Axcel sells OldCo') belong in separate groups.
    3.  **Create a Unique Event Key:** For each unique event group, create a short, descriptive, lowercase key. The key should include the main entities and the action, plus today's date in YYYY-MM-DD format. Example: \`acquisition-visma-innovateai-2024-05-20\`.
    4.  **Handle Singletons:** If an article describes an event that no other article covers, it forms its own group of one.
    5.  **Be Conservative:** If you are not highly confident that two articles describe the exact same event, place them in separate groups. It is better to have two small groups than to incorrectly merge two distinct events.
  `,
  outputFormatDescription: `
    Respond ONLY with a valid JSON object with a single top-level key "events".
    The value of "events" should be an array of objects.
    Each object in the array represents one unique event and must have two keys:
    - "event_key": The unique, descriptive key you created (e.g., "acquisition-visma-innovateai-2024-05-20").
    - "article_ids": An array of strings, where each string is the ID of an article belonging to this event.

    Example Response:
    {
      "events": [
        {
          "event_key": "acquisition-visma-innovateai-2024-05-20",
          "article_ids": ["60d21b4667d0d8992e610c85", "60d21b4667d0d8992e610c88"]
        },
        {
          "event_key": "investment-polaris-newco-2024-05-20",
          "article_ids": ["60d21b4667d0d8992e610c91"]
        }
      ]
    }
  `,
  reiteration: "Your entire response must be a single, valid JSON object as described. Do not include any other text, explanations, or markdown formatting."
};

# File: src/modules/assessments/instructionHeadlines.js
// src/modules/assessments/instructionHeadlines.js
export const instructionHeadlines = {
  whoYouAre: 'You are a wealth management analyst.',
  whatYouDo:
    'You assess whether news paper headlines describe immediate, substantial private wealth events.',
  guidelines: `
Include only:
- Major liquidity events for private individuals, families, their family offices, or family foundations (e.g., company sales, IPOs benefiting founders, substantial asset sales) generating >$50M.
- Obituaries or similar events of ultra high net worth individuals leading to substantial wealth transfer/inheritance.
- Significant transactions or capital events within privately-held/family-owned holding companies of rich list families that clearly indicate a substantial change in the family's private wealth (e.g., large dividend payouts from holding to family, sale of a major subsidiary by the holding company).
- Any headlines directly indicating substantial (>$50M) wealth generation or transfer for rich list families or their primary business entities where the family is the clear beneficiary (e.g., "Bestseller owner Anders Holch Povlsen acquires major real estate portfolio for DKK 1 billion", "Grundfos owner foundation distributes DKK 500 million to Due Jensen family").
- **SPECIAL ATTENTION**: News involving known Rich List individuals like **Martin Thorborg**, Anders Holch Povlsen, the Kirk Kristiansen family (LEGO), the Holch Povlsen family (Bestseller), the Due Jensen family (Grundfos), etc., especially related to their business or investment activities should be scored with high relevance (70-100).

Strictly exclude:
- A Private Equity or Venture Capital firm's own operational news, such as fundraising, closing a new fund, or hiring partners. Focus on their *transactions* (buying/selling companies), not their internal business.
- Investment decisions made by large institutional pension funds (like ATP), as these do not represent private family wealth.
- General corporate news such as expansions, new product launches, operational performance (profits/losses of publicly traded companies). **EXCEPTION:** A takeover bid or M&A of a public company is RELEVANT.
- Headlines without direct, immediate, and substantial (>$50M) wealth impact for private individuals/families (unless it's a Rich List individual per "SPECIAL ATTENTION" rule).
- Foreign corporate or public institution activity, unless it's a direct acquisition/sale involving a private individual/family.
- Philanthropic donations by foundations or individuals (unless on the rich list)
- Appointments to boards or executive positions.
- General market commentary or economic trends.

Relevance Scoring:
- 91â€“100: Clear and substantial private wealth gain/transfer (>$50M) for individuals/families; news directly concerning Rich List families and significant activities of their primary businesses that clearly impact family wealth. Obituaries of UHNW individuals.
- 71â€“90: Likely or partial substantial wealth gain (potentially >$50M, or an IPO of a significant family-owned company). News about significant investments/divestments by Rich List family holdings where the private benefit is strongly implied. For Rich List individuals (like Martin Thorborg), this score applies if the event suggests significant business involvement or strategy shift.
- 51â€“70: Moderate or indirect wealth gain (typically <$50M but still a clear private wealth event).
- 31â€“50: Minor or future potential gain, or wealth event of unclear substantiality.
- 0â€“30: No private wealth relevance, or event clearly below significance thresholds, or anything from the 'Strictly Exclude' list.
`,
  scoring: `
Examples of High Relevance (91â€“100):
- "Danish family sells tech company for EUR 150M"
- "LEGO heir passes away leaving substantial estate"
- "Grundfos owner Poul Due Jensen's family holding company, KIRKBI A/S, acquires significant UK property portfolio for DKK 2 billion"
- "Bestseller owner Anders Holch Povlsen receives DKK 1 billion dividend from family holding company"
- "Martin Thorborg's company Dinero acquired by Visma" 
- "Anders Holch Povlsen invests DKK 500 million in new green tech venture"

Examples of Moderate/High Relevance (70-89 for Rich List):
- "Martin Thorborg's new AI venture secures seed funding" (Implies potential future wealth, activity of rich list person)
- "Business-update: Martin Thorborg erkender: Kunstig intelligens kan true hans forretning" (Significant strategic statement from Rich List individual about their business - score 70-80 to flag for review)

Examples of Low Relevance (0â€“29):
- "Boeing raises billions to pay debts"
- "Rockwool plans global expansion"
- "Homeowners to receive tax relief"
- "Grundfos (the company) announces record profits"
- "Danfoss heir appointed to new board" 
- "Martin Wellesen gives a public lecture on entrepreneurship" (Not a wealth event for him, and not on rich list)
- "Axcel closes its seventh fund at EUR 1.3 billion" (PE firm operational news)
- "ATP sells its stake in Bavarian Nordic" (Pension fund activity)
`,
  vitals: `
  **VITAL: Headlines mentioning names from the Rich List (e.g., Martin Thorborg, Holch Povlsen, Kirk Kristiansen) should be considered highly relevant (score 70-100).**
    But also an interview with a founder of a large family company for example (e.g. John Blem being interviewed to tell about Milestone) should score 100.
`,
  outputFormatDescription: `
Respond in English with a valid JSON object, exactly formatted like below.
It is vital that your response has a top-level "assessment" key:
{
  "assessment": [
    {
      "relevance_headline": 95,
      "assessment_headline": "Imminent personal wealth generation due to company sale."
    }
  ]
}
NEVER RETURN A PLAIN ARRAY.
`,
};

# File: src/modules/assessments/instructionSynthesize.js
// src/modules/assessments/instructionSynthesize.js

export const instructionSynthesize = {
  whoYouAre: "You are an expert financial journalist working for an exclusive executive briefing service in English.",
  whatYouDo: "You will receive JSON data containing one or more articles about today's news event, and potentially some historical articles for context. Your task is to synthesize this information into a concise, high-value intelligence brief.",
  writingStyle: "Factual, dense, and objective, in the style of the Wall Street Journal or Financial Times. Use clear, professional English. Omit filler words and speculation.",
  guidelines: `
    1.  **Prioritize Today's News:** Your summary must be based on the information provided in the \`todays_articles\` array. This is the core of the brief.
    2.  **Use Historical Context:** If \`historical_articles\` are provided, use them to add depth and background to the summary. For example, if today's news is an acquisition, a historical article about the company's last funding round is crucial context. Mention this context briefly (e.g., 'This follows a funding round last year...').
    3.  **Create a New Headline:** Write a new, overarching headline for the event. It should be clear, concise, and capture the essence of the news.
    4.  **Write a Concise Summary:** Write a new summary of the event. **The summary must be no more than 4 sentences and under 90 words.** It should seamlessly integrate the key facts from today's news with any relevant historical context.
    5.  **Identify and Merge Key Individuals:**
        *   From the text and provided data, identify the key individuals involved (founders, sellers, buyers, etc.).
        *   Create a single, de-duplicated list of these individuals.
        *   For each individual, you must include their name, role, company, and any \`email_suggestion\` found in the source data. If multiple suggestions exist for one person, pick the most plausible one.
  `,
  outputFormatDescription: `
    Respond ONLY with a valid JSON object with the following structure:
    {
      "headline": "New, synthesized headline here. In English.",
      "summary": "New, synthesized summary here. In English. It must be under 90 words and no more than 4 sentences.",
      "key_individuals": [
        {
          "name": "Full Name",
          "role_in_event": "e.g., Founder & Seller",
          "company": "Company Name",
          "email_suggestion": "name.surname@company.com"
        }
      ]
    }
  `,
  reiteration: "Your entire response must be a single, valid JSON object. Adhere strictly to the length and sentence constraints for the summary. The quality of the brief is paramount."
};

# File: src/modules/assessments/shotsArticle.js
// src/modules/assessments/shotsArticle.js

export const shotsInput = [
  { articleText: 'Nyt anlÃ¦g ved Esbjerg skal producere klimavenlig brint. DirektÃ¸r Jens Hansen udtaler...' },
  { articleText: 'Aarstiderne, stiftet af SÃ¸ren Ejlersen, er blevet solgt til en international fÃ¸devaregigant for et trecifret millionbelÃ¸b.' },
  { articleText: 'Many homeowners will see lower property taxes in 2025 and 2026' },
  { articleText: 'The MÃ¸ller family has sold their shipping software company, NaviTech, for $500M.' },
  { articleText: 'Stellantis, the multinational car company, has reported that it stands to lose over 300 million kroner due to new US tariffs.' }, // NEW NEGATIVE EXAMPLE
  { articleText: 'The family-owned conglomerate USTC, owned by the Ã˜stergaard-Nielsen family, is disputing a multimillion-krone claim from the Nordic Waste bankruptcy trustee.' }, // NEW RICH LIST PROXIMITY EXAMPLE
  { articleText: 'CEO of family-owned Scandinavian tech firm, Anna Schmidt, sells for $120M' },
  { articleText: 'The Grundfos holding company, owned by the Due Jensen family, has announced a dividend of 300 million kroner to be distributed among family members.' },
  { articleText: 'Rockwool plans massive global expansions' },
];

export const shotsOutput = [
  // REFINED: Updated to new JSON structure
  JSON.stringify({
    topic: 'Green hydrogen plant in Esbjerg',
    relevance_article: 10,
    assessment_article: 'Infrastructure project with no direct personal wealth transfer.',
    amount: 0,
    key_individuals: [],
    background: 'Public or corporate energy initiative.',
  }),
  // REFINED: Updated to new JSON structure with email inference
  JSON.stringify({
    topic: 'Sale of Aarstiderne',
    relevance_article: 95,
    assessment_article: 'Clear private wealth event for Scandinavian founder.',
    amount: 150, // Assuming DKK millions -> USD
    key_individuals: [{
      "name": "SÃ¸ren Ejlersen",
      "role_in_event": "Founder & Seller",
      "company": "Aarstiderne",
      "email_suggestion": "soren.ejlersen@aarstiderne.com"
    }],
    background: 'Sale of private Scandinavian company.',
  }),
  // REFINED: Updated to new JSON structure
  JSON.stringify({
    topic: 'Property tax cuts for homeowners',
    relevance_article: 15,
    assessment_article: 'General tax relief is not a substantial direct wealth event.',
    amount: 0,
    key_individuals: [],
    background: 'Policy affecting many, not enriching individuals.',
  }),
  // REFINED: Updated to new JSON structure with email inference
  JSON.stringify({
    topic: 'Sale of NaviTech',
    relevance_article: 100,
    assessment_article: 'Substantial wealth event clearly benefiting a Scandinavian family.',
    amount: 500,
    key_individuals: [{
      "name": "MÃ¸ller family",
      "role_in_event": "Seller",
      "company": "NaviTech",
      "email_suggestion": "contact@navitech.com"
    }],
    background: 'Private business transaction.',
  }),
  // NEW: Output for the Stellantis negative example
  JSON.stringify({
    topic: 'Tariff losses for Stellantis',
    relevance_article: 5,
    assessment_article: 'Irrelevant. Article describes financial losses for a foreign multinational corporation.',
    amount: -300,
    key_individuals: [],
    background: 'General automotive industry news.',
  }),
  // NEW: Output for the USTC Rich List Proximity example
  JSON.stringify({
    topic: 'USTC legal dispute over Nordic Waste claim',
    relevance_article: 60,
    assessment_article: 'High relevance due to the involvement of a Rich List family (Ã˜stergaard-Nielsen/USTC) in a significant financial event.',
    amount: 0,
    key_individuals: [{
        "name": "Ã˜stergaard-Nielsen family",
        "role_in_event": "Owner",
        "company": "USTC",
        "email_suggestion": "contact@ustc.dk"
    }],
    background: 'Ongoing legal and financial issue for a major family holding company.',
  }),
  // REFINED: Updated to new JSON structure with email inference
  JSON.stringify({
    topic: 'Sale of Scandinavian tech firm',
    relevance_article: 95,
    assessment_article: 'Substantial wealth event for private Scandinavian individual.',
    amount: 120,
    key_individuals: [{
      "name": "Anna Schmidt",
      "role_in_event": "CEO & Seller",
      "company": "Unknown Tech Firm",
      "email_suggestion": null
    }],
    background: 'Private tech company acquisition.',
  }),
  // REFINED: Updated to new JSON structure
  JSON.stringify({
    topic: 'Grundfos family dividend',
    relevance_article: 95,
    assessment_article: 'Direct and substantial wealth transfer to a private Scandinavian family.',
    amount: 45, // 300M DKK -> USD
    key_individuals: [{
        "name": "Due Jensen family",
        "role_in_event": "Recipient",
        "company": "Grundfos",
        "email_suggestion": null
    }],
    background: 'Dividend from a family-owned holding company.',
  }),
  // REFINED: Updated to new JSON structure
  JSON.stringify({
    topic: 'Rockwool global expansion',
    relevance_article: 10,
    assessment_article: 'Corporate strategy of a public company, no individual wealth generation.',
    amount: 0,
    key_individuals: [],
    background: 'Public company operations.',
  }),
];

# File: src/modules/assessments/shotsHeadlines.js
// src/modules/assessments/shotsHeadlines.js
export const shotsInput = [
  // --- This set is unchanged but assessments are refined for consistency ---
  [
    'Rockwool stÃ¥r foran massive udvidelser over hele kloden',
    'Boeing henter 145 mia. kr.',
    'Boligejere med for stor grundskyldsregning har udsigt til hjÃ¦lp',
    'Kriseramte Boeing vil rejse milliarder for at tilbagebetale gÃ¦ld',
    'Aarstiderne solgt til gigant',
    'Scandinavian family sells company for $500M',
  ].join('\n- '),

  // --- This set is unchanged but assessments are refined for consistency ---
  [
    'Local football match results',
    'New Scandinavian tech startup launched',
    'Vestas CEO buys shares',
    'Vestas CEO sells significant shares',
    'Maersk heir sells estate in Copenhagen',
    'Scandinavian lottery winner claims prize',
  ].join('\n- '),

  // --- This set is unchanged but assessments are refined for consistency ---
  [
    'A.P. Moller Foundation donates $100 million to charity',
    'LEGO family (KIRKBI A/S) in acquisition talks for rival toy company for DKK 5 billion',
    'Danfoss heir (Bitten & Mads Clausen Foundation) announces succession plan for family business leadership',
    'Widex and Demant plan to merge operations',
    'Novo Nordisk (public company) announces stock split',
    '3Shape (privately owned) is working on an IPO',
  ].join('\n- '),

  // --- NEW: This set explicitly teaches the rules from your feedback ---
  [
    'NÃ¥|SpÃ¥r milliard-smell fra toll', // Stellantis example
    'Familieejet koncern bestrider millionkrav efter Nordic Waste', // USTC example
    'Fynske bankers fusionsplaner skydes ned af storaktionÃ¦r' // Public bank merger
  ].join('\n- '),

  // --- This set is refined to better teach Rich List Proximity ---
  [
    'Grundfos owner (Poul Due Jensen Foundation) announces DKK 300 million dividend distribution to family members',
    'Bestseller owner Anders Holch Povlsen personally acquires Scottish estate for DKK 150 million',
    "Martin Thorborg's AI Startup Secures Funding",
    'Martin Thorborg giver et foredrag om ivÃ¦rksÃ¦tteri' // Example of non-relevant Rich List news
  ].join('\n- '),
];

export const shotsOutput = [
  JSON.stringify({
    assessment: [
      {
        relevance_headline: 10,
        assessment_headline:
          'Corporate expansion (Rockwool is public), no direct private wealth generation for Scandinavian individuals.',
      },
      {
        relevance_headline: 0,
        assessment_headline:
          'Foreign corporate activity, no relevance to Scandinavian private wealth.',
      },
      {
        relevance_headline: 15, // Refined score
        assessment_headline:
          'Tax relief provides benefit, but not a substantial direct wealth transfer.',
      },
      {
        relevance_headline: 0,
        assessment_headline:
          'Foreign corporate debt repayment, no relevance to Scandinavian private wealth.',
      },
      {
        relevance_headline: 95,
        assessment_headline:
          'Acquisition likely results in substantial wealth for Scandinavian founders/owners.',
      },
      {
        relevance_headline: 100,
        assessment_headline:
          'Clear substantial private wealth event for Scandinavian family.',
      },
    ],
  }),
  JSON.stringify({
    assessment: [
      { relevance_headline: 0, assessment_headline: 'Not a wealth event.' },
      {
        relevance_headline: 10,
        assessment_headline:
          'New company, no immediate substantial wealth transfer.',
      },
      {
        relevance_headline: 5,
        assessment_headline:
          'Public market activity by an individual, not a substantial private wealth generation event.',
      },
      {
        relevance_headline: 30,
        assessment_headline:
          'Share sale by individual, possibly some personal gain, but unlikely to be a major liquidity event based on headline alone.',
      },
      {
        relevance_headline: 95,
        assessment_headline:
          "Clear wealth event (>$30M implied by 'Maersk heir' and 'estate in Copenhagen') benefiting Scandinavian private individual.",
      },
      {
        relevance_headline: 40, // Refined score
        assessment_headline:
          'Private wealth event, but likely below significance threshold.',
      },
    ],
  }),
  JSON.stringify({
    assessment: [
      {
        relevance_headline: 0,
        assessment_headline:
          'Foundation donation, no personal private wealth involved for the family.',
      },
      {
        relevance_headline: 95,
        assessment_headline:
          "Significant acquisition by rich list family's holding company (KIRKBI A/S), likely impacting family's ultimate wealth substantially.",
      },
      {
        relevance_headline: 30,
        assessment_headline:
          'Succession planning in a family business suggests future wealth considerations, not an immediate substantial wealth event for individuals.',
      },
      {
        relevance_headline: 70,
        assessment_headline:
          'Merger of two significant Scandinavian-founded companies, potential for substantial wealth implications for any remaining private owners.',
      },
      {
        relevance_headline: 0,
        assessment_headline:
          'Public market action by a public company, no personal private wealth transfer.',
      },
      {
        relevance_headline: 80,
        assessment_headline:
          'Potential substantial private wealth event if IPO proceeds benefit Scandinavian founders/owners significantly.',
      },
    ],
  }),
  // --- NEW: Output for the new example set ---
  JSON.stringify({
    assessment: [
        {
            relevance_headline: 5,
            assessment_headline: "Irrelevant. News about a foreign multinational (Stellantis) and financial losses due to tariffs."
        },
        {
            relevance_headline: 60,
            assessment_headline: "Relevant due to Rich List family involvement (USTC owners) in a significant legal/financial dispute."
        },
        {
            relevance_headline: 10,
            assessment_headline: "Irrelevant. Merger of publicly-listed, non-family-owned banks."
        }
    ]
  }),
  // --- REFINED: Output for the Rich List Proximity set ---
  JSON.stringify({
    assessment: [
      {
        relevance_headline: 95,
        assessment_headline:
          'Clear substantial private wealth event for the Scandinavian Due Jensen family via distribution from their foundation.',
      },
      {
        relevance_headline: 90,
        assessment_headline:
          'Substantial personal acquisition by Scandinavian rich list individual Anders Holch Povlsen, a clear private wealth event.',
      },
      {
        relevance_headline: 85,
        assessment_headline:
          'High relevance. A new venture by a known Rich List individual (Martin Thorborg) securing funding is a significant potential wealth event.',
      },
      {
        relevance_headline: 0,
        assessment_headline: "Irrelevant. Rich List individual's public appearance is not a wealth event."
      }
    ],
  }),
];

# File: src/modules/email/components/articleFormatter.js
// src/modules/email/components/articleFormatter.js (version 2.0)
import { logger } from '../../../utils/logger.js';
import { truncateString } from '../../../utils/helpers.js';

function createArticleCard(article) {
    const {
        link,
        headline,
        source,
        contacts,
        summary,
        assessmentText,
        relevanceScore,
        callToActionText,
    } = article;

    const scoreColor = relevanceScore >= 80 ? '#27ae60' : relevanceScore >= 50 ? '#f39c12' : '#c0392b';

    const contactsHtml = (contacts && contacts.length > 0)
        ? `<p style="margin: 0 0 15px; font-size: 14px; color: #555;"><strong>Contacts:</strong> ${contacts.join(', ')}</p>`
        : '';

    return `
    <div style="border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 20px; padding: 20px; background-color: #ffffff; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
        <h3 style="margin-top: 0; margin-bottom: 10px; font-size: 18px; color: #333;">
            <a href="${link}" style="color: #007bff; text-decoration: none;">${headline}</a>
        </h3>
        <p style="margin: 0 0 15px; font-size: 14px; color: #777;"><strong>Source:</strong> ${source}</p>
        ${contactsHtml}
        <p style="margin: 0 0 15px; font-size: 15px; color: #555; line-height: 1.6;">${summary}</p>
        <div style="background-color: #f8f9fa; border: 1px solid #dee2e6; border-radius: 6px; padding: 15px; margin-bottom: 15px;">
            <p style="margin: 0; font-size: 14px; color: #333;">
                <strong>System Assessment:</strong> <span style="font-weight: bold; color: ${scoreColor};">[Score: ${relevanceScore}]</span> ${assessmentText}
            </p>
        </div>
        <a href="${link}" style="display: inline-block; background-color: #007bff; color: #ffffff; padding: 10px 15px; border-radius: 5px; text-decoration: none; font-weight: bold; font-size: 14px;">
            ${callToActionText}
        </a>
    </div>
    `;
}

export function formatArticleForEmail(article) {
    if (!article || typeof article !== 'object' || !article.link || !article.headline) {
        logger.warn(`formatArticleForEmail: Invalid article object provided.`, { articlePreview: article });
        return `<p style="color:red;">Error: Article data was invalid.</p>`;
    }

    const genericArticleData = {
        link: article.link,
        headline: article.headline,
        source: article.source || article.newspaper || 'N/A',
        contacts: article.contacts || [],
        summary: 'No summary available.',
        assessmentText: article.assessment_article || article.assessment_headline || 'Assessment not available.',
        relevanceScore: article.relevance_article ?? article.relevance_headline ?? 'N/A',
        callToActionText: 'Read Full Article â†’',
    };

    if (article.articleContent && typeof article.articleContent === 'object') {
        const { contents } = article.articleContent;
        if (contents && Array.isArray(contents) && contents.length > 0) {
            genericArticleData.summary = truncateString(contents.join(' '), 250);
        }
    }
    
    if (genericArticleData.summary === 'No summary available.') {
      genericArticleData.summary = truncateString(genericArticleData.assessmentText, 250);
    }

    try {
        return createArticleCard(genericArticleData);
    } catch (error) {
        logger.error(`Error creating article card for email: "${article.headline}"`, { errorMessage: error.message });
        return `<p style="color:red;">Error formatting article: ${truncateString(article.headline, 50)}</p>`;
    }
}

# File: src/modules/email/components/emailBodyBuilder.js
// src/modules/email/components/emailBodyBuilder.js
import { logger } from '../../../utils/logger.js';
import { EMAIL_CONFIG } from '../../../config/index.js';
import { LOGO_URL } from '../constants.js';
import { formatEventForEmail } from './eventFormatter.js';
import { countryNameToFlagMap } from '../../../config/sources.js';

function createEmailWrapper(bodyContent, subject) {
    return `
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>${subject}</title>
    </head>
    <body style="margin: 0; padding: 0; font-family: Helvetica, Arial, sans-serif; background-color: #f4f4f4;">
        <table width="100%" border="0" cellspacing="0" cellpadding="0" style="background-color: #f4f4f4;">
            <tr><td align="center">
                <table width="600" border="0" cellspacing="0" cellpadding="20" style="max-width: 600px; width: 100%; background-color: #ffffff; margin-top: 20px; margin-bottom: 20px;">
                    <tr><td>${bodyContent}</td></tr>
                </table>
            </td></tr>
        </table>
    </body>
    </html>`;
}

export function createPersonalizedEmailBody(user, eventsByCountry, subject) {
    if (!user || !eventsByCountry || Object.keys(eventsByCountry).length === 0) {
        logger.warn('createPersonalizedEmailBody: Missing user or events data.');
        return null;
    }

    let formattedEventsHtml = '';
    for (const [country, events] of Object.entries(eventsByCountry)) {
        const flag = countryNameToFlagMap.get(country) || 'ðŸŒ';
        formattedEventsHtml += `<h2 style="font-size: 22px; color: #333; border-bottom: 2px solid #eee; padding-bottom: 10px; margin-top: 40px;">${flag} ${country}</h2>`;
        formattedEventsHtml += events.map(formatEventForEmail).join('');
    }

    const mainContent = `
        <div style="text-align: center; padding-bottom: 20px; border-bottom: 1px solid #eeeeee;">
            <img src="${LOGO_URL}" alt="${EMAIL_CONFIG.brandName} Logo" style="max-width: 150px; height: auto;">
        </div>
        <h1 style="color: #333333; text-align: center; margin-top: 20px;">${subject}</h1>
        <p style="font-size: 16px; color: #555555; text-align: left;">
            Hi ${user.firstName},
            <br><br>
            Here are the latest relevant events identified for you:
        </p>

        <div style="text-align: center; margin: 25px 0;">
            <p style="font-size: 14px; color: #555; margin-bottom: 10px;">ðŸ’¥ <strong>New Feature!</strong></p>
            <a href="https://headlines-client.vercel.app" target="_blank" style="background-color: #ffc107; color: #212529; padding: 12px 25px; text-decoration: none; border-radius: 5px; font-weight: bold; font-size: 16px; display: inline-block;">
                View History
            </a>
        </div>
        
        ${formattedEventsHtml}

        <p style="font-size: 16px; color: #555555; text-align: left;">
            Best Regards,<br>The Wealth Insight Team
        </p>
        <div style="text-align: center; margin-top: 30px; padding-top: 20px; border-top: 1px solid #eeeeee; font-size: 12px; color: #888888;">
            <p>${EMAIL_CONFIG.brandName} | ${EMAIL_CONFIG.companyAddress}</p>
            <p><a href="${EMAIL_CONFIG.unsubscribeUrl}" style="color: #888888;">Unsubscribe</a></p>
        </div>
    `;

    return createEmailWrapper(mainContent, subject);
}

# File: src/modules/email/components/eventFormatter.js
// src/modules/email/components/eventFormatter.js
import { logger } from '../../../utils/logger.js';

function createEventBriefCard(event) {
    const {
        synthesized_headline,
        synthesized_summary,
        ai_assessment_reason, // New property
        source_articles,
        highest_relevance_score,
        key_individuals
    } = event;

    const scoreColor = highest_relevance_score >= 80 ? '#27ae60' : highest_relevance_score >= 50 ? '#f39c12' : '#c0392b';

    const contactsHtml = (key_individuals && key_individuals.length > 0)
        ? `<div style="padding:10px; background-color: #f8f9fa; border-radius: 4px; margin-bottom: 15px; font-size: 14px; color: #333;">
             <strong>Key Individuals:</strong> ${key_individuals.map(p => {
                const emailPart = p.email_suggestion ? ` (<a href="mailto:${p.email_suggestion}" style="color: #007bff; text-decoration:none;">${p.email_suggestion}</a>)` : '';
                return `${p.name} - <i>${p.role_in_event}</i>${emailPart}`;
             }).join('; ')}
           </div>`
        : '';
    
    // NEW: HTML block for the AI's reasoning
    const reasoningHtml = ai_assessment_reason 
        ? `<div style="margin-top: 15px; padding-left: 10px; border-left: 2px solid #eeeeee; font-size: 12px; color: #666666; font-style: italic;">
             <strong>AI Reasoning:</strong> ${ai_assessment_reason}
           </div>`
        : '';

    const sourcesHtml = source_articles.map(article => `
        <tr style="vertical-align: top;">
            <td style="padding: 4px 8px 4px 0; color: #555; font-weight: bold; white-space: nowrap;">${article.newspaper}:</td>
            <td style="padding: 4px 0;">
                <a href="${article.link}" style="color: #007bff; text-decoration: none; font-size: 14px;">${article.headline}</a>
            </td>
        </tr>
    `).join('');

    return `
    <div style="border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 25px; padding: 20px; background-color: #ffffff; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
        <h2 style="margin-top: 0; margin-bottom: 15px; font-size: 20px; color: #1a1a1a;">
           <span style="font-weight: bold; color: ${scoreColor};">[${highest_relevance_score}]</span> ${synthesized_headline}
        </h2>
        
        <p style="margin: 0 0 15px; font-size: 15px; color: #555; line-height: 1.6;">${synthesized_summary}</p>
        
        ${contactsHtml}

        ${reasoningHtml}

        <h4 style="margin-top: 20px; margin-bottom: 10px; font-size: 14px; color: #333; border-bottom: 1px solid #eee; padding-bottom: 5px;">Source Articles</h4>
        <table border="0" cellpadding="0" cellspacing="0" width="100%">${sourcesHtml}</table>
    </div>
    `;
}

export function formatEventForEmail(event) {
    if (!event || typeof event !== 'object' || !event.synthesized_headline) {
        logger.warn(`formatEventForEmail: Invalid event object provided.`, { eventPreview: event });
        return `<p style="color:red;">Error: Event data was invalid.</p>`;
    }

    try {
        return createEventBriefCard(event);
    } catch (error) {
        logger.error(`Error creating event card for email: "${event.synthesized_headline}"`, { errorMessage: error.message });
        return `<p style="color:red;">Error formatting event: ${event.synthesized_headline}</p>`;
    }
}

# File: src/modules/email/components/supervisorEmailBodyBuilder.js
// src/modules/email/components/supervisorEmailBodyBuilder.js
import { SUPERVISOR_EMAIL_CONFIG, HEADLINES_RELEVANCE_THRESHOLD } from '../../../config/index.js';
import { LOGO_URL } from '../constants.js';
import { truncateString } from '../../../utils/helpers.js';
import Article from '../../../../models/Article.js';
import SynthesizedEvent from '../../../../models/SynthesizedEvent.js';

function escapeHtml(unsafe) {
    if (unsafe === null || unsafe === undefined) return '';
    return String(unsafe)
         .replace(/&/g, "&")
         .replace(/</g, "<")
         .replace(/>/g, ">")
         .replace(/"/g, "'")
         .replace(/'/g, "'");
}

function createSupervisorEmailWrapper(bodyContent) {
    return `
    <!DOCTYPE html>
    <html>
    <head><title>${SUPERVISOR_EMAIL_CONFIG.subject}</title></head>
    <body style="font-family: sans-serif; background-color: #f0f0f0; padding: 20px;">
        <table width="95%" border="0" cellspacing="0" cellpadding="20" style="max-width: 1200px; margin: auto; background-color: #ffffff;">
            <tr><td>${bodyContent}</td></tr>
        </table>
    </body>
    </html>`;
}

function createScraperFailureAlertHtml(enrichmentOutcomes) {
    if (!enrichmentOutcomes || enrichmentOutcomes.length === 0) return '';
    
    const scraperFailures = enrichmentOutcomes.filter(item => 
        item.outcome === 'Dropped' && item.assessment_article.includes('Enrichment Failed')
    );

    if (scraperFailures.length === 0) return '';

    let listItems = scraperFailures.map(item => `
        <li style="margin-bottom: 10px;">
            <strong>${escapeHtml(item.newspaper)}:</strong> 
            <a href="${item.link}">${escapeHtml(item.headline)}</a><br/>
            <em style="font-size:12px; color: #555;">${escapeHtml(item.assessment_article)}</em>
        </li>
    `).join('');

    return `
    <div style="border: 2px solid #c0392b; background-color: #fbeae5; padding: 15px; margin: 20px 0; border-radius: 8px;">
        <h2 style="color: #c0392b; margin-top: 0;">âš ï¸ Scraper Action Required</h2>
        <p>The following relevant headlines failed the enrichment stage, likely due to an outdated or incorrect article text selector. Please review the selectors for these sources in <strong>src/config/sources.js</strong>.</p>
        <ul style="padding-left: 20px; margin-top: 15px;">
            ${listItems}
        </ul>
    </div>
    `;
}

function createScraperHealthTable(healthStats) {
    if (!healthStats || healthStats.length === 0) return '';

    let table = `<h2>Scraper Health Check</h2>
    <table border="1" cellpadding="5" cellspacing="0" style="width: 100%; border-collapse: collapse; font-size: 12px;">
        <thead style="background-color: #f8f8f8;"><tr><th>Source</th><th>Status</th><th>Articles Found</th></tr></thead><tbody>`;
    
    healthStats.sort((a, b) => a.source.localeCompare(b.source));

    for (const stat of healthStats) {
        const status = stat.success ? 'âœ… OK' : 'âŒ FAILED';
        const statusColor = stat.success ? 'green' : 'red';
        table += `<tr>
                <td>${escapeHtml(stat.source)}</td>
                <td style="color: ${statusColor};">${status}</td>
                <td>${stat.count}</td>
            </tr>`;
    }
    table += `</tbody></table>`;
    return table;
}


// --- MODIFIED: This function now creates detailed cards instead of a simple table ---
function createEnrichmentFunnelHtml(enrichmentOutcomes) {
    if (!enrichmentOutcomes || enrichmentOutcomes.length === 0) {
        return '<h2>Enrichment Funnel</h2><p>No headlines were relevant enough for enrichment.</p>';
    }

    let cardsHtml = `<h2>Enrichment Funnel Audit Trail</h2>
    <p>Complete lifecycle of every headline that scored â‰¥ ${HEADLINES_RELEVANCE_THRESHOLD}.</p>`;

    // Sort to show successful items first, then by score
    enrichmentOutcomes.sort((a, b) => {
        if (a.outcome === 'Success' && b.outcome !== 'Success') return -1;
        if (a.outcome !== 'Success' && b.outcome === 'Success') return 1;
        return (b.headlineScore || 0) - (a.headlineScore || 0);
    });

    for (const item of enrichmentOutcomes) {
        const isSuccess = item.outcome === 'Success';
        const statusColor = isSuccess ? '#27ae60' : '#c0392b'; // green or red
        const statusIcon = isSuccess ? 'âœ…' : 'âŒ';

        cardsHtml += `
        <div style="border: 1px solid #ccc; border-left: 5px solid ${statusColor}; margin-bottom: 20px; padding: 15px; background-color: #f9f9f9;">
            <h4 style="margin-top: 0; margin-bottom: 10px; font-size: 16px;">
                <a href="${item.link}" style="color: #007bff; text-decoration:none;">${escapeHtml(item.headline)}</a>
            </h4>
            <p style="margin: 0 0 10px;">
                <strong>${statusIcon} Status:</strong> <span style="font-weight: bold; color: ${statusColor};">${item.outcome}</span>
            </p>
            <div style="font-size: 13px; line-height: 1.5;">
                <p style="margin: 0 0 5px;">
                    <strong>âž¡ï¸ Stage 1 (Headline):</strong> Score [${item.headlineScore}] - <i>${escapeHtml(item.assessment_headline)}</i>
                </p>
                <p style="margin: 0 0 10px;">
                    <strong>âž¡ï¸ Stage 2 (Content):</strong> Final Score [${item.finalScore ?? 'N/A'}] - <span style="font-style: italic;">${escapeHtml(item.assessment_article)}</span>
                </p>
                <div style="padding: 10px; background-color: #fff; border: 1px solid #eee; font-size: 11px; color: #555; max-height: 100px; overflow-y: auto;">
                    <strong>Article Snippet:</strong>
                    <p style="margin-top: 5px; margin-bottom: 0; white-space: pre-wrap; font-family: monospace;">${escapeHtml(item.content_snippet)}...</p>
                </div>
            </div>
        </div>
        `;
    }
    return cardsHtml;
}
// --- END MODIFICATION ---


async function createEventsTableHtml(runStartDate) {
    const recentEvents = await SynthesizedEvent.find({ createdAt: { $gte: runStartDate }})
                                                 .sort({ createdAt: -1 })
                                                 .limit(50)
                                                 .lean();
    if (recentEvents.length === 0) return `<h2>Synthesized Events from this Run</h2><p>No events were synthesized in this run.</p>`;

    let table = `<h2>Synthesized Events from this Run</h2>
    <table border="1" cellpadding="5" cellspacing="0" style="width: 100%; border-collapse: collapse; font-size: 12px;">
        <thead style="background-color: #f8f8f8;"><tr><th>Synthesized Headline</th><th>Score</th><th>Sources</th><th>Key Individuals</th><th>Emailed?</th></tr></thead><tbody>`;
    for (const event of recentEvents) {
        const sources = event.source_articles.map(a => a.newspaper).join(', ');
        const individuals = event.key_individuals.map(p => p.name).join(', ') || 'N/A';
        table += `<tr>
                <td>${truncateString(escapeHtml(event.synthesized_headline), 80)}</td>
                <td>${event.highest_relevance_score}</td>
                <td>${escapeHtml(sources)}</td>
                <td>${escapeHtml(individuals)}</td>
                <td>${event.emailed ? 'Yes' : 'No'}</td>
            </tr>`;
    }
    table += `</tbody></table>`;
    return table;
}

async function createArticlesTableHtml(runStartDate) {
    const freshArticles = await Article.find({ createdAt: { $gte: runStartDate }})
                                         .sort({ relevance_headline: -1 })
                                         .limit(100)
                                         .lean();
    if (freshArticles.length === 0) return `<h2>All Fresh Articles Processed</h2><p>No new raw articles were processed.</p>`;

    let table = `<h2>All Fresh Articles Processed in this Run</h2>
    <table border="1" cellpadding="5" cellspacing="0" style="width: 100%; border-collapse: collapse; font-size: 12px;">
        <thead style="background-color: #f8f8f8;"><tr><th>Headline</th><th>Source</th><th>HL Score</th><th>Status</th></tr></thead><tbody>`;
    for (const article of freshArticles) {
        const status = article.relevance_headline >= HEADLINES_RELEVANCE_THRESHOLD ? 'Relevant for Enrichment' : 'Low Relevance';
        table += `<tr>
                <td><a href="${article.link}">${truncateString(escapeHtml(article.headline), 80)}</a></td>
                <td>${escapeHtml(article.newspaper)}</td>
                <td>${article.relevance_headline}</td>
                <td>${status}</td>
            </tr>`;
    }
    table += `</tbody></table>`;
    return table;
}


export async function createSupervisorEmailBody(runStats) {
    const runTimestamp = new Date().toLocaleString('en-GB', { timeZone: 'Europe/Copenhagen' });
    const runStartDate = new Date(Date.now() - 10 * 60 * 1000); // Widen window slightly to be safe
    
    let statsHtml = `<h2>Run Statistics</h2><ul>`;
    const statOrder = ['headlinesScraped', 'freshHeadlinesFound', 'headlinesAssessed', 'relevantHeadlines', 'articlesEnriched', 'relevantArticles', 'eventsClustered', 'eventsSynthesized', 'eventsEmailed', 'errors'];
    for (const key of statOrder) {
        if (runStats.hasOwnProperty(key)) {
            const value = runStats[key];
            const formattedKey = key.replace(/([A-Z])/g, ' $1').replace(/^./, str => str.toUpperCase());
            statsHtml += `<li><strong>${formattedKey}:</strong> ${Array.isArray(value) && value.length === 0 ? '0' : (Array.isArray(value) ? value.join(', ') : value)}</li>`;
        }
    }
    statsHtml += `</ul>`;

    const scraperFailureAlertHtml = createScraperFailureAlertHtml(runStats.enrichmentOutcomes); // NEW
    const scraperHealthHtml = createScraperHealthTable(runStats.scraperHealth);
    const enrichmentFunnelHtml = createEnrichmentFunnelHtml(runStats.enrichmentOutcomes);

    const [eventsTableHtml, articlesTableHtml] = await Promise.all([
        createEventsTableHtml(runStartDate),
        createArticlesTableHtml(runStartDate)
    ]);
    
    const bodyContent = `
        <div style="text-align:center;"><img src="${LOGO_URL}" alt="Logo" style="max-width:150px;"></div>
        <h1 style="text-align:center;">${SUPERVISOR_EMAIL_CONFIG.subject}</h1>
        <p style="text-align:center;">Run completed: ${runTimestamp}</p>
        
        ${scraperFailureAlertHtml} <!-- The new, prominent alert -->
        
        ${statsHtml}
        
        ${enrichmentFunnelHtml} <!-- The new, detailed audit trail -->
        
        ${eventsTableHtml}
        
        ${articlesTableHtml}
        
        ${scraperHealthHtml}

        <div style="text-align: center; margin-top: 30px; font-size: 12px; color: #888888;">
            <p>This is an automated report from the ${SUPERVISOR_EMAIL_CONFIG.brandName}.</p>
        </div>
    `;

    return createSupervisorEmailWrapper(bodyContent);
}

# File: src/modules/email/constants.js
// src/modules/email/constants.js

// Placeholder for your logo URL (replace with actual URL to a PNG/JPG)
export const LOGO_URL =
  'https://static.seekingalpha.com/cdn/s3/uploads/getty_images/1493722121/image_1493722121.jpg'; // <-- REPLACE THIS


# File: src/modules/email/index.js
// src/modules/email/index.js
import { logger } from '../../utils/logger.js';
import { sendPersonalizedEmail, performActualSupervisorEmailSend } from './mailer.js';
import SynthesizedEvent from '../../../models/SynthesizedEvent.js';
import { USERS } from '../../config/users.js';
import { newspaperToCountryMap, countryNameToFlagMap } from '../../config/sources.js';
import { createPersonalizedEmailBody } from './components/emailBodyBuilder.js';

/**
 * Groups a list of events by their country of origin.
 * @param {Array<Object>} events - A list of synthesized events.
 * @returns {Object} An object where keys are country names and values are arrays of events.
 */
function groupEventsByCountry(events) {
    const eventsByCountry = {};
    for (const event of events) {
        const primaryNewspaper = event.source_articles[0]?.newspaper;
        if (primaryNewspaper) {
            const country = newspaperToCountryMap.get(primaryNewspaper) || 'Other';
            if (!eventsByCountry[country]) {
                eventsByCountry[country] = [];
            }
            eventsByCountry[country].push(event);
        }
    }
    return eventsByCountry;
}

/**
 * Main function to send personalized wealth event emails to all configured users.
 * @returns {Promise<Object>} An object containing the total count of events processed.
 */
export async function sendWealthEventsEmail() {
    logger.info(`ðŸ“§ Checking for new synthesized events to email...`);
    
    const eventsToSend = await SynthesizedEvent.find({ emailed: false }).sort({ createdAt: -1 }).lean();
    
    if (eventsToSend.length === 0) {
        logger.info('No new synthesized events to email.');
        return { eventsSentCount: 0 };
    }

    logger.info(`Found ${eventsToSend.length} new events to process for ${USERS.length} users.`);
    
    const allEventsByCountry = groupEventsByCountry(eventsToSend);
    let anyEmailSent = false;

    for (const user of USERS) {
        const userSpecificEventsByCountry = {};
        let eventCountForUser = 0;

        for (const country of user.countries) {
            if (allEventsByCountry[country]) {
                userSpecificEventsByCountry[country] = allEventsByCountry[country];
                eventCountForUser += allEventsByCountry[country].length;
            }
        }

        if (eventCountForUser === 0) {
            logger.info(`No new events for ${user.firstName}'s subscribed countries. Skipping email.`);
            continue;
        }

        const includedFlags = Object.keys(userSpecificEventsByCountry)
            .map(country => countryNameToFlagMap.get(country) || '')
            .join(' ');
        
        const subject = `${includedFlags} New Wealth Opportunities`.trim();
        const body = createPersonalizedEmailBody(user, userSpecificEventsByCountry, subject);

        if (body) {
            const emailSentSuccessfully = await sendPersonalizedEmail({ user, subject, body });
            if (emailSentSuccessfully) {
                anyEmailSent = true;
            }
        }
    }

    // After processing all users, mark the events as emailed so they aren't sent again.
    if (anyEmailSent) {
        const eventIds = eventsToSend.map(e => e._id);
        await SynthesizedEvent.updateMany(
            { _id: { $in: eventIds } },
            { $set: { emailed: true, email_sent_at: new Date() } }
        );
        logger.info(`Successfully processed and marked ${eventsToSend.length} events as emailed.`);
    }

    return { eventsSentCount: eventsToSend.length };
}

/**
 * Coordinates sending the supervisor report email to all designated superusers.
 * @param {Object} runStats - Statistics about the current pipeline run.
 */
export async function sendSupervisorReportEmail(runStats) {
    if (!runStats) {
        logger.error('No runStats provided for supervisor report. Skipping email.');
        return;
    }
    
    logger.info('Preparing supervisor report email...');
    
    // Find all users with the superUser flag set to true.
    const superUserEmails = USERS.filter(user => user.superUser === true).map(user => user.email);

    if (superUserEmails.length === 0) {
        logger.warn('No superusers found in src/config/users.js. Skipping supervisor report.');
        return;
    }
    
    try {
        await performActualSupervisorEmailSend(runStats, superUserEmails);
        logger.info('âœ… Supervisor report email successfully sent/queued to all superusers.');
    } catch (error) {
        logger.error({ err: error }, 'ðŸ’¥ CRITICAL: Failed to send supervisor report email.');
    }
}

# File: src/modules/email/mailer.js
// src/modules/email/mailer.js
import nodemailer from 'nodemailer';
import { logger } from '../../utils/logger.js';
import { safeExecute } from '../../utils/helpers.js';
import {
  SUPERVISOR_EMAIL_CONFIG,
  SMTP_CONFIG,
  IS_PRODUCTION,
  FORCE_EMAIL_SEND_DEV
} from '../../config/index.js';
import { createSupervisorEmailBody } from './components/supervisorEmailBodyBuilder.js';

const SMTP_UNCONFIGURED_MSG = 'SMTP authentication not fully configured.';

async function sendEmail(mailOptions, emailType) {
    if (!IS_PRODUCTION && !FORCE_EMAIL_SEND_DEV) {
        logger.warn(`[${emailType} Mailer] DEV MODE: Skipping actual email send to: ${mailOptions.to}`);
        return { skipped: true, reason: 'DEV mode' };
    }

    if (!SMTP_CONFIG?.auth?.user || !SMTP_CONFIG?.auth?.pass) {
        logger.error(`âŒ [${emailType} Mailer] ${SMTP_UNCONFIGURED_MSG}`);
        return { error: SMTP_UNCONFIGURED_MSG };
    }

    logger.info(`ðŸ“¤ [${emailType} Mailer] Sending email via Nodemailer to: ${mailOptions.to}.`);

    const transporter = nodemailer.createTransport(SMTP_CONFIG);

    const sendResult = await safeExecute(() => transporter.sendMail(mailOptions), {
        errorHandler: (error) => {
            logger.error(`âŒ [${emailType} Mailer] Nodemailer SMTP error:`, { message: error.message, code: error.code });
            return { errorOccurred: true, details: error.message };
        },
    });

    if (sendResult && sendResult.errorOccurred) {
        return { error: `SMTP Error: ${sendResult.details}` };
    }

    logger.info(`âœ… [${emailType} Mailer] Email sent successfully to ${mailOptions.to}.`);
    return { success: true };
}

export async function sendPersonalizedEmail({ user, subject, body }) {
    if (!user || !user.email) {
        logger.error(`âŒ [Wealth Events Mailer] Invalid user object provided.`);
        return false;
    }

    const mailOptions = {
        from: `"${SMTP_CONFIG.fromName}" <${SMTP_CONFIG.fromAddress}>`,
        to: user.email,
        subject: subject,
        html: body,
    };

    const result = await sendEmail(mailOptions, 'Wealth Events');
    return result.success || false;
}

export async function performActualSupervisorEmailSend(runStats, recipients) {
    if (!recipients || recipients.length === 0) {
        logger.warn('[Supervisor Mailer] Skipping: No superusers configured to receive this report.');
        return;
    }

    const emailBodyHtml = await createSupervisorEmailBody(runStats);
    if (!emailBodyHtml) {
        logger.error('âŒ [Supervisor Mailer] HTML email body generation failed.');
        throw new Error('Failed to generate supervisor email body');
    }

    const mailOptions = {
        from: `"${SMTP_CONFIG.fromName}" <${SMTP_CONFIG.fromAddress}>`,
        to: recipients.join(', '),
        subject: SUPERVISOR_EMAIL_CONFIG.subject,
        html: emailBodyHtml,
    };

    const result = await sendEmail(mailOptions, 'Supervisor Report');

    if (result.error) {
        throw new Error(`Failed to send supervisor email: ${result.error}`);
    }
}

# File: src/modules/mongoStore/index.js
// src/modules/mongoStore/index.js
import Article from '../../../models/Article.js';
import SynthesizedEvent from '../../../models/SynthesizedEvent.js';
import { logger } from '../../utils/logger.js';
import { generateEmbedding } from '../../utils/vectorUtils.js';

/**
 * Filters a list of scraped articles against the database to find which ones are new.
 * This is the only database read operation at the start of the pipeline.
 * In refresh mode, it pulls existing articles from the DB to be re-processed.
 * @param {Array} articles - The array of freshly scraped articles.
 * @param {boolean} isRefreshMode - Flag for re-processing.
 * @returns {Promise<Array>} An array of articles to be processed in the pipeline.
 */
export async function filterFreshArticles(articles, isRefreshMode = false) {
    if (!articles || articles.length === 0) return [];

    const scrapedLinks = articles.map(a => a.link);

    if (isRefreshMode) {
        logger.warn('REFRESH MODE: All scraped articles will be processed, pulling existing data from DB where available.');
        const existingDbArticles = await Article.find({ link: { $in: scrapedLinks } }).lean();
        const existingArticlesMap = new Map(existingDbArticles.map(a => [a.link, a]));
        
        const articlesForReprocessing = articles.map(scrapedArticle => {
            return existingArticlesMap.get(scrapedArticle.link) || scrapedArticle;
        });

        logger.info(`REFRESH MODE: Prepared ${articlesForReprocessing.length} articles for full re-processing.`);
        return articlesForReprocessing;
    }
    
    // Standard mode: find articles that are not yet in the database.
    const existingArticles = await Article.find({ link: { $in: scrapedLinks } }).select('link').lean();
    const existingLinks = new Set(existingArticles.map(a => a.link));
    
    const freshArticles = articles.filter(a => !existingLinks.has(a.link));
    logger.info(`Filtering complete. Found ${existingLinks.size} existing articles from previous runs, ${freshArticles.length} are fresh.`);
    return freshArticles;
}


/**
 * Saves all processed articles and synthesized events to the database in a single transactional operation.
 * @param {Array} articlesToSave - The array of all articles processed in the run.
 * @param {Array} eventsToSave - The array of synthesized events.
 * @returns {Promise<boolean>} A promise that resolves to true if successful.
 */
export async function savePipelineResults(articlesToSave, eventsToSave) {
    logger.info(`Committing pipeline results to database...`);
    
    const articleOps = [];
    if (articlesToSave && articlesToSave.length > 0) {
        for (const article of articlesToSave) {
            // If the article was fully enriched and assessed, generate a new, more accurate embedding.
            // Otherwise, its initial headline-based embedding is sufficient.
            if (article.relevance_article && article.articleContent) {
                const textToEmbed = `${article.headline}\n${article.assessment_article || ''}\n${(article.articleContent.contents || []).join(' ').substring(0, 500)}`;
                article.embedding = await generateEmbedding(textToEmbed);
            }

            const { _id, ...dataToSet } = article;
            Object.keys(dataToSet).forEach(key => dataToSet[key] === undefined && delete dataToSet[key]);

            articleOps.push({
                updateOne: {
                    filter: { link: article.link },
                    update: { $set: dataToSet },
                    upsert: true,
                },
            });
        }
    }

    // This block only runs if articles were successfully committed first.
    const eventOps = [];
    if (eventsToSave && eventsToSave.length > 0 && articleOps.length > 0) {
         // First, commit articles to ensure they have permanent _id fields.
        await Article.bulkWrite(articleOps, { ordered: false });
        logger.info(`Article commit complete. Upserted: ${articleOps.filter(op => op.updateOne.upsert).length}, Modified: ${articleOps.filter(op => !op.updateOne.upsert).length}.`);
        
        for (const event of eventsToSave) {
            const sourceLinks = event.source_articles.map(sa => sa.link);
            const savedArticles = await Article.find({ link: { $in: sourceLinks } }).select('_id link').lean();
            const linkToIdMap = new Map(savedArticles.map(a => [a.link, a._id]));

            event.source_articles.forEach(sa => {
                sa.article_id = linkToIdMap.get(sa.link);
            });
            // Remove articles that couldn't be mapped (should not happen in this logic)
            event.source_articles = event.source_articles.filter(sa => sa.article_id);

            // Use .toObject() if it's a Mongoose model instance, otherwise just use the object
            const eventPayload = event.toObject ? event.toObject() : event;

            eventOps.push({
                updateOne: {
                    filter: { event_key: event.event_key },
                    update: { $set: eventPayload },
                    upsert: true,
                }
            });
        }
    } else if (articleOps.length > 0) {
        // If there are only articles to save, commit them.
        await Article.bulkWrite(articleOps, { ordered: false });
        logger.info(`Article commit complete. Upserted: ${articleOps.filter(op => op.updateOne.upsert).length}.`);
    }

    try {
        if (eventOps.length > 0) {
            const eventResult = await SynthesizedEvent.bulkWrite(eventOps, { ordered: false });
            logger.info(`Event commit complete. Upserted: ${eventResult.upsertedCount}, Modified: ${eventResult.modifiedCount}.`);
        } else if (articlesToSave.length > 0) {
             logger.info('No new events to commit.');
        } else {
             logger.info('No new articles or events to commit.');
        }
        
        return true;

    } catch (error) {
        logger.fatal({ err: error }, 'CRITICAL: Failed to commit pipeline results to the database.');
        return false;
    }
}

# File: src/modules/scraper/index.js
// src/modules/scraper/index.js
import axios from 'axios';
import * as cheerio from 'cheerio';
import pLimit from 'p-limit';
import { HttpsProxyAgent } from 'https-proxy-agent';
import { logger } from '../../utils/logger.js';
import { safeExecute, truncateString } from '../../utils/helpers.js';
import { CONCURRENCY_LIMIT, SCRAPER_PROXY_URL, MIN_ARTICLE_CHARS } from '../../config/index.js';
// MODIFIED: Import the new country-based config
import { COUNTRIES_CONFIG, TEXT_SELECTORS } from '../../config/sources.js';

const limit = pLimit(CONCURRENCY_LIMIT);

const axiosInstance = axios.create();
if (SCRAPER_PROXY_URL) {
    logger.info(`Using scraper proxy: ${new URL(SCRAPER_PROXY_URL).hostname}`);
    const httpsAgent = new HttpsProxyAgent(SCRAPER_PROXY_URL);
    axiosInstance.defaults.httpsAgent = httpsAgent;
    axiosInstance.defaults.httpAgent = httpsAgent;
}

const BROWSER_HEADERS = {
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
    'Accept-Encoding': 'gzip, deflate, br',
    'Accept-Language': 'en-US,en;q=0.9',
    'Sec-Ch-Ua': '"Not/A)Brand";v="99", "Google Chrome";v="115", "Chromium";v="115"',
    'Sec-Ch-Ua-Mobile': '?0',
    'Sec-Ch-Ua-Platform': '"Windows"',
    'Sec-Fetch-Dest': 'document',
    'Sec-Fetch-Mode': 'navigate',
    'Sec-Fetch-Site': 'none',
    'Sec-Fetch-User': '?1',
    'Upgrade-Insecure-Requests': '1',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36',
};

async function fetchPage(url) {
    const axiosConfig = { headers: BROWSER_HEADERS, timeout: 30000 };
    const result = await safeExecute(() => axiosInstance.get(url, axiosConfig), {
        errorHandler: (err) => {
            const status = err.response ? err.response.status : 'N/A';
            if (err.code === 'ECONNABORTED' || err.message.includes('timeout')) {
                logger.error(`Request to ${url} timed out after 30 seconds.`);
            } else {
                logger.error(`Failed to fetch page ${url} [Status: ${status}].`);
            }
            return null;
        }
    });
    return result;
}

export async function scrapeSite(site) {
    if (site.name === 'EQT') {
        const pageResponse = await fetchPage(site.url);
        if (!pageResponse) return { source: site.name, articles: [], success: false };

        const buildIdMatch = pageResponse.data.match(/"buildId":"([a-zA-Z0-9_-]+)"/);
        if (!buildIdMatch || !buildIdMatch[1]) {
            logger.warn(`Could not find Build ID for EQT. Site structure may have changed.`);
            return { source: site.name, articles: [], success: false };
        }
        const buildId = buildIdMatch[1];
        const apiUrl = `${site.url.replace('/news', '')}/_next/data/${buildId}/en/news.json`;

        const apiResponse = await fetchPage(apiUrl);
        if (!apiResponse) return { source: site.name, articles: [], success: false };
        
        try {
            const hits = apiResponse.data?.pageProps?.page?.pageContent?.find(c => c._type === 'listing')?.initialResults?.main?.hits || [];
            const articles = hits.map(hit => ({
                headline: hit.thumbnail.title,
                link: new URL(hit.thumbnail.path, site.url).href,
                source: site.name,
                newspaper: site.newspaper,
            }));
            return { source: site.name, articles, success: true };
        } catch (e) {
            logger.error({ err: e }, `Failed to parse API response from EQT.`);
            return { source: site.name, articles: [], success: false };
        }
    }

    const response = await fetchPage(site.url);
    if (!response) {
        return { source: site.name, articles: [], success: false };
    }
    
    const $ = cheerio.load(response.data);
    let articles = [];

    if (site.useJsonLd) {
        $('script[type="application/ld+json"]').each((_, el) => {
            try {
                const jsonData = JSON.parse($(el).html());
                if (jsonData['@type'] === 'ItemList' && jsonData.itemListElement) {
                    jsonData.itemListElement.forEach(item => {
                        if (item.name && item.url) {
                           const absoluteUrl = new URL(item.url, site.url).href;
                           articles.push({ headline: item.name, link: absoluteUrl, source: site.name, newspaper: site.newspaper || site.name });
                        }
                    });
                }
            } catch (e) { 
                logger.warn({ err: e, site: site.name }, `Failed to parse JSON-LD from ${site.name}`);
            }
        });
    } else {
        $(site.selector).each((_, el) => {
            const articleData = site.extract($(el), site);
            if (articleData && articleData.headline && articleData.link) {
                articleData.link = new URL(articleData.link, site.url).href;
                articleData.newspaper = site.newspaper || site.name;
                articles.push(articleData);
            }
        });
    }
    
    const uniqueArticles = Array.from(new Map(articles.map(a => [a.link, a])).values());
    return { source: site.name, articles: uniqueArticles, success: true };
}

export async function scrapeAllHeadlines() {
    logger.info('ðŸ“° Starting headline scraping from all sources...');
    
    // MODIFIED: Flatten the new country-based structure into a single list of sites to scrape.
    const allSites = COUNTRIES_CONFIG.flatMap(country => country.sites);
    
    const promises = allSites.map(site => limit(() => scrapeSite(site)));
    const results = await Promise.all(promises);
    
    results.forEach(r => {
        logger.info(`Scraped ${r.articles.length} unique headlines from ${r.source}.`);
    });

    const allArticles = results.flatMap(r => r.articles);
    const scraperHealth = results.map(r => ({ source: r.source, success: r.success, count: r.articles.length }));

    logger.info(`Scraping complete. Found a total of ${allArticles.length} headlines.`);
    return { allArticles, scraperHealth };
}

export async function scrapeArticleContent(article) {
    logger.debug(`Enriching article: ${article.link}`);
    
    const pageResponse = await fetchPage(article.link);
    if (!pageResponse) {
        return { ...article, enrichment_error: 'Failed to fetch page' };
    }
    
    if (article.newspaper === 'EQT') {
        const $page = cheerio.load(pageResponse.data);
        const scriptData = $page('script#__NEXT_DATA__').html();
        if (scriptData) {
            try {
                const jsonData = JSON.parse(scriptData);
                const pageContent = jsonData?.props?.pageProps?.page?.pageContent;
                if (pageContent) {
                    const richTextBlock = pageContent.find(block => block._type === 'richTextBlock');
                    if (richTextBlock && richTextBlock.body) {
                        const bodyHtml = richTextBlock.body;
                        const $body = cheerio.load(bodyHtml);
                        const fullText = $body.text().replace(/\s\s+/g, ' ').trim();
                        article.articleContent = { contents: [fullText] };
                        return article;
                    }
                }
            } catch (e) {
                logger.warn({ err: e }, `Failed to parse JSON data for EQT article: ${article.link}. Falling back to standard method.`);
            }
        }
    }

    const newspaperName = article.newspaper || article.source;
    let selectors = TEXT_SELECTORS[newspaperName];
    if (!selectors) {
        logger.warn(`No text selector for newspaper "${newspaperName}".`);
        return { ...article, enrichment_error: `No selector for "${newspaperName}"` };
    }
    if (!Array.isArray(selectors)) {
        selectors = [selectors];
    }

    const $ = cheerio.load(pageResponse.data);
    let fullText = '';

    for (const selector of selectors) {
        let extractedText = '';
        if (selector.startsWith('meta[')) {
            extractedText = $(selector).attr('content') || '';
        } else {
            extractedText = $(selector).map((_, el) => $(el).text()).get().join(' ');
        }
        
        fullText = extractedText.replace(/\s\s+/g, ' ').trim();

        if (fullText.length >= MIN_ARTICLE_CHARS) {
            logger.debug(`Successfully extracted content for "${truncateString(article.headline, 50)}" using selector: "${selector}"`);
            break; 
        }
    }
    
    if (fullText.length >= MIN_ARTICLE_CHARS) {
        article.articleContent = { contents: [fullText] };
    } else {
        logger.warn(`Could not find sufficient text for "${truncateString(article.headline, 50)}" with any configured selectors.`);
        article.enrichment_error = 'Content not found or too short with all selectors';
    }
    return article;
}

# File: src/utils/helpers.js
// src/utils/helpers.js (version 1.0)
import { logger } from './logger.js';

/**
 * Truncates a string to a specified length, adding an ellipsis if truncated.
 * @param {string} str The string to truncate.
 * @param {number} maxLength The maximum length of the string.
 * @returns {string} The truncated string.
 */
export function truncateString(str, maxLength = 100) {
    if (typeof str !== 'string' || str.length <= maxLength) {
        return str;
    }
    return str.substring(0, maxLength) + '...';
}

/**
 * Executes an async function and handles errors gracefully.
 * @param {() => Promise<any>} asyncFn The async function to execute.
 * @param {{errorHandler: (error: Error) => any}} options Error handling options.
 * @returns {Promise<any>} The result of the function or the error handler.
 */
export async function safeExecute(asyncFn, { errorHandler } = {}) {
    try {
        return await asyncFn();
    } catch (error) {
        if (errorHandler) {
            return errorHandler(error);
        }
        logger.error({ err: error }, 'An unexpected error occurred in a safeExecute block.');
        return null; // Default fallback
    }
}

# File: src/utils/logger.js
// src/utils/logger.js
import pino from 'pino';
import { LOG_LEVEL, IS_PRODUCTION } from '../config/index.js';

const pinoConfig = {
    level: LOG_LEVEL || 'info',
    // More concise logging by default, removing pid and hostname
    base: undefined, 
};

if (!IS_PRODUCTION) {
    pinoConfig.transport = {
        target: 'pino-pretty',
        options: {
            colorize: true,
            translateTime: 'HH:MM:ss',
            ignore: 'pid,hostname,runStats', // MODIFIED: Ignore the verbose runStats object in console output
        },
    };
}

export const logger = pino(pinoConfig);

# File: src/utils/pipelineLogger.js
// src/utils/pipelineLogger.js
import { logger } from './logger.js';
import Article from '../../models/Article.js';
import SynthesizedEvent from '../../models/SynthesizedEvent.js';
import { truncateString } from './helpers.js';
import { disconnectDatabase } from '../database.js';

// --- Console Colors for Readability ---
const colors = {
    reset: "\x1b[0m",
    red: "\x1b[31m",
    green: "\x1b[32m",
    yellow: "\x1b[33m",
    cyan: "\x1b[36m",
    magenta: "\x1b[35m",
    grey: "\x1b[90m",
};

/**
 * Fetches and calculates comprehensive statistics from the database.
 * @returns {Promise<Object>} An object containing various database stats.
 */
async function getDatabaseStats() {
    try {
        const [totalArticles, totalEvents, relevanceAggregation, sourceAggregation] = await Promise.all([
            Article.countDocuments(),
            SynthesizedEvent.countDocuments(),
            Article.aggregate([
                {
                    $bucket: {
                        groupBy: "$relevance_article",
                        boundaries: [0, 30, 50, 80, 101],
                        default: "Other",
                        output: { count: { $sum: 1 } }
                    }
                }
            ]),
            Article.aggregate([
                { $group: { _id: '$newspaper', count: { $sum: 1 } } },
                { $sort: { count: -1 } },
                { $limit: 10 }
            ])
        ]);

        return {
            totalArticles,
            totalEvents,
            relevanceBuckets: relevanceAggregation,
            topSources: sourceAggregation
        };
    } catch (error) {
        logger.error({ err: error }, "Failed to fetch database statistics.");
        return null;
    }
}

/**
 * The main function to log the final, comprehensive report for a pipeline run.
 * @param {Object} runStats - The statistics collected during the pipeline run.
 * @param {number} duration - The duration of the pipeline run in seconds.
 */
export async function logFinalReport(runStats, duration) {
    const dbStats = await getDatabaseStats();

    let report = `\n\n${colors.cyan}=============================================================${colors.reset}\n`;
    report += `${colors.cyan} ðŸš€ PIPELINE RUN SUMMARY${colors.reset}\n`;
    report += `${colors.cyan}=============================================================${colors.reset}\n\n`;
    report += `  ${colors.magenta}Duration:${colors.reset} ${duration} seconds\n\n`;

    // --- Current Run Funnel ---
    report += `  ${colors.yellow}--- Funnel (This Run) ---${colors.reset}\n`;
    report += `  ${'Headlines Scraped:'.padEnd(25)} ${runStats.headlinesScraped}\n`;
    report += `  ${'Fresh/Refreshed Articles:'.padEnd(25)} ${runStats.freshHeadlinesFound}\n`;
    report += `  ${'Headlines Assessed:'.padEnd(25)} ${runStats.headlinesAssessed}\n`;
    report += `  ${'  > Relevant (>=20):'.padEnd(25)} ${runStats.relevantHeadlines}\n`;
    report += `  ${'Articles Enriched:'.padEnd(25)} ${runStats.articlesEnriched}\n`;
    report += `  ${'  > Relevant (>=50):'.padEnd(25)} ${runStats.relevantArticles}\n`;
    report += `  ${'Events Clustered:'.padEnd(25)} ${runStats.eventsClustered}\n`;
    report += `  ${'Events Synthesized:'.padEnd(25)} ${runStats.eventsSynthesized}\n`;
    report += `  ${colors.green}${'Events Emailed:'.padEnd(25)} ${runStats.eventsEmailed}${colors.reset}\n`;
    if (runStats.errors && runStats.errors.length > 0) {
        report += `  ${colors.red}${'Errors Encountered:'.padEnd(25)} ${runStats.errors.length}${colors.reset}\n`;
    }
    report += '\n';

    // --- Top Synthesized Events from this Run ---
    if (runStats.synthesizedEventsForReport && runStats.synthesizedEventsForReport.length > 0) {
        report += `  ${colors.yellow}--- Top Synthesized Events (This Run) ---${colors.reset}\n`;
        runStats.synthesizedEventsForReport.slice(0, 5).forEach(event => {
            report += `  ${colors.green}[${String(event.highest_relevance_score).padStart(3)}]${colors.reset} "${truncateString(event.synthesized_headline, 70)}"\n`;
        });
        report += '\n';
    }

    // --- Database Statistics ---
    if (dbStats) {
        report += `  ${colors.yellow}--- Database Statistics (Overall) ---${colors.reset}\n`;
        report += `  ${'Total Articles:'.padEnd(25)} ${dbStats.totalArticles}\n`;
        report += `  ${'Total Synthesized Events:'.padEnd(25)} ${dbStats.totalEvents}\n\n`;
        
        report += `  ${colors.magenta}Article Relevance Breakdown:${colors.reset}\n`;
        dbStats.relevanceBuckets.forEach(bucket => {
            // FIX: Handle potential undefined boundaries
            const rangeEnd = bucket.boundaries && bucket.boundaries.length > 1 ? bucket.boundaries[1] - 1 : '...';
            const range = bucket._id === 'Other' ? 'N/A' : `${bucket._id} - ${rangeEnd}`;
            report += `  ${`  Score ${range}:`.padEnd(25)} ${bucket.count} articles\n`;
        });
        report += '\n';

        report += `  ${colors.magenta}Top 10 Article Sources:${colors.reset}\n`;
        dbStats.topSources.forEach(source => {
            report += `  ${`  ${source._id}:`.padEnd(25)} ${source.count} articles\n`;
        });
    }

    report += `\n${colors.cyan}=============================================================${colors.reset}\n`;

    // --- FIX: Only log the formatted string, not the raw objects ---
    logger.info(report);

    await disconnectDatabase();
}

# File: src/utils/vectorUtils.js
// src/utils/vectorUtils.js
import { pipeline } from '@xenova/transformers';

// Use a singleton pattern to ensure we only load the model once.
class EmbeddingPipeline {
    static task = 'feature-extraction';
    static model = 'Xenova/all-MiniLM-L6-v2';
    static instance = null;

    static async getInstance(progress_callback = null) {
        if (this.instance === null) {
            this.instance = pipeline(this.task, this.model, { progress_callback });
        }
        return this.instance;
    }
}

/**
 * Generates an embedding for a given text.
 * @param {string} text The text to embed.
 * @returns {Promise<Array<number>>} A promise that resolves to the embedding vector.
 */
export async function generateEmbedding(text) {
    const extractor = await EmbeddingPipeline.getInstance();
    const output = await extractor(text, { pooling: 'mean', normalize: true });
    return Array.from(output.data);
}

/**
 * Calculates the cosine similarity between two vectors.
 * @param {Array<number>} vecA The first vector.
 * @param {Array<number>} vecB The second vector.
 * @returns {number} The cosine similarity score (between -1 and 1).
 */
export function cosineSimilarity(vecA, vecB) {
    let dotProduct = 0.0;
    let normA = 0.0;
    let normB = 0.0;
    for (let i = 0; i < vecA.length; i++) {
        dotProduct += vecA[i] * vecB[i];
        normA += vecA[i] * vecA[i];
        normB += vecB[i] * vecB[i];
    }
    return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}
