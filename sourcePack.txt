
# File: .claude/settings.local.json
{
  "permissions": {
    "allow": [
      "Bash(rm:*)"
    ],
    "deny": []
  }
}

# File: .dockerignore
# File: .dockerignore (version 1.01)
/.git
/node_modules
.dockerignore
.env

# Explicitly include package-lock.json to ensure it's in the build context,
# overriding any other potential ignore rules.
!package-lock.json

# File: .env.template
# .env.template
# This file provides a template for the required environment variables.
# Copy this file to .env and fill in your actual values.
# DO NOT COMMIT THE .env FILE TO VERSION CONTROL.

# --- Core Application Behavior ---
NODE_ENV=development # 'development' or 'production'
LOG_LEVEL=debug      # 'debug', 'info', 'warn', 'error'
CONCURRENCY_LIMIT=3  # Number of parallel network operations (scraping, AI calls)
FORCE_EMAIL_SEND_DEV=true # Set to 'true' to force emails to be sent even if NODE_ENV is 'development'

# --- MongoDB Configuration ---
MONGO_URI="mongodb+srv://user:password@cluster.mongodb.net/database?retryWrites=true&w=majority"

# --- Kimi API Configuration ---
KIMI_API_KEY="sk-..."
LLM_MODEL_HEADLINES="moonshot-v1-8k" # Example Kimi model
LLM_MODEL_ARTICLES="moonshot-v1-32k" # Example Kimi model

# --- Email Sending Configuration (via Nodemailer) ---
SMTP_HOST=smtp.gmail.com
SMTP_PORT=465
SMTP_SECURE=true # true for 465, false for other ports
SMTP_USER="your-email@gmail.com"
SMTP_PASS="your-app-password" # Use an App Password for Gmail
SMTP_FROM_ADDRESS="your-email@gmail.com"
SMTP_FROM_NAME="Wealth Events Bot"

# --- Email Recipients ---
# Comma-separated list of emails
HEADLINE_RECIPIENTS="recipient1@example.com,recipient2@example.com"
SUPERVISOR_EMAIL="supervisor@example.com"
# Set to false to disable sending to supervisor if the email is the default placeholder
SEND_TO_DEFAULT_SUPERVISOR=true

# File: .github/workflows/fly-deploy.yml
# See https://fly.io/docs/app-guides/continuous-deployment-with-github-actions/

name: Fly Deploy
on:
  push:
    branches:
      - main
jobs:
  deploy:
    name: Deploy app
    runs-on: ubuntu-latest
    concurrency: deploy-group
    steps:
      - uses: actions/checkout@v4
      
      # Step 1: Install flyctl using the official installer.
      - name: Install flyctl
        run: |
          curl -L https://fly.io/install.sh | sh
          # Step 2: Add flyctl to the PATH for subsequent steps.
          # This is the officially recommended and robust method.
          echo "/home/runner/.fly/bin" >> $GITHUB_PATH

      - name: Deploy to Fly.io
        # Now 'flyctl' can be called directly because its location is in the PATH.
        run: flyctl deploy --remote-only
        env:
          FLY_API_TOKEN: ${{ secrets.FLY_API_TOKEN }}

# File: .github/workflows/run-pipeline.yml
name: Run Pipeline on Schedule

on:
  workflow_dispatch: # Allows you to run this workflow manually from the Actions tab
  schedule:
    # IMPORTANT: GitHub schedules run on UTC time.
    # 10:00 Copenhagen (CEST, UTC+2) is 08:00 UTC
    # 16:30 Copenhagen (CEST, UTC+2) is 14:30 UTC
    - cron: '0 6 * * *'
    - cron: '0 8 * * *'
    - cron: '30 14 * * *'
    - cron: '39 22 * * *'

jobs:
  run-on-fly:
    name: Start a Fly Machine to Run the Pipeline
    runs-on: ubuntu-latest

    steps:
      # Step 1: Check out your repository's code
      - uses: actions/checkout@v4
      
      # Step 2: Install flyctl and add it to the PATH.
      - name: Install flyctl
        run: |
          curl -L https://fly.io/install.sh | sh
          echo "/home/runner/.fly/bin" >> $GITHUB_PATH
        
      # Step 3: Run the machine command.
      - name: Start a temporary machine and wait for completion
        env:
          FLY_API_TOKEN: ${{ secrets.FLY_API_TOKEN }}
        run: |
          # 'flyctl' can now be called directly.
          flyctl machine run . --region lhr --memory 2048
          
          echo "The machine has completed its run and has been destroyed."

# File: .gitignore
/node_modules
/.pnpm
.pnp.*
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/versions
# misc
.DS_Store
*.pem
# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*
# env files
.env*
!/.env.template
# vercel
.vercel
# typescript
*.tsbuildinfo
next-env.d.ts

# File: .nvmrc
20.15.1


# File: CLAUDE.md
# File: CLAUDE.md (version 1.02)
# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

**Headlines-Mongo** is a news processing application that scrapes Danish business news (BÃ¸rsen, Berlingske, Politiken, Finans.dk), assesses relevance using AI/LLM, and sends curated newsletters via email. The application is deployed on Fly.io and is designed to be triggered by a scheduler.

## Architecture

The application is architected as a **script-based, scheduled task** that runs its data pipeline once and then exits. It is not a web server.

1.  **Trigger**: The application is triggered directly by a scheduler (e.g., Fly.io's `schedule` attribute in `fly.toml` or a local cron job) which executes the `npm start` command.
2.  **Scraping**: Fetch headlines from configured sources.
3.  **Filtering**: Skip articles already in the database.
4.  **AI Assessment (Headlines)**: LLM evaluates headline relevance (threshold: 10).
5.  **Enrichment**: Extract full article content for relevant headlines.
6.  **AI Assessment (Content)**: LLM evaluates article content quality (threshold: 10).
7.  **Storage**: Store relevant articles in MongoDB.
8.  **Email**: Send curated newsletters and a supervisor report directly via a configured SMTP service.

All processing is done within the `runPipeline` function call.

## Core Components

### Key Files
- `app.js`: Main application entry point. Sets up the environment and triggers the pipeline.
- `app-logic.js`: Contains the `runPipeline` function which orchestrates the entire data processing flow from start to finish.
- `src/config/sources.js`: Web scraping configuration for Danish news sites.
- `src/config/env.js`: Centralized module for reading and exporting all environment variables.
- `src/config/email.js`: SMTP and email content configuration.

### Pipeline Modules
- `src/modules/scraping/fetchHeadlines.js`: Multi-source headline extraction.
- `src/modules/assessments/assessHeadlines.js`: AI relevance scoring for headlines.
- `src/modules/assessments/assessArticles.js`: AI content quality scoring.
- `src/modules/scraping/enrichWithBody.js`: Full article content extraction.
- `src/modules/email/index.js`: Email composition and delivery coordination.
- `src/modules/mongoStore/articleOperations.js`: MongoDB CRUD operations.

### Models
- `models/Article.js`: MongoDB schema with comprehensive fields for AI scoring and processing metadata.

## Development Commands

### Core Operations
```bash
# Run the pipeline script locally
npm start

# Run in test mode, re-processing articles from the current scrape
node app.js --refresh

# Run the Jest test suite
npm test

# File: Dockerfile
# File: Dockerfile (version 1.02)
# syntax = docker/dockerfile:1

ARG NODE_VERSION=20.15.1
FROM node:${NODE_VERSION}-slim AS base

WORKDIR /app

# --- Build Stage ---
FROM base AS build
RUN apt-get update -qq && apt-get install -y --no-install-recommends build-essential python-is-python3
COPY package-lock.json package.json ./

# Switch to `npm install` which is more robust than `npm ci` in complex scenarios,
# especially with `file:` dependencies that might exist locally but not in the build context.
# Using --omit=dev is equivalent to --production, ensuring dev dependencies are not installed.
RUN npm install --omit=dev

COPY . .

# --- Final Production Image ---
FROM base
COPY --from=build --chown=node:node /app /app
USER node

# This is no longer a web server, so no EXPOSE needed.
# It runs the pipeline script once and then exits.
CMD [ "node", "app.js" ]

# File: app-logic.js
// app-logic.js
import { connectDatabase, disconnectDatabase } from './src/database.js';
import { scrapeAllHeadlines, scrapeArticleContent } from './src/modules/scraper/index.js';
import { filterFreshArticles, prepareArticlesForPipeline, updateArticlesWithFullData } from './src/modules/mongoStore/index.js';
import { assessHeadlinesInBatches, assessArticleContent, performKimiSanityCheck, checkModelPermissions } from './src/modules/ai/index.js';
import { clusterArticlesIntoEvents, synthesizeEvent } from './src/modules/ai/eventProcessing.js';
import { findSimilarArticles } from './src/modules/ai/rag.js';
import Article from './models/Article.js';
import SynthesizedEvent from './models/SynthesizedEvent.js';
import { logger } from './src/utils/logger.js';
import { ARTICLES_RELEVANCE_THRESHOLD, HEADLINES_RELEVANCE_THRESHOLD, LLM_MODEL_TRIAGE, LLM_MODEL_ARTICLES, IS_REFRESH_MODE } from './src/config/index.js';
import { sendWealthEventsEmail, sendSupervisorReportEmail } from './src/modules/email/index.js';
import { truncateString } from './src/utils/helpers.js';

export async function runPipeline() {
    const runStartTime = Date.now();
    logger.info('ðŸš€ STARTING SYNTHESIS PIPELINE...');
    const runStats = {
        headlinesScraped: 0,
        scraperHealth: [],
        freshHeadlinesFound: 0,
        headlinesAssessed: 0,
        relevantHeadlines: 0,
        articlesEnriched: 0,
        enrichedBySource: {},
        eventsClustered: 0,
        eventsSynthesized: 0,
        eventsEmailed: 0,
        errors: [],
    };

    let dbConnected = false;

    try {
        // --- STEP 1: PRE-FLIGHT CHECKS & DB CONNECTION ---
        const requiredModels = [LLM_MODEL_TRIAGE, LLM_MODEL_ARTICLES];
        if (!await performKimiSanityCheck() || !await checkModelPermissions(requiredModels)) {
            logger.fatal('AI service checks failed. Aborting pipeline.');
            return;
        }
        await connectDatabase();
        dbConnected = true;

        // --- STEP 2: SCRAPE & PREPARE ARTICLES ---
        const { allArticles: scrapedHeadlines, scraperHealth } = await scrapeAllHeadlines();
        runStats.scraperHealth = scraperHealth;
        runStats.headlinesScraped = scrapedHeadlines.length;
        
        const articlesToProcess = await filterFreshArticles(scrapedHeadlines);
        runStats.freshHeadlinesFound = articlesToProcess.length;

        if (articlesToProcess.length === 0) {
            logger.info('No new or refreshed articles to process. Ending run.');
            return;
        }
        
        const articlesForPipeline = await prepareArticlesForPipeline(articlesToProcess);

        if (articlesForPipeline.length === 0) {
            logger.info('No articles were successfully prepared for the pipeline. Ending run.');
            return;
        }

        // --- STEP 3: HEADLINE ASSESSMENT ---
        const assessedCandidates = await assessHeadlinesInBatches(articlesForPipeline);
        runStats.headlinesAssessed = assessedCandidates.length;

        logger.info('--- Headline Assessment Complete ---');
        assessedCandidates.forEach(a => {
            const status = a.relevance_headline >= HEADLINES_RELEVANCE_THRESHOLD ? 'âœ… Relevant' : 'âŒ Irrelevant';
            logger.info(`[${String(a.relevance_headline).padStart(3, ' ')}] ${status} - "${truncateString(a.headline, 70)}"`);
        });

        const relevantCandidates = assessedCandidates.filter(a => a.relevance_headline >= HEADLINES_RELEVANCE_THRESHOLD);
        runStats.relevantHeadlines = relevantCandidates.length;

        if (relevantCandidates.length === 0) {
            logger.info('No headlines met the relevance threshold for event synthesis.');
            return;
        }
        logger.info(`Found ${relevantCandidates.length} relevant headlines for enrichment.`);
        
        // --- STEP 4: ENRICHMENT & ARTICLE ASSESSMENT ---
        const enrichedArticles = [];
        for (const article of relevantCandidates) {
            const enriched = await scrapeArticleContent(article);
            if (enriched.articleContent && enriched.articleContent.contents.join('').length > 150) {
                const finalAssessment = await assessArticleContent(enriched);
                if (finalAssessment.relevance_article >= ARTICLES_RELEVANCE_THRESHOLD) {
                    enrichedArticles.push(finalAssessment);
                    runStats.articlesEnriched++;
                    runStats.enrichedBySource[article.source] = (runStats.enrichedBySource[article.source] || 0) + 1;
                }
            }
        }
        await updateArticlesWithFullData(enrichedArticles);
        logger.info(`Enriched and assessed ${enrichedArticles.length} full articles meeting the relevance threshold.`);

        if (enrichedArticles.length === 0) {
            logger.info('No articles met the full article relevance threshold for event synthesis.');
            return;
        }

        // --- STEP 5: CLUSTERING ---
        const eventClusters = await clusterArticlesIntoEvents(enrichedArticles);
        runStats.eventsClustered = eventClusters.length;
        if (eventClusters.length === 0) {
            logger.info('No unique events were clustered from the relevant articles.');
            return;
        }
        logger.info(`Clustered ${enrichedArticles.length} articles into ${eventClusters.length} unique events.`);

        // --- STEP 6: SYNTHESIS ---
        const synthesizedEventsToSave = [];
        for (const cluster of eventClusters) {
            const articlesInCluster = enrichedArticles.filter(a => cluster.article_ids.includes(a._id.toString()));
            if (articlesInCluster.length === 0) continue;

            const historicalContext = await findSimilarArticles(articlesInCluster);
            const synthesizedEvent = await synthesizeEvent(articlesInCluster, historicalContext);

            if (synthesizedEvent && !synthesizedEvent.error) {
                runStats.eventsSynthesized++;
                logger.info(`Synthesized Event: "${truncateString(synthesizedEvent.headline, 80)}"`);
                
                // Find the highest-scoring article to source the assessment reason from.
                const highestScoringArticle = articlesInCluster.reduce((max, current) => 
                    (current.relevance_article > max.relevance_article) ? current : max, articlesInCluster[0]
                );

                const aggregatedIndividuals = articlesInCluster.flatMap(a => a.key_individuals || []);
                const uniqueIndividuals = Array.from(new Map(aggregatedIndividuals.map(p => [p.name, p])).values());

                const eventToSave = new SynthesizedEvent({
                    event_key: cluster.event_key,
                    synthesized_headline: synthesizedEvent.headline,
                    synthesized_summary: synthesizedEvent.summary,
                    ai_assessment_reason: highestScoringArticle.assessment_article || highestScoringArticle.assessment_headline,
                    highest_relevance_score: Math.max(...articlesInCluster.map(a => a.relevance_article)),
                    key_individuals: uniqueIndividuals,
                    source_articles: articlesInCluster.map(a => ({
                        article_id: a._id,
                        headline: a.headline,
                        link: a.link,
                        newspaper: a.newspaper
                    })),
                });
                synthesizedEventsToSave.push(eventToSave);
            }
        }

        if (synthesizedEventsToSave.length > 0) {
            await SynthesizedEvent.bulkWrite(
                synthesizedEventsToSave.map(e => ({
                    updateOne: {
                        filter: { event_key: e.event_key },
                        update: { $set: e },
                        upsert: true,
                    }
                }))
            );
            logger.info(`Successfully saved/updated ${synthesizedEventsToSave.length} synthesized events.`);
        }
        
        // --- STEP 7: SEND EMAIL ---
        const emailResult = await sendWealthEventsEmail();
        runStats.eventsEmailed = emailResult.eventsSentCount;

    } catch (error) {
        logger.fatal({ err: error }, 'A critical error occurred in the main pipeline');
        runStats.errors.push(`CRITICAL: ${error.message}`);
    } finally {
        const runEndTime = Date.now();
        const duration = ((runEndTime - runStartTime) / 1000).toFixed(2);
        
        if (dbConnected) {
             await sendSupervisorReportEmail(runStats);
             await disconnectDatabase();
        } else {
             logger.info('Pipeline halted before DB connection. No supervisor report sent.');
        }
       
        logger.info(`PIPELINE FINISHED in ${duration} seconds. Emailed ${runStats.eventsEmailed} events.`);
    }
}

# File: app.js
// app.js
import 'dotenv/config'; // Load environment variables at the very beginning
import { logger } from './src/utils/logger.js';
import { runPipeline } from './app-logic.js';

// NEW: Check for a '--refresh' command-line argument to enable re-processing.
const isRefreshMode = process.argv.includes('--refresh');
if (isRefreshMode) {
    process.env.REFRESH_MODE = 'true';
    logger.warn('ðŸš€ REFRESH MODE ACTIVATED: Previously processed articles from this scrape will be treated as fresh.');
}

async function start() {
    try {
        await runPipeline();
        // The process will exit naturally after the pipeline completes.
    } catch (error) {
        logger.fatal({ err: error }, 'A top-level, unhandled exception occurred in the application. The pipeline did not complete.');
        // Exit with a failure code to signal an issue to the scheduler (e.g., Fly.io).
        process.exit(1);
    }
}

start();

# File: docker-compose.yml
# docker-compose.yml (version 1.03)
# This file is for LOCAL DEVELOPMENT and TESTING ONLY.
# It allows us to reliably run the application in a container,
# mimicking the production environment.

services:
  app:
    # Build the image from the Dockerfile in the current directory.
    build: .
    # Use the .env file to supply environment variables to the container.
    # docker-compose has a robust parser that handles special characters correctly.
    env_file:
      - .env
    # The application is a script, not a web server, so no port mapping is needed.
    # Give the container a friendly name.
    container_name: headlines_local

# File: fly.toml
app = 'headlines-polished-sea-1731'
primary_region = 'lhr'

# This empty [processes] block tells flyctl to use the modern Machines platform
# and not look for a long-running web service.
# This is now the ONLY machine-related configuration in this file.
[processes]

# File: models/Article.js
// models/Article.js
import mongoose from 'mongoose';

const { Schema, model, models } = mongoose;

const ArticleSchema = new Schema(
  {
    headline: {
      type: String,
      required: true,
      trim: true,
      minlength: 10,
      maxlength: 500,
    },
    link: { type: String, required: true, unique: true, trim: true },
    newspaper: { type: String, required: true, trim: true },
    source: { type: String, required: true, trim: true },
    section: { type: String, required: false, trim: true },
    author: { type: String, required: false, trim: true },
    published: { type: String, required: false, trim: true },
    position: { type: String, required: false, trim: true },
    raw: { type: Schema.Types.Mixed, required: false },
    relevance_headline: { type: Number, required: true, min: 0, max: 100 },
    assessment_headline: { type: String, required: true, trim: true },
    articleContent: {
      headlines: { type: [String], required: false, default: [] },
      subheadings: { type: [String], required: false, default: [] },
      captions: { type: [String], required: false, default: [] },
      contents: { type: [String], required: false, default: [] },
    },
    topic: { type: String, required: false, trim: true },
    relevance_article: { type: Number, required: false, min: 0, max: 100 },
    assessment_article: { type: String, required: false, trim: true },
    amount: { type: Number, required: false },
    key_individuals: [{
        name: String,
        role_in_event: String,
        company: String,
        email_suggestion: { type: String, required: false }, // NEW FIELD
    }],
    background: { type: String, required: false, trim: true },
    error: { type: String, required: false, trim: true, default: null },
    enrichment_error: { type: String, required: false, trim: true, default: null },
    storage_error_initial_headline_data: { type: String, required: false, trim: true, default: null },
    db_operation_status: { type: String, required: false, trim: true },
    db_error_reason: { type: String, required: false, trim: true },
    emailed: { type: Boolean, default: false },
    email_error: { type: String, required: false, trim: true, default: null },
    email_skipped_reason: { type: String, required: false, trim: true, default: null },
    embedding: { type: [Number], required: false },
  },
  {
    timestamps: true,
    collection: 'articles',
  }
);

ArticleSchema.index({ headline: 1 });
ArticleSchema.index({ newspaper: 1, createdAt: -1 });
ArticleSchema.index({ relevance_article: -1, createdAt: -1 });
ArticleSchema.index({ relevance_headline: -1, createdAt: -1 });

export default models.Article || model('Article', ArticleSchema);

# File: models/SynthesizedEvent.js
// models/SynthesizedEvent.js
import mongoose from 'mongoose';

const { Schema, model, models } = mongoose;

const SourceArticleSchema = new Schema({
  article_id: { type: Schema.Types.ObjectId, ref: 'Article', required: true },
  headline: { type: String, required: true },
  link: { type: String, required: true },
  newspaper: { type: String, required: true },
}, { _id: false });

const KeyIndividualSchema = new Schema({
    name: String,
    role_in_event: String,
    company: String,
    email_suggestion: { type: String, required: false },
}, { _id: false });

const SynthesizedEventSchema = new Schema(
  {
    event_key: {
      type: String,
      required: true,
      unique: true,
      trim: true,
      index: true,
      description: "A unique key for the event, e.g., 'acquisition-visma-innovateai-2024-05-20'",
    },
    synthesized_headline: { type: String, required: true, trim: true },
    synthesized_summary: { type: String, required: true, trim: true },
    ai_assessment_reason: { type: String, required: false }, // NEW FIELD
    source_articles: { type: [SourceArticleSchema], required: true },
    highest_relevance_score: { type: Number, required: true },
    key_individuals: { type: [KeyIndividualSchema], required: true },
    event_date: { type: Date, default: Date.now },
    emailed: { type: Boolean, default: false },
    email_sent_at: { type: Date },
  },
  {
    timestamps: true,
    collection: 'synthesized_events',
  }
);

SynthesizedEventSchema.index({ event_date: -1 });

export default models.SynthesizedEvent || model('SynthesizedEvent', SynthesizedEventSchema);

# File: norway.js
import axios from 'axios';
import * as cheerio from 'cheerio';

const url = 'https://www.finansavisen.no/kapital';

/**
 * Fetches the HTML content of the target website.
 * @returns {Promise<string>} The HTML content as a string.
 */
async function downloadWebsite() {
  try {
    console.log(`Downloading HTML from ${url}...`);
    const response = await axios.get(url);
    return response.data;
  } catch (error) {
    console.error(`Error downloading the website: ${error.message}`);
    process.exit(1);
  }
}

/**
 * Parses the HTML to extract headlines and their hyperlinks.
 * @param {string} html - The HTML content of the website.
 * @returns {Array<Object>} A list of article objects with headlines and hyperlinks.
 */
function listHeadlines(html) {
  const articles = [];
  const $ = cheerio.load(html);
  const baseUrl = 'https://www.finansavisen.no';

  // Each article seems to be within an <article> tag with the class 'dre-item'
  $('article.dre-item').each((index, element) => {
    // The headline text and link are within an <a> tag with the class 'dre-item__title'
    const titleElement = $(element).find('a.dre-item__title');
    
    if (titleElement.length > 0) {
      // Extract the raw text and clean it up by removing extra whitespace/newlines
      const headline = titleElement.text().trim().replace(/\s+/g, ' ');
      const relativeLink = titleElement.attr('href');

      if (headline && relativeLink) {
        articles.push({
          headline: headline,
          hyperlink: `${baseUrl}${relativeLink}`
        });
      }
    }
  });
  
  return articles;
}

/**
 * Main function to run the scraper.
 */
async function main() {
  const html = await downloadWebsite();
  const headlines = listHeadlines(html);
  
  console.log('Successfully scraped the following headlines:');
  console.log(JSON.stringify(headlines, null, 2));
}

main();

# File: package.json
{
  "name": "headlines-pipeline",
  "version": "3.0.0",
  "description": "A Node.js pipeline to scrape, analyze, and store news articles about wealth events.",
  "main": "app.js",
  "type": "module",
  "scripts": {
    "start": "node app.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [
    "scraper",
    "axios",
    "cheerio",
    "nodejs",
    "openai",
    "mongoose"
  ],
  "author": "The Driver",
  "license": "ISC",
  "dependencies": {
    "@xenova/transformers": "^2.17.2",
    "axios": "^1.7.2",
    "cheerio": "^1.0.0-rc.12",
    "dotenv": "^16.4.5",
    "https-proxy-agent": "^7.0.6",
    "mongoose": "^8.4.1",
    "nodemailer": "^6.9.13",
    "openai": "^4.47.3",
    "p-limit": "^5.0.0",
    "pino": "^9.1.0",
    "pino-pretty": "^11.1.0"
  }
}


# File: scrape.js
// scrape.js
// A utility script to scrape a few headlines and articles from each configured source.
// This is useful for testing, debugging, and adding new newspapers.
// It now directly uses the main application's scraping modules for consistency.
// To run: `node scrape.js` from the project root.

import 'dotenv/config';
import { SITES_CONFIG } from './src/config/sources.js';
import { scrapeAllHeadlines, scrapeArticleContent } from './src/modules/scraper/index.js';
import { truncateString } from './src/utils/helpers.js';

// --- Configuration ---
const HEADLINES_TO_SCRAPE_PER_SITE = 3;

// --- Console Colors for Readability ---
const colors = {
    reset: "\x1b[0m",
    red: "\x1b[31m",
    green: "\x1b[32m",
    yellow: "\x1b[33m",
    cyan: "\x1b[36m",
    grey: "\x1b[90m",
};
const log = {
    info: (msg) => console.log(`${colors.cyan}${msg}${colors.reset}`),
    success: (msg) => console.log(`${colors.green}${msg}${colors.reset}`),
    warn: (msg) => console.log(`${colors.yellow}${msg}${colors.reset}`),
    error: (msg) => console.log(`${colors.red}${msg}${colors.reset}`),
};


/**
 * Main function to orchestrate the test scrape.
 */
async function main() {
    log.info(`ðŸš€ Starting test scrape for ${HEADLINES_TO_SCRAPE_PER_SITE} articles per site...`);

    const { allArticles } = await scrapeAllHeadlines(); // MODIFIED: Destructure to get the articles array.
    const sites = Object.values(SITES_CONFIG);

    for (const site of sites) {
        log.info(`\n==================== ðŸ“° ${site.name.toUpperCase()} ====================`);

        // FIX: Filter by `h.source` which is guaranteed to match `site.name`.
        const siteHeadlines = allArticles
            .filter(h => h.source === site.name)
            .slice(0, HEADLINES_TO_SCRAPE_PER_SITE);

        if (siteHeadlines.length === 0) {
            log.warn(`No headlines found for ${site.name}.`);
            continue;
        }

        log.info(`Found ${siteHeadlines.length} headlines. Fetching full article content...`);

        for (const [index, headline] of siteHeadlines.entries()) {
            console.log(`\n[${index + 1}/${siteHeadlines.length}] ${truncateString(headline.headline, 80)}`);
            console.log(`${colors.grey}  -> ${headline.link}${colors.reset}`); // Always show link
            
            // Use the main application's function to fetch and parse the article
            const articleWithContent = await scrapeArticleContent(headline);

            if (articleWithContent.articleContent?.contents?.length > 0) {
                const contentSnippet = articleWithContent.articleContent.contents.join(' ').trim().replace(/\s\s+/g, ' ').substring(0, 150);
                log.success(`  âœ… SUCCESS: "${contentSnippet}..."`);
            } else {
                const reason = articleWithContent.enrichment_error || 'Selector did not find content (this is expected for live blogs or paywalled articles)';
                log.error(`  âŒ FAILED: ${reason}`);
            }
        }
    }

    log.info('\nâœ… Test scrape finished.');
}

// --- Execute Script ---
main().catch(err => {
    console.error(err);
    log.error('The test scrape script encountered a fatal error.');
    process.exit(1);
});

# File: scripts/embedPastArticles.js
// scripts/embedPastArticles.js
import 'dotenv/config';
import mongoose from 'mongoose';
import { connectDatabase, disconnectDatabase } from '../src/database.js';
import Article from '../models/Article.js';
import { generateEmbedding } from '../src/utils/vectorUtils.js';
import { logger } from '../src/utils/logger.js';

async function embedPastArticles() {
    logger.info('Starting backfill process for article embeddings...');
    await connectDatabase();

    const articlesToProcess = await Article.find({ embedding: { $exists: false } }).lean();

    if (articlesToProcess.length === 0) {
        logger.info('No articles found without embeddings. Process complete.');
        await disconnectDatabase();
        return;
    }

    logger.info(`Found ${articlesToProcess.length} articles to embed. This may take some time...`);
    
    let processedCount = 0;
    const operations = [];

    for (const article of articlesToProcess) {
        try {
            const textToEmbed = `${article.headline}\n${article.assessment_headline || ''}`;
            const embedding = await generateEmbedding(textToEmbed);

            operations.push({
                updateOne: {
                    filter: { _id: article._id },
                    update: { $set: { embedding: embedding } }
                }
            });
            
            processedCount++;
            logger.info(`(${processedCount}/${articlesToProcess.length}) Embedded: "${article.headline}"`);

        } catch (error) {
            logger.error({ err: error, articleId: article._id }, `Failed to process article.`);
        }
    }

    if (operations.length > 0) {
        logger.info(`Bulk writing ${operations.length} updates to the database...`);
        await Article.bulkWrite(operations, { ordered: false });
        logger.info('âœ… Bulk write complete.');
    }

    logger.info('Embedding backfill process finished.');
    await disconnectDatabase();
}

embedPastArticles().catch(err => {
    logger.fatal({ err }, 'An unhandled error occurred during the embedding backfill process.');
    process.exit(1);
});

# File: scripts/reDeploy.sh
#!/bin/bash
# redeploy.sh
# A script to completely destroy, re-create, set secrets, and then redeploy the Fly.io app.
# This ensures a clean slate, removing any old machines or volumes.

# --- Configuration ---
# Colors for better logging
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0;33[0m' # No Color

# --- Pre-flight Checks ---
echo -e "${YELLOW}--- Running Pre-flight Checks ---${NC}"

if ! command -v fly &> /dev/null; then
    echo -e "${RED}Error: 'fly' command-line tool not found.${NC}"
    exit 1
fi

if [ ! -f "fly.toml" ]; then
    echo -e "${RED}Error: No fly.toml file found in this directory.${NC}"
    exit 1
fi

if [ ! -f "scripts/setFlySecrets.sh" ]; then
    echo -e "${RED}Error: The secrets script is missing at 'scripts/setFlySecrets.sh'.${NC}"
    exit 1
fi

APP_NAME=$(grep '^app = ' fly.toml | cut -d "'" -f 2)

if [ -z "$APP_NAME" ]; then
    echo -e "${RED}Error: Could not determine app name from fly.toml.${NC}"
    exit 1
fi

echo -e "${GREEN}Checks passed. App name is '${APP_NAME}'.${NC}"
echo ""

# --- Step 1: Destroy the App (with confirmation and error handling) ---
echo -e "${YELLOW}--- Step 1: Destroying the App ---${NC}"
echo -e "${RED}WARNING: This is a destructive action. It will permanently delete the app '${APP_NAME}' if it exists.${NC}"
read -p "Are you absolutely sure you want to proceed with the full redeploy? (y/N) " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "Operation cancelled by user."
    exit 1
fi

echo "Attempting to destroy '${APP_NAME}'..."
DESTROY_OUTPUT=$(fly apps destroy "$APP_NAME" --yes 2>&1)
DESTROY_STATUS=$?

if [ $DESTROY_STATUS -eq 0 ]; then
    echo -e "${GREEN}App '${APP_NAME}' destroyed successfully.${NC}"
elif echo "$DESTROY_OUTPUT" | grep -q "Could not find App"; then
    echo -e "${YELLOW}Warning: App '${APP_NAME}' did not exist. Continuing to the create step.${NC}"
else
    echo -e "${RED}An error occurred while trying to destroy the app:${NC}"
    echo "$DESTROY_OUTPUT"
    exit 1
fi
echo ""


# --- Step 2: Create the App ---
echo -e "${YELLOW}--- Step 2: Creating the App ---${NC}"
echo "Registering a new, empty app shell on Fly.io for '${APP_NAME}'..."

fly apps create "$APP_NAME" --org personal

if [ $? -ne 0 ]; then
    echo -e "${RED}An error occurred while creating the app. Please check the output above.${NC}"
    exit 1
fi
echo -e "${GREEN}Empty app shell for '${APP_NAME}' created successfully.${NC}"
echo ""


# --- Step 3: Set Secrets ---
echo -e "${YELLOW}--- Step 3: Setting Secrets ---${NC}"
echo "Running the setFlySecrets.sh script to populate environment variables..."

# Automatically answer 'y' to the confirmation prompt within setFlySecrets.sh
# to avoid being prompted twice.
echo 'y' | bash ./scripts/setFlySecrets.sh

if [ $? -ne 0 ]; then
    echo -e "${RED}An error occurred while setting secrets. Please check the output above.${NC}"
    exit 1
fi
echo -e "${GREEN}Secrets set successfully.${NC}"
echo ""


# --- Step 4: Deploy the App ---
echo -e "${YELLOW}--- Step 4: Deploying the App ---${NC}"
echo "Deploying the project to the new instance of '${APP_NAME}'..."
echo "This will create a new release and 1 stopped machine with 2048MB of memory."

# MODIFIED: Use explicit flags to force the machine size during the initial deploy.
# This is the definitive way to set the size for this type of worker app.
fly deploy --vm-cpus 1 --vm-memory 2048

if [ $? -eq 0 ]; then
    echo -e "${GREEN}âœ… Successfully deployed '${APP_NAME}'. The initial machine has been configured with 2048MB of memory.${NC}"
else
    echo -e "${RED}âŒ An error occurred during deployment. Please check the output above.${NC}"
    exit 1
fi

# File: scripts/setFlySecrets.sh
#!/bin/bash
# scripts/setFlySecrets.sh (version 1.0)

# A script to read a .env file and set the variables as Fly.io secrets.
# It builds a single command to set all secrets at once for efficiency.

# --- Configuration ---
ENV_FILE=".env"

# --- Pre-flight Checks ---

# Check for .env file
if [ ! -f "$ENV_FILE" ]; then
    echo "Error: .env file not found in the current directory."
    exit 1
fi

# Check for flyctl command
if ! command -v fly &> /dev/null
then
    echo "Error: 'fly' command-line tool not found."
    exit 1
fi

if [ ! -f "fly.toml" ]; then
    echo "Error: No fly.toml file found in this directory."
    echo "Please run 'fly launch' first."
    exit 1
fi

APP_NAME=$(grep '^app = ' fly.toml | cut -d "'" -f 2)
if [ -z "$APP_NAME" ]; then
    echo "Error: Could not determine app name from fly.toml."
    exit 1
fi

echo "Reading secrets from '$ENV_FILE' for app '$APP_NAME'..."

# --- Main Logic ---
secrets_args=()
while IFS= read -r line || [ -n "$line" ]; do
    # Skip comments and empty lines
    if [[ "$line" =~ ^#.* ]] || [[ -z "$line" ]]; then
        continue
    fi
    # Handle carriage return for Windows-edited .env files
    line=$(echo "$line" | tr -d '\r')
    key=$(echo "$line" | cut -d '=' -f 1)
    # Correctly extract value, even if it contains '='
    value=$(echo "$line" | sed -e "s/^$key=//")
    if [ -z "$key" ]; then
        continue
    fi
    # Use printf for robust quoting to handle special characters
    secrets_args+=("$(printf "%s=%s" "$key" "$value")")
    echo "  - Found secret: $key"
done < "$ENV_FILE"

if [ ${#secrets_args[@]} -eq 0 ]; then
    echo "No secrets to set were found in '$ENV_FILE'."
    exit 0
fi

echo ""
echo "The following secrets will be set for the app '$APP_NAME':"
for arg in "${secrets_args[@]}"; do
    key=$(echo "$arg" | cut -d '=' -f 1)
    echo "  - $key"
done
echo ""

read -p "Are you sure you want to proceed? (y/N) " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]
then
    echo "Operation cancelled by user."
    exit 1
fi

echo "Setting secrets on Fly.io..."
fly secrets set --stage "${secrets_args[@]}"

if [ $? -eq 0 ]; then
    echo "âœ… Successfully set ${#secrets_args[@]} secrets. A new release is being created."
else
    echo "âŒ An error occurred while setting secrets."
    exit 1
fi

# File: src/config/index.js
// src/config/index.js
import dotenv from 'dotenv';

dotenv.config();

/**
 * Helper function to safely read and clean string environment variables.
 * It trims whitespace and removes surrounding quotes.
 * @param {string} key The environment variable key.
 * @param {string} defaultValue The default value if the key is not found.
 * @returns {string} The cleaned environment variable value.
 */
function getCleanStringEnv(key, defaultValue = '') {
    let value = process.env[key] || defaultValue;
    value = value.trim();
    if ((value.startsWith('"') && value.endsWith('"')) || (value.startsWith("'") && value.endsWith("'"))) {
        return value.slice(1, -1);
    }
    return value;
}


// --- Core App Behavior ---
export const NODE_ENV = getCleanStringEnv('NODE_ENV', 'development');
export const IS_PRODUCTION = NODE_ENV === 'production';
export const LOG_LEVEL = getCleanStringEnv('LOG_LEVEL', 'info');
export const CONCURRENCY_LIMIT = parseInt(process.env.CONCURRENCY_LIMIT, 10) || 3;
export const FORCE_EMAIL_SEND_DEV = process.env.FORCE_EMAIL_SEND_DEV === 'true';
export const IS_REFRESH_MODE = process.env.REFRESH_MODE === 'true';

// --- Database ---
export const MONGO_URI = getCleanStringEnv('MONGO_URI');

// --- LLM Configuration ---
export const KIMI_API_KEY = getCleanStringEnv('KIMI_API_KEY');
export const LLM_MODEL_TRIAGE = getCleanStringEnv('LLM_MODEL_TRIAGE', 'moonshot-v1-8k');
export const LLM_MODEL_HEADLINES = getCleanStringEnv('LLM_MODEL_HEADLINES', 'moonshot-v1-8k');
export const LLM_MODEL_ARTICLES = getCleanStringEnv('LLM_MODEL_ARTICLES', 'moonshot-v1-32k');

// --- Scraper Configuration ---
export const SCRAPER_PROXY_URL = getCleanStringEnv('SCRAPER_PROXY_URL') || null;


// --- Thresholds ---
export const HEADLINES_RELEVANCE_THRESHOLD = 20; // MODIFIED: Changed from 10 to 20
export const ARTICLES_RELEVANCE_THRESHOLD = 50; // MODIFIED: Changed from 30 to 50
export const MIN_ARTICLE_CHARS = 150;
export const MAX_ARTICLE_CHARS = 100000;
export const MIN_HEADLINE_CHARS = 5;
export const MAX_HEADLINE_CHARS = 500;
export const AI_BATCH_SIZE = 6;

// --- Email Configuration ---
export const SMTP_CONFIG = {
    host: getCleanStringEnv('SMTP_HOST'),
    port: parseInt(process.env.SMTP_PORT, 10) || 587,
    secure: process.env.SMTP_SECURE === 'true',
    auth: {
        user: getCleanStringEnv('SMTP_USER'),
        pass: getCleanStringEnv('SMTP_PASS'),
    },
    fromAddress: getCleanStringEnv('SMTP_FROM_ADDRESS') || getCleanStringEnv('SMTP_USER'),
    fromName: getCleanStringEnv('SMTP_FROM_NAME', 'Headlines Bot'),
};

export const HEADLINE_RECIPIENTS_STR = getCleanStringEnv('HEADLINE_RECIPIENTS');
export const SUPERVISOR_EMAIL_ENV = getCleanStringEnv('SUPERVISOR_EMAIL', 'your-supervisor-default@example.com');
export const SEND_TO_DEFAULT_SUPERVISOR_ENV = process.env.SEND_TO_DEFAULT_SUPERVISOR === 'true';

// Derived Email Config
export const HEADLINE_RECIPIENTS = HEADLINE_RECIPIENTS_STR.split(',').map(e => e.trim()).filter(Boolean);
export const SUPERVISOR_EMAIL = SUPERVISOR_EMAIL_ENV;
export const SEND_TO_DEFAULT_SUPERVISOR = SEND_TO_DEFAULT_SUPERVISOR_ENV;

// --- Email Template Config ---
export const EMAIL_CONFIG = {
  templateName: 'wealthEvents',
  subject: 'ðŸ‡©ðŸ‡° ðŸ‡³ðŸ‡´ New Nordic Banking Opportunities Detected',
  language: 'en',
  brandName: 'Nordic Wealth Watch',
  companyAddress: 'Wealth Watch Inc., Copenhagen, Denmark',
  unsubscribeUrl: '#',
};

export const SUPERVISOR_EMAIL_CONFIG = {
  templateName: 'supervisorReport',
  subject: 'âš™ï¸ Hourly Headlines Processing Run Summary',
  language: 'en',
  brandName: 'Headlines Processing Bot',
};

# File: src/config/sources.js
// src/config/sources.js
// Centralized configuration for web scraping sources.
// This separates the scraper's target configuration from its operational logic.

export const SITES_CONFIG = {
    berlingske: { name: 'Berlingske', url: 'https://www.berlingske.dk/business', selector: 'h4.teaser__title a.teaser__title-link', extract: (el, site) => ({ headline: el.text().trim(), link: new URL(el.attr('href'), site.url).href, source: site.name, newspaper: site.name }) },
    borsen: { name: 'BÃ¸rsen', url: 'https://borsen.dk/nyheder', useJsonLd: true },
    politiken: { name: 'Politiken', url: 'https://politiken.dk/danmark/oekonomi/', selector: 'article', extract: (el, site) => { const h = el.find('h2, h3, h4').first().text().trim(); const a = el.find('a[href*="/art"]').first().attr('href'); return h && a ? { headline: h, link: new URL(a, site.url).href, source: site.name, newspaper: site.name } : null; } },
    finans: { name: 'Finans.dk', url: 'https://finans.dk/seneste-nyt', selector: 'article a h3', extract: (el, site) => ({ headline: el.text().trim(), link: el.closest('a').attr('href'), source: site.name, newspaper: site.name }) },
    
    // MODIFIED: Removing DN Investor as it is un-scrapable with the current method (JS-driven, no href links).
    // dn_investor: {
    //     name: 'DN Investor',
    //     url: 'https://www.dn.no/investor',
    //     newspaper: 'DN.no',
    //     ...
    // },

    axcel: {
        name: 'Axcel',
        url: 'https://axcel.com/news',
        selector: 'div.news-mask a',
        extract: (el, site) => ({
            headline: el.find('h3').text().trim(),
            link: new URL(el.attr('href'), site.url).href,
            source: site.name,
            newspaper: site.name
        })
    },
    polaris: {
        name: 'Polaris',
        url: 'https://polarisequity.dk/news',
        selector: 'div.fl-post-feed-post',
        extract: (el, site) => {
            const linkEl = el.find('h3.fl-post-feed-title a');
            const headline = linkEl.text().trim();
            const href = linkEl.attr('href');
            if (headline && href) {
                return { headline, link: new URL(href, site.url).href, source: site.name, newspaper: site.name };
            }
            return null;
        }
    },
    finansavisen: {
        name: 'Finansavisen',
        url: 'https://www.finansavisen.no/',
        newspaper: 'Finansavisen',
        selector: 'article.dre-item a.dre-item__title',
        extract: (el, site) => ({
            headline: el.text().trim(),
            link: new URL(el.attr('href'), site.url).href,
            source: site.name,
            newspaper: site.newspaper
        })
    },
    finansavisen_kapital: {
        name: 'Finansavisen Kapital',
        url: 'https://www.finansavisen.no/kapital',
        newspaper: 'Kapital',
        selector: 'article.dre-item a.dre-item__title',
        extract: (el, site) => ({
            headline: el.text().trim(),
            link: new URL(el.attr('href'), site.url).href,
            source: site.name,
            newspaper: site.newspaper
        })
    },
    e24: {
        name: 'E24',
        url: 'https://e24.no/',
        newspaper: 'E24',
        selector: 'a._teaser_bizto_1',
        extract: (el, site) => {
            const headlineEl = el.find('h3._mainTitle_qsmm2_16').clone();
            headlineEl.find('style').remove();
            const headline = headlineEl.text().trim();
            const href = el.attr('href');
            if (headline && href) {
                return { headline, link: new URL(href, site.url).href, source: site.name, newspaper: site.newspaper };
            }
            return null;
        }
    },
    nordic_capital: {
        name: 'Nordic Capital',
        url: 'https://www.nordiccapital.com/news-views/',
        newspaper: 'Nordic Capital',
        selector: 'article.masonry-card--component a',
        extract: (el, site) => {
            const headline = el.find('h3').text().trim();
            const href = el.attr('href');
            if (headline && href) {
                return {
                    headline,
                    link: new URL(href, site.url).href,
                    source: site.name,
                    newspaper: site.newspaper
                };
            }
            return null;
        }
    },
    // --- PRIVATE EQUITY FIRMS ---
    eqt: {
        name: 'EQT',
        url: 'https://eqtgroup.com/news',
        newspaper: 'EQT',
    },
    fsn_capital: {
        name: 'FSN Capital',
        url: 'https://fsncapital.com/en/news/',
        newspaper: 'FSN Capital',
        selector: 'div.newsitem',
        extract: (el, site) => {
            const linkEl = el.find('h4.title a');
            return {
                headline: linkEl.text().trim(),
                link: linkEl.attr('href'),
                source: site.name,
                newspaper: site.newspaper,
            }
        },
    },
    altor: {
        name: 'Altor',
        url: 'https://www.altor.com/news/',
        newspaper: 'Altor',
        selector: 'a.g-content-card.g-news__item',
        extract: (el, site) => ({
            headline: el.find('p.g-content-card__header').text().trim(),
            link: new URL(el.attr('href'), site.url).href,
            source: site.name,
            newspaper: site.newspaper,
        }),
    },
    verdane: {
        name: 'Verdane',
        url: 'https://verdane.com/portfolio/',
        newspaper: 'Verdane',
        selector: 'li.wp-block-post.portfolio',
        extract: (el, site) => {
            const linkEl = el.find('a.wp-block-klingit-the-product-block-link');
            const companyName = linkEl.find('h3.wp-block-post-title').text().trim();
            if (companyName) {
                return {
                    headline: `Verdane invests in ${companyName}`,
                    link: linkEl.attr('href'),
                    source: site.name,
                    newspaper: site.newspaper,
                };
            }
            return null;
        },
    },
};

export const TEXT_SELECTORS = {
  'Berlingske': '.article-body p',
  'BÃ¸rsen': '.article-content',
  'Politiken': 'section#js-article-body .font-serif-body-20 p',
  'Finans.dk': 'p.container-text:not([class*="italic"])',
  'DN.no': '.dn-article-top .lead, .dn-content .dn-text p',
  'Axcel': 'div.article-content p',
  'Polaris': 'div.fl-module-fl-post-content p',
  'Finansavisen': '.c-article-regular__body__preamble, .c-article-regular__body p',
  'Kapital': '.c-article-regular__body__preamble, .c-article-regular__body p',
  'E24': 'article p[data-test-tag="lead-text"], article p.hyperion-css-1lemvax',
  'Nordic Capital': '.multi-column-rich-text--content-block .block-content p',
  'EQT': '.body-l-body-m p', 
  'FSN Capital': 'div.newspage__content p',
  'Altor': 'div.g-wysiwyg p',
  'Verdane': '.entry-content p',
};

# File: src/database.js
// src/database.js (version 1.0)
import mongoose from 'mongoose';
import { MONGO_URI } from './config/index.js';
import { logger } from './utils/logger.js';

export async function connectDatabase() {
    if (!MONGO_URI) {
        logger.fatal('MONGO_URI is not defined in environment variables. Exiting.');
        process.exit(1);
    }

    try {
        logger.info('Attempting to connect to MongoDB...');
        await mongoose.connect(MONGO_URI, {
            serverSelectionTimeoutMS: 5000,
        });
        logger.info('âœ… MongoDB connection successful.');
    } catch (error) {
        logger.fatal({ err: error }, 'âŒ CRITICAL: Failed to establish MongoDB connection.');
        process.exit(1);
    }
}

export async function disconnectDatabase() {
    try {
        await mongoose.disconnect();
        logger.info('MongoDB connection closed.');
    } catch (error) {
        logger.error({ err: error }, 'Error disconnecting from MongoDB.');
    }
}

# File: src/modules/ai/eventProcessing.js
// src/modules/ai/eventProcessing.js
import OpenAI from 'openai';
import { KIMI_API_KEY, LLM_MODEL_ARTICLES, CONCURRENCY_LIMIT } from '../../config/index.js';
import { logger } from '../../utils/logger.js';
import { instructionCluster } from '../assessments/instructionCluster.js';
import { instructionSynthesize } from '../assessments/instructionSynthesize.js';
import { safeExecute } from '../../utils/helpers.js';

const kimi = new OpenAI({
    apiKey: 'dummy-key',
    baseURL: 'https://api.moonshot.ai/v1',
    defaultHeaders: { 'Authorization': `Bearer ${KIMI_API_KEY}` },
    timeout: 120 * 1000,
    maxRetries: 3, // Changed from 1 to 3 for more robustness
});

async function generateJsonResponse(model, instructions, userContent, temperature = 0.1) {
    const messages = [
        { role: 'system', content: JSON.stringify(instructions) },
        { role: 'user', content: userContent },
    ];

    const result = await safeExecute(() => kimi.chat.completions.create({
        model,
        messages,
        response_format: { type: "json_object" },
        temperature,
    }));

    if (!result) return { error: 'API call failed' };

    try {
        return JSON.parse(result.choices[0].message.content);
    } catch (parseError) {
        logger.error({ err: parseError, content: result.choices[0].message.content }, "JSON Parsing Error in AI response");
        return { error: "JSON Parsing Error" };
    }
}

export async function clusterArticlesIntoEvents(articles) {
    logger.info(`Clustering ${articles.length} articles into unique events...`);
    const articlePayload = articles.map(a => ({
        id: a._id.toString(),
        headline: a.headline,
        source: a.newspaper,
        summary: (a.articleContent?.contents || []).join(' ').substring(0, 400),
    }));

    const userContent = JSON.stringify(articlePayload);
    const response = await generateJsonResponse(LLM_MODEL_ARTICLES, instructionCluster, userContent);

    if (response.error || !response.events) {
        logger.error('Failed to cluster articles.', { response });
        return [];
    }

    return response.events; // Expected format: [{ event_key: "...", article_ids: ["...", "..."] }]
}


export async function synthesizeEvent(articlesInCluster, historicalContext) {
    logger.info(`Synthesizing event for cluster with ${articlesInCluster.length} articles.`);

    const todayPayload = articlesInCluster.map(a => ({
        headline: a.headline,
        source: a.newspaper,
        full_text: (a.articleContent?.contents || []).join('\n'),
    }));

    const historyPayload = historicalContext.map(h => ({
        headline: h.headline,
        source: h.newspaper,
        published: h.createdAt,
        summary: (h.articleContent?.contents || []).join(' ').substring(0, 500),
    }));

    const userContent = JSON.stringify({
        todays_articles: todayPayload,
        historical_articles: historyPayload,
    });

    const response = await generateJsonResponse(LLM_MODEL_ARTICLES, instructionSynthesize, userContent, 0.2);

    if (response.error) {
        logger.error('Failed to synthesize event.', { response });
        return { error: 'Synthesis failed' };
    }
    
    // Expected format: { headline: "...", summary: "...", key_individuals: [...] }
    return response;
}

# File: src/modules/ai/index.js
// src/modules/ai/index.js
import OpenAI from 'openai';
import pLimit from 'p-limit';
import { KIMI_API_KEY, LLM_MODEL_TRIAGE, LLM_MODEL_ARTICLES, AI_BATCH_SIZE, CONCURRENCY_LIMIT, HEADLINES_RELEVANCE_THRESHOLD } from '../../config/index.js';
import { logger } from '../../utils/logger.js';
import { instructionHeadlines } from '../assessments/instructionHeadlines.js';
import { shotsInput as shotsInputHeadlines, shotsOutput as shotsOutputHeadlines } from '../assessments/shotsHeadlines.js';
import { instructionArticle } from '../assessments/instructionArticle.js';
import { shotsInput as shotsInputArticle, shotsOutput as shotsOutputArticle } from '../assessments/shotsArticle.js';
import { safeExecute, truncateString } from '../../utils/helpers.js';

if (!KIMI_API_KEY) {
    throw new Error('KIMI_API_KEY is not defined in the environment variables.');
}

const kimi = new OpenAI({
    apiKey: 'dummy-key',
    baseURL: 'https://api.moonshot.ai/v1',
    defaultHeaders: { 'Authorization': `Bearer ${KIMI_API_KEY}` },
    timeout: 90 * 1000,
    maxRetries: 3,
});

const limit = pLimit(CONCURRENCY_LIMIT);
let isApiKeyInvalid = false;

// --- UNCHANGED FUNCTIONS ---
export async function performKimiSanityCheck() {
    try {
        logger.info('ðŸ”¬ Performing Kimi AI service sanity check...');
        const response = await kimi.chat.completions.create({
            model: "moonshot-v1-8k", messages: [{ role: 'user', content: 'What is in one word the name of the capital of France' }], temperature: 0,
        }, { timeout: 20 * 1000 });
        const answer = response.choices[0].message.content.trim().toLowerCase();
        if (answer.includes('paris')) { return true; }
        else {
            logger.fatal(`Kimi sanity check failed. Expected a response containing "Paris", but got: "${answer}".`);
            return false;
        }
    } catch (error) {
        if (error.status === 401) {
            let keyHint = 'The key is either missing, empty, or too short to be valid.';
            if (KIMI_API_KEY && KIMI_API_KEY.length > 8) {
                const maskedKey = `${KIMI_API_KEY.substring(0, 5)}...${KIMI_API_KEY.slice(-4)}`;
                keyHint = `Key being used: ${maskedKey}`;
            }
            logger.fatal(`Kimi sanity check failed due to INVALID API KEY (401). ${keyHint}. Please verify your .env file and the baseURL.`);
        } else {
            logger.fatal({ err: error }, 'Kimi sanity check failed with an unexpected API error.');
        }
        isApiKeyInvalid = true;
        return false;
    }
}

export async function checkModelPermissions(requiredModels) {
    logger.info('ðŸ”¬ Verifying permissions for configured Kimi models...');
    try {
        const response = await kimi.models.list();
        const availableModels = new Set(response.data.map(model => model.id));
        for (const model of requiredModels) {
            if (!availableModels.has(model)) {
                logger.fatal(`Model validation failed. The configured model "${model}" is not available or you don't have permission. Please check your .env file.`);
                logger.info({ availableModels: [...availableModels] }, 'Available models for your API key:');
                return false;
            }
        }
        return true;
    } catch (error) {
        logger.fatal({ err: error }, 'Failed to retrieve model list from Kimi API.');
        isApiKeyInvalid = true;
        return false;
    }
}

async function generateAssessment(model, instructions, userContent, fewShotInputs = [], fewShotOutputs = []) {
    if (isApiKeyInvalid) { return { error: 'API Key is invalid. Halting further AI assessments.' }; }
    const messages = [ { role: 'system', content: JSON.stringify(instructions) } ];
    fewShotInputs.forEach((input, i) => {
        let shotContent = (typeof input === 'string') ? input : (input && input.articleText);
        if (shotContent && typeof shotContent === 'string') {
            messages.push({ role: 'user', content: shotContent });
            messages.push({ role: 'assistant', content: fewShotOutputs[i] });
        }
    });
    messages.push({ role: 'user', content: userContent });
    const apiCallPromise = safeExecute(() => kimi.chat.completions.create({
        model, messages, response_format: { type: "json_object" }, temperature: 0.1,
    }), {
        errorHandler: (err) => {
            if (err.status === 401) {
                isApiKeyInvalid = true;
                logger.fatal('KIMI API KEY IS INVALID. Halting all AI requests.');
                return { error: 'Invalid Kimi API Key' };
            }
            logger.error(`Kimi API Error: ${err.name} - ${err.message}`);
            return { error: `Kimi API Error: ${err.message}` };
        }
    });
    let timeoutHandle;
    const timeoutPromise = new Promise((resolve) => {
        timeoutHandle = setTimeout(() => resolve({ error: 'External watchdog timed out after 100s' }), 100 * 1000);
    });
    const result = await Promise.race([apiCallPromise, timeoutPromise]);
    clearTimeout(timeoutHandle);
    if (result.error) return result;
    try {
        return JSON.parse(result.choices[0].message.content);
    } catch (parseError) {
        logger.error(`JSON Parse Error: ${parseError.message}`);
        return { error: "JSON Parsing Error" };
    }
}

// --- REFACTORED BATCH ASSESSMENT LOGGING ---
export async function assessHeadlinesInBatches(articles) {
    const batches = [];
    for (let i = 0; i < articles.length; i += AI_BATCH_SIZE) {
        batches.push(articles.slice(i, i + AI_BATCH_SIZE));
    }
    logger.info(`Assessing ${articles.length} headlines in ${batches.length} batches.`);
    const allAssessedPromises = [];
    let completedBatches = 0;

    for (const batch of batches) {
        allAssessedPromises.push(
            limit(async () => {
                const headlinesText = batch.map(a => a.headline).join('\n- ');
                const response = await generateAssessment(LLM_MODEL_TRIAGE, instructionHeadlines, headlinesText, shotsInputHeadlines, shotsOutputHeadlines);
                
                completedBatches++;
                
                // --- NEW CONCISE LOGGING ---
                if (response && response.assessment && Array.isArray(response.assessment)) {
                    logger.info(`--- Batch ${completedBatches}/${batches.length} Results ---`);
                    batch.forEach((article, i) => {
                        const assessment = response.assessment[i];
                        if (assessment && typeof assessment.relevance_headline === 'number') {
                            const score = assessment.relevance_headline;
                            const comment = assessment.assessment_headline || 'No comment.';
                            const emoji = score >= HEADLINES_RELEVANCE_THRESHOLD ? 'âœ…' : 'âŒ';
                            logger.info(`${emoji} [${score}] ${truncateString(article.headline, 70)} | ${truncateString(comment, 60)}`);
                        } else {
                            logger.warn(`- Malformed assessment for: ${truncateString(article.headline, 70)}`);
                        }
                    });
                } else {
                    logger.error(`âŒ Headline assessment failed for batch ${completedBatches}/${batches.length}. Reason: ${response.error || 'Malformed response'}`);
                }
                // --- END NEW LOGGING ---

                if (response.error || !response.assessment || !Array.isArray(response.assessment) || response.assessment.length !== batch.length) {
                    return batch.map(article => ({ ...article, relevance_headline: 0, assessment_headline: response.error || 'AI assessment failed.' }));
                }

                return batch.map((article, i) => ({ ...article, ...response.assessment[i] }));
            })
        );
    }
    
    const assessedBatches = await Promise.all(allAssessedPromises);
    logger.info(`Finished assessing all ${batches.length} batches.`);
    return assessedBatches.flat();
}

export async function assessArticleContent(article) {
    logger.info(`Assessing content for: "${truncateString(article.headline, 60)}"`);
    const articleText = article.articleContent.contents.join('\n');
    const response = await generateAssessment(LLM_MODEL_ARTICLES, instructionArticle, articleText, shotsInputArticle, shotsOutputArticle);
    if (response.error) {
        logger.error(`Article assessment failed for ${article.link}.`);
        return { ...article, error: `AI Error: ${response.error}` };
    }
    return { ...article, ...response, error: null };
}

# File: src/modules/ai/rag.js
// src/modules/ai/rag.js
import Article from '../../../models/Article.js';
import { logger } from '../../utils/logger.js';
import { generateEmbedding, cosineSimilarity } from '../../utils/vectorUtils.js';

const SIMILARITY_THRESHOLD = 0.65; // Tune this threshold as needed
const MAX_CONTEXT_ARTICLES = 3;

/**
 * Finds historical articles similar to a given set of new articles.
 * @param {Array<Object>} articlesInCluster - The new articles forming an event.
 * @returns {Promise<Array<Object>>} A promise that resolves to an array of relevant historical articles.
 */
export async function findSimilarArticles(articlesInCluster) {
    logger.info('RAG: Searching for historical context...');
    if (!articlesInCluster || articlesInCluster.length === 0) return [];

    // 1. Create a query embedding from the new event's content
    const queryText = articlesInCluster.map(a => a.headline).join('\n');
    const queryEmbedding = await generateEmbedding(queryText);

    // 2. Fetch all historical articles with embeddings from the database
    // In a large-scale app, you'd add filters (e.g., date range) here.
    const historicalCandidates = await Article.find({
        embedding: { $exists: true, $ne: null }
    }).lean();

    if (historicalCandidates.length === 0) {
        logger.warn('RAG: No historical articles with embeddings found to search against.');
        return [];
    }

    // 3. Calculate similarity for each candidate
    const scoredArticles = [];
    for (const candidate of historicalCandidates) {
        const similarity = cosineSimilarity(queryEmbedding, candidate.embedding);
        if (similarity >= SIMILARITY_THRESHOLD) {
            scoredArticles.push({ ...candidate, similarity });
        }
    }
    
    // 4. Sort by similarity and return the top N
    scoredArticles.sort((a, b) => b.similarity - a.similarity);
    const topContext = scoredArticles.slice(0, MAX_CONTEXT_ARTICLES);
    
    logger.info(`RAG: Found ${topContext.length} relevant historical articles.`);
    return topContext;
}

# File: src/modules/assessments/instructionArticle.js
// src/modules/assessments/instructionArticle.js
export const instructionArticle = {
  whoYouAre: 'You are a senior Scandinavian wealth management analyst. Your goal is to qualify leads for an investment bank by analyzing full-text articles.',
  whatYouDo: 'You determine if an article describes a significant wealth event for a PRIVATE Scandinavian individual, family, or their direct holding company. You also flag any major event concerning a top-tier Rich List family.',

  guidelines: `
    **Primary Focus (High Score):**
    - Direct, substantial wealth-generating events (company sales, IPOs, M&A, large dividends) benefiting named private Scandinavian individuals/families, valued over $30M.

    **Secondary Focus (Medium Score - Rich List Proximity):**
    - **VITAL RULE:** Any significant strategic or financial news related to a top-tier Danish/Nordic Rich List family (e.g., the family behind **USTC**, Kirk Kristiansen, Holch Povlsen). This includes large investments, divestments, legal battles over significant assets, or major strategic shifts in their core family-owned businesses. The event itself might be a cost (like a fine) or an investment, but its scale and relation to the family's wealth make it a crucial intelligence point.

    **Strictly Exclude:**
    - News primarily about foreign multinational corporations (e.g., Stellantis) that do not directly involve a sale *from* a private Scandinavian owner.
    - Articles about financial losses, tariffs, or market challenges for public or foreign companies.
    - General market analysis, corporate performance reports, or mergers of non-family-owned entities.
  `,

  scoring: `
    **Score 90-100:** A clear, confirmed wealth-generating event for a private Scandinavian family.
    
    **Score 51-89:**
    - A strongly implied but not fully detailed wealth-generating event.
    - An event that falls under the **"Rich List Proximity"** rule. For these, the assessment must state: "High relevance due to the involvement of a Rich List family in a significant financial event."

    **Score 0-50:** Irrelevant news, including anything from the 'Strictly Exclude' list.
  `,
  
  outputFormatDescription: 'Respond only with a valid JSON object. For each key individual, you MUST attempt to provide an email suggestion. The JSON structure is: { "topic": "...", "relevance_article": 95, "assessment_article": "...", "amount": 500, "key_individuals": [{"name": "Name", "role_in_event": "Founder", "company": "Company Name", "email_suggestion": "name@company.com"}], "background": "..." }',

  reiteration: 'Your entire response must be a single, valid JSON object. Your analysis must strictly adhere to the focus on PRIVATE SCANDINAVIAN wealth and the special rules for Rich List families.'
};

# File: src/modules/assessments/instructionCluster.js
// src/modules/assessments/instructionCluster.js

export const instructionCluster = {
  whoYouAre: "You are a news clustering analyst. Your goal is to identify which news articles are reporting on the exact same real-world event.",
  whatYouDo: "You will receive a JSON array of articles, each with an ID, headline, and summary. You must group articles that describe the same underlying event (e.g., the same company sale, the same IPO, the same investment).",
  guidelines: `
    1.  **Analyze Content:** Read the headline and summary of each article to understand the core event it describes.
    2.  **Group by Event:** If two or more articles are about the same event (e.g., 'Visma buys InnovateAI'), they belong in the same group. Articles about different events (e.g., 'Polaris invests in NewCo', 'Axcel sells OldCo') belong in separate groups.
    3.  **Create a Unique Event Key:** For each unique event group, create a short, descriptive, lowercase key. The key should include the main entities and the action, plus today's date in YYYY-MM-DD format. Example: \`acquisition-visma-innovateai-2024-05-20\`.
    4.  **Handle Singletons:** If an article describes an event that no other article covers, it forms its own group of one.
    5.  **Be Conservative:** If you are not highly confident that two articles describe the exact same event, place them in separate groups. It is better to have two small groups than to incorrectly merge two distinct events.
  `,
  outputFormatDescription: `
    Respond ONLY with a valid JSON object with a single top-level key "events".
    The value of "events" should be an array of objects.
    Each object in the array represents one unique event and must have two keys:
    - "event_key": The unique, descriptive key you created (e.g., "acquisition-visma-innovateai-2024-05-20").
    - "article_ids": An array of strings, where each string is the ID of an article belonging to this event.

    Example Response:
    {
      "events": [
        {
          "event_key": "acquisition-visma-innovateai-2024-05-20",
          "article_ids": ["60d21b4667d0d8992e610c85", "60d21b4667d0d8992e610c88"]
        },
        {
          "event_key": "investment-polaris-newco-2024-05-20",
          "article_ids": ["60d21b4667d0d8992e610c91"]
        }
      ]
    }
  `,
  reiteration: "Your entire response must be a single, valid JSON object as described. Do not include any other text, explanations, or markdown formatting."
};

# File: src/modules/assessments/instructionHeadlines.js
// src/modules/assessments/instructionHeadlines.js
export const instructionHeadlines = {
  whoYouAre: 'You are a Scandinavian wealth management analyst. Your goal is to identify news headlines that could lead to new business for an investment bank.',
  whatYouDo: 'You assess if headlines indicate a significant wealth event for a PRIVATE Scandinavian individual, family, or their direct holding company. Your focus is on "new family money."',
  
  guidelines: `
    **Include ONLY:**
    - Major liquidity events for private Scandinavian individuals/families (company sales, founder-led IPOs, large asset sales) valued over $30M.
    - Significant dividend payments from private/family-owned holding companies directly to the family.
    - Obituaries of ultra-high-net-worth Scandinavian individuals.

    **Strictly EXCLUDE:**
    - News about large, publicly traded, or foreign multinational corporations (e.g., Stellantis, Boeing, Maersk as a public entity) unless the story is about a founding family's direct liquidity event.
    - General market analysis, stock performance, or corporate earnings reports.
    - Financial losses, fines, or tariff impacts, UNLESS it involves a Rich List family (see VITAL RULE).
    - Mergers of publicly listed banks or non-family-owned cooperatives.
  `,

  scoring: `
    **Score 90-100 (High Relevance):** Clear, direct wealth-generating event for a named private Scandinavian family/individual (e.g., "Family sells tech firm for $100M").
    
    **Score 50-89 (Medium Relevance / Rich List Proximity):**
    - Strongly implied but not explicitly valued wealth events.
    - **VITAL RULE:** Any significant news (positive or negative, e.g., legal disputes, major investments, fines) involving a top-tier Danish/Nordic Rich List family (e.g., the family behind **USTC**, Kirk Kristiansen, Holch Povlsen). The event itself may not be a gain, but the family's involvement makes it relevant to their wealth management. The assessment should state "Relevant due to Rich List family involvement."
    
    **Score 20-49 (Low Relevance):** Minor or speculative wealth events.
    
    **Score 0-19 (No Relevance):** Anything in the 'Strictly EXCLUDE' list.
  `,

  vitals: 'Any mention of "Goldman Sachs" or "Morgan Stanley" in the context of a private Scandinavian deal is an automatic 100. Always apply the Rich List Proximity rule for families like the owners of USTC.',
  
  outputFormatDescription: `
    Respond in English with a valid JSON object, exactly formatted like below.
    Like shown here, it is vital that your response has a top-level "assessment" key:
    {
      "assessment": [
        {
          "relevance_headline": 95,
          "assessment_headline": "Imminent personal wealth generation due to company sale."
        }
      ]
    }
    NEVER RETURN A PLAIN ARRAY.
  `,
};

# File: src/modules/assessments/instructionSynthesize.js
// src/modules/assessments/instructionSynthesize.js

export const instructionSynthesize = {
  whoYouAre: "You are an expert financial journalist working for an exclusive executive briefing service.",
  whatYouDo: "You will receive JSON data containing one or more articles about today's news event, and potentially some historical articles for context. Your task is to synthesize this information into a concise, high-value intelligence brief.",
  writingStyle: "Factual, dense, and objective, in the style of the Wall Street Journal or Financial Times. Use clear, professional English. Omit filler words and speculation.",
  guidelines: `
    1.  **Prioritize Today's News:** Your summary must be based on the information provided in the \`todays_articles\` array. This is the core of the brief.
    2.  **Use Historical Context:** If \`historical_articles\` are provided, use them to add depth and background to the summary. For example, if today's news is an acquisition, a historical article about the company's last funding round is crucial context. Mention this context briefly (e.g., 'This follows a funding round last year...').
    3.  **Create a New Headline:** Write a new, overarching headline for the event. It should be clear, concise, and capture the essence of the news.
    4.  **Write a Concise Summary:** Write a new summary of the event. **The summary must be no more than 4 sentences and under 90 words.** It should seamlessly integrate the key facts from today's news with any relevant historical context.
    5.  **Identify and Merge Key Individuals:**
        *   From the text and provided data, identify the key individuals involved (founders, sellers, buyers, etc.).
        *   Create a single, de-duplicated list of these individuals.
        *   For each individual, you must include their name, role, company, and any \`email_suggestion\` found in the source data. If multiple suggestions exist for one person, pick the most plausible one.
  `,
  outputFormatDescription: `
    Respond ONLY with a valid JSON object with the following structure:
    {
      "headline": "New, synthesized headline here.",
      "summary": "New, synthesized summary here. It must be under 90 words and no more than 4 sentences.",
      "key_individuals": [
        {
          "name": "Full Name",
          "role_in_event": "e.g., Founder & Seller",
          "company": "Company Name",
          "email_suggestion": "name.surname@company.com"
        }
      ]
    }
  `,
  reiteration: "Your entire response must be a single, valid JSON object. Adhere strictly to the length and sentence constraints for the summary. The quality of the brief is paramount."
};

# File: src/modules/assessments/shotsArticle.js
// src/modules/assessments/shotsArticle.js

export const shotsInput = [
  { articleText: 'Nyt anlÃ¦g ved Esbjerg skal producere klimavenlig brint. DirektÃ¸r Jens Hansen udtaler...' },
  { articleText: 'Aarstiderne, stiftet af SÃ¸ren Ejlersen, er blevet solgt til en international fÃ¸devaregigant for et trecifret millionbelÃ¸b.' },
  { articleText: 'Many homeowners will see lower property taxes in 2025 and 2026' },
  { articleText: 'The MÃ¸ller family has sold their shipping software company, NaviTech, for $500M.' },
  { articleText: 'Stellantis, the multinational car company, has reported that it stands to lose over 300 million kroner due to new US tariffs.' }, // NEW NEGATIVE EXAMPLE
  { articleText: 'The family-owned conglomerate USTC, owned by the Ã˜stergaard-Nielsen family, is disputing a multimillion-krone claim from the Nordic Waste bankruptcy trustee.' }, // NEW RICH LIST PROXIMITY EXAMPLE
  { articleText: 'CEO of family-owned Scandinavian tech firm, Anna Schmidt, sells for $120M' },
  { articleText: 'The Grundfos holding company, owned by the Due Jensen family, has announced a dividend of 300 million kroner to be distributed among family members.' },
  { articleText: 'Rockwool plans massive global expansions' },
];

export const shotsOutput = [
  // REFINED: Updated to new JSON structure
  JSON.stringify({
    topic: 'Green hydrogen plant in Esbjerg',
    relevance_article: 10,
    assessment_article: 'Infrastructure project with no direct personal wealth transfer.',
    amount: 0,
    key_individuals: [],
    background: 'Public or corporate energy initiative.',
  }),
  // REFINED: Updated to new JSON structure with email inference
  JSON.stringify({
    topic: 'Sale of Aarstiderne',
    relevance_article: 95,
    assessment_article: 'Clear private wealth event for Scandinavian founder.',
    amount: 150, // Assuming DKK millions -> USD
    key_individuals: [{
      "name": "SÃ¸ren Ejlersen",
      "role_in_event": "Founder & Seller",
      "company": "Aarstiderne",
      "email_suggestion": "soren.ejlersen@aarstiderne.com"
    }],
    background: 'Sale of private Scandinavian company.',
  }),
  // REFINED: Updated to new JSON structure
  JSON.stringify({
    topic: 'Property tax cuts for homeowners',
    relevance_article: 15,
    assessment_article: 'General tax relief is not a substantial direct wealth event.',
    amount: 0,
    key_individuals: [],
    background: 'Policy affecting many, not enriching individuals.',
  }),
  // REFINED: Updated to new JSON structure with email inference
  JSON.stringify({
    topic: 'Sale of NaviTech',
    relevance_article: 100,
    assessment_article: 'Substantial wealth event clearly benefiting a Scandinavian family.',
    amount: 500,
    key_individuals: [{
      "name": "MÃ¸ller family",
      "role_in_event": "Seller",
      "company": "NaviTech",
      "email_suggestion": "contact@navitech.com"
    }],
    background: 'Private business transaction.',
  }),
  // NEW: Output for the Stellantis negative example
  JSON.stringify({
    topic: 'Tariff losses for Stellantis',
    relevance_article: 5,
    assessment_article: 'Irrelevant. Article describes financial losses for a foreign multinational corporation.',
    amount: -300,
    key_individuals: [],
    background: 'General automotive industry news.',
  }),
  // NEW: Output for the USTC Rich List Proximity example
  JSON.stringify({
    topic: 'USTC legal dispute over Nordic Waste claim',
    relevance_article: 60,
    assessment_article: 'High relevance due to the involvement of a Rich List family (Ã˜stergaard-Nielsen/USTC) in a significant financial event.',
    amount: 0,
    key_individuals: [{
        "name": "Ã˜stergaard-Nielsen family",
        "role_in_event": "Owner",
        "company": "USTC",
        "email_suggestion": "contact@ustc.dk"
    }],
    background: 'Ongoing legal and financial issue for a major family holding company.',
  }),
  // REFINED: Updated to new JSON structure with email inference
  JSON.stringify({
    topic: 'Sale of Scandinavian tech firm',
    relevance_article: 95,
    assessment_article: 'Substantial wealth event for private Scandinavian individual.',
    amount: 120,
    key_individuals: [{
      "name": "Anna Schmidt",
      "role_in_event": "CEO & Seller",
      "company": "Unknown Tech Firm",
      "email_suggestion": null
    }],
    background: 'Private tech company acquisition.',
  }),
  // REFINED: Updated to new JSON structure
  JSON.stringify({
    topic: 'Grundfos family dividend',
    relevance_article: 95,
    assessment_article: 'Direct and substantial wealth transfer to a private Scandinavian family.',
    amount: 45, // 300M DKK -> USD
    key_individuals: [{
        "name": "Due Jensen family",
        "role_in_event": "Recipient",
        "company": "Grundfos",
        "email_suggestion": null
    }],
    background: 'Dividend from a family-owned holding company.',
  }),
  // REFINED: Updated to new JSON structure
  JSON.stringify({
    topic: 'Rockwool global expansion',
    relevance_article: 10,
    assessment_article: 'Corporate strategy of a public company, no individual wealth generation.',
    amount: 0,
    key_individuals: [],
    background: 'Public company operations.',
  }),
];

# File: src/modules/assessments/shotsHeadlines.js
// src/modules/assessments/shotsHeadlines.js
export const shotsInput = [
  // --- This set is unchanged but assessments are refined for consistency ---
  [
    'Rockwool stÃ¥r foran massive udvidelser over hele kloden',
    'Boeing henter 145 mia. kr.',
    'Boligejere med for stor grundskyldsregning har udsigt til hjÃ¦lp',
    'Kriseramte Boeing vil rejse milliarder for at tilbagebetale gÃ¦ld',
    'Aarstiderne solgt til gigant',
    'Scandinavian family sells company for $500M',
  ].join('\n- '),

  // --- This set is unchanged but assessments are refined for consistency ---
  [
    'Local football match results',
    'New Scandinavian tech startup launched',
    'Vestas CEO buys shares',
    'Vestas CEO sells significant shares',
    'Maersk heir sells estate in Copenhagen',
    'Scandinavian lottery winner claims prize',
  ].join('\n- '),

  // --- This set is unchanged but assessments are refined for consistency ---
  [
    'A.P. Moller Foundation donates $100 million to charity',
    'LEGO family (KIRKBI A/S) in acquisition talks for rival toy company for DKK 5 billion',
    'Danfoss heir (Bitten & Mads Clausen Foundation) announces succession plan for family business leadership',
    'Widex and Demant plan to merge operations',
    'Novo Nordisk (public company) announces stock split',
    '3Shape (privately owned) is working on an IPO',
  ].join('\n- '),

  // --- NEW: This set explicitly teaches the rules from your feedback ---
  [
    'NÃ¥|SpÃ¥r milliard-smell fra toll', // Stellantis example
    'Familieejet koncern bestrider millionkrav efter Nordic Waste', // USTC example
    'Fynske bankers fusionsplaner skydes ned af storaktionÃ¦r' // Public bank merger
  ].join('\n- '),

  // --- This set is refined to better teach Rich List Proximity ---
  [
    'Grundfos owner (Poul Due Jensen Foundation) announces DKK 300 million dividend distribution to family members',
    'Bestseller owner Anders Holch Povlsen personally acquires Scottish estate for DKK 150 million',
    "Martin Thorborg's AI Startup Secures Funding",
    'Martin Thorborg giver et foredrag om ivÃ¦rksÃ¦tteri' // Example of non-relevant Rich List news
  ].join('\n- '),
];

export const shotsOutput = [
  JSON.stringify({
    assessment: [
      {
        relevance_headline: 10,
        assessment_headline:
          'Corporate expansion (Rockwool is public), no direct private wealth generation for Scandinavian individuals.',
      },
      {
        relevance_headline: 0,
        assessment_headline:
          'Foreign corporate activity, no relevance to Scandinavian private wealth.',
      },
      {
        relevance_headline: 15, // Refined score
        assessment_headline:
          'Tax relief provides benefit, but not a substantial direct wealth transfer.',
      },
      {
        relevance_headline: 0,
        assessment_headline:
          'Foreign corporate debt repayment, no relevance to Scandinavian private wealth.',
      },
      {
        relevance_headline: 95,
        assessment_headline:
          'Acquisition likely results in substantial wealth for Scandinavian founders/owners.',
      },
      {
        relevance_headline: 100,
        assessment_headline:
          'Clear substantial private wealth event for Scandinavian family.',
      },
    ],
  }),
  JSON.stringify({
    assessment: [
      { relevance_headline: 0, assessment_headline: 'Not a wealth event.' },
      {
        relevance_headline: 10,
        assessment_headline:
          'New company, no immediate substantial wealth transfer.',
      },
      {
        relevance_headline: 5,
        assessment_headline:
          'Public market activity by an individual, not a substantial private wealth generation event.',
      },
      {
        relevance_headline: 30,
        assessment_headline:
          'Share sale by individual, possibly some personal gain, but unlikely to be a major liquidity event based on headline alone.',
      },
      {
        relevance_headline: 95,
        assessment_headline:
          "Clear wealth event (>$30M implied by 'Maersk heir' and 'estate in Copenhagen') benefiting Scandinavian private individual.",
      },
      {
        relevance_headline: 40, // Refined score
        assessment_headline:
          'Private wealth event, but likely below significance threshold.',
      },
    ],
  }),
  JSON.stringify({
    assessment: [
      {
        relevance_headline: 0,
        assessment_headline:
          'Foundation donation, no personal private wealth involved for the family.',
      },
      {
        relevance_headline: 95,
        assessment_headline:
          "Significant acquisition by rich list family's holding company (KIRKBI A/S), likely impacting family's ultimate wealth substantially.",
      },
      {
        relevance_headline: 30,
        assessment_headline:
          'Succession planning in a family business suggests future wealth considerations, not an immediate substantial wealth event for individuals.',
      },
      {
        relevance_headline: 70,
        assessment_headline:
          'Merger of two significant Scandinavian-founded companies, potential for substantial wealth implications for any remaining private owners.',
      },
      {
        relevance_headline: 0,
        assessment_headline:
          'Public market action by a public company, no personal private wealth transfer.',
      },
      {
        relevance_headline: 80,
        assessment_headline:
          'Potential substantial private wealth event if IPO proceeds benefit Scandinavian founders/owners significantly.',
      },
    ],
  }),
  // --- NEW: Output for the new example set ---
  JSON.stringify({
    assessment: [
        {
            relevance_headline: 5,
            assessment_headline: "Irrelevant. News about a foreign multinational (Stellantis) and financial losses due to tariffs."
        },
        {
            relevance_headline: 60,
            assessment_headline: "Relevant due to Rich List family involvement (USTC owners) in a significant legal/financial dispute."
        },
        {
            relevance_headline: 10,
            assessment_headline: "Irrelevant. Merger of publicly-listed, non-family-owned banks."
        }
    ]
  }),
  // --- REFINED: Output for the Rich List Proximity set ---
  JSON.stringify({
    assessment: [
      {
        relevance_headline: 95,
        assessment_headline:
          'Clear substantial private wealth event for the Scandinavian Due Jensen family via distribution from their foundation.',
      },
      {
        relevance_headline: 90,
        assessment_headline:
          'Substantial personal acquisition by Scandinavian rich list individual Anders Holch Povlsen, a clear private wealth event.',
      },
      {
        relevance_headline: 85,
        assessment_headline:
          'High relevance. A new venture by a known Rich List individual (Martin Thorborg) securing funding is a significant potential wealth event.',
      },
      {
        relevance_headline: 0,
        assessment_headline: "Irrelevant. Rich List individual's public appearance is not a wealth event."
      }
    ],
  }),
];

# File: src/modules/email/components/articleFormatter.js
// src/modules/email/components/articleFormatter.js (version 2.0)
import { logger } from '../../../utils/logger.js';
import { truncateString } from '../../../utils/helpers.js';

function createArticleCard(article) {
    const {
        link,
        headline,
        source,
        contacts,
        summary,
        assessmentText,
        relevanceScore,
        callToActionText,
    } = article;

    const scoreColor = relevanceScore >= 80 ? '#27ae60' : relevanceScore >= 50 ? '#f39c12' : '#c0392b';

    const contactsHtml = (contacts && contacts.length > 0)
        ? `<p style="margin: 0 0 15px; font-size: 14px; color: #555;"><strong>Contacts:</strong> ${contacts.join(', ')}</p>`
        : '';

    return `
    <div style="border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 20px; padding: 20px; background-color: #ffffff; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
        <h3 style="margin-top: 0; margin-bottom: 10px; font-size: 18px; color: #333;">
            <a href="${link}" style="color: #007bff; text-decoration: none;">${headline}</a>
        </h3>
        <p style="margin: 0 0 15px; font-size: 14px; color: #777;"><strong>Source:</strong> ${source}</p>
        ${contactsHtml}
        <p style="margin: 0 0 15px; font-size: 15px; color: #555; line-height: 1.6;">${summary}</p>
        <div style="background-color: #f8f9fa; border: 1px solid #dee2e6; border-radius: 6px; padding: 15px; margin-bottom: 15px;">
            <p style="margin: 0; font-size: 14px; color: #333;">
                <strong>System Assessment:</strong> <span style="font-weight: bold; color: ${scoreColor};">[Score: ${relevanceScore}]</span> ${assessmentText}
            </p>
        </div>
        <a href="${link}" style="display: inline-block; background-color: #007bff; color: #ffffff; padding: 10px 15px; border-radius: 5px; text-decoration: none; font-weight: bold; font-size: 14px;">
            ${callToActionText}
        </a>
    </div>
    `;
}

export function formatArticleForEmail(article) {
    if (!article || typeof article !== 'object' || !article.link || !article.headline) {
        logger.warn(`formatArticleForEmail: Invalid article object provided.`, { articlePreview: article });
        return `<p style="color:red;">Error: Article data was invalid.</p>`;
    }

    const genericArticleData = {
        link: article.link,
        headline: article.headline,
        source: article.source || article.newspaper || 'N/A',
        contacts: article.contacts || [],
        summary: 'No summary available.',
        assessmentText: article.assessment_article || article.assessment_headline || 'Assessment not available.',
        relevanceScore: article.relevance_article ?? article.relevance_headline ?? 'N/A',
        callToActionText: 'Read Full Article â†’',
    };

    if (article.articleContent && typeof article.articleContent === 'object') {
        const { contents } = article.articleContent;
        if (contents && Array.isArray(contents) && contents.length > 0) {
            genericArticleData.summary = truncateString(contents.join(' '), 250);
        }
    }
    
    if (genericArticleData.summary === 'No summary available.') {
      genericArticleData.summary = truncateString(genericArticleData.assessmentText, 250);
    }

    try {
        return createArticleCard(genericArticleData);
    } catch (error) {
        logger.error(`Error creating article card for email: "${article.headline}"`, { errorMessage: error.message });
        return `<p style="color:red;">Error formatting article: ${truncateString(article.headline, 50)}</p>`;
    }
}

# File: src/modules/email/components/emailBodyBuilder.js
// src/modules/email/components/emailBodyBuilder.js
import { logger } from '../../../utils/logger.js';
import { EMAIL_CONFIG } from '../../../config/index.js';
import { LOGO_URL } from '../constants.js';
import { formatEventForEmail } from './eventFormatter.js';

function createEmailWrapper(bodyContent) {
    return `
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>${EMAIL_CONFIG.subject}</title>
    </head>
    <body style="margin: 0; padding: 0; font-family: Helvetica, Arial, sans-serif; background-color: #f4f4f4;">
        <table width="100%" border="0" cellspacing="0" cellpadding="0" style="background-color: #f4f4f4;">
            <tr>
                <td align="center">
                    <table width="600" border="0" cellspacing="0" cellpadding="20" style="max-width: 600px; width: 100%; background-color: #ffffff; margin-top: 20px; margin-bottom: 20px;">
                        <tr>
                            <td>
                                ${bodyContent}
                            </td>
                        </tr>
                    </table>
                </td>
            </tr>
        </table>
    </body>
    </html>`;
}

export function createEmailBody(events) {
    if (!Array.isArray(events) || events.length === 0) {
        logger.warn('createEmailBody: No events provided to build email body.');
        return null;
    }

    const formattedEventsHtml = events.map(formatEventForEmail).join('');

    const mainContent = `
        <div style="text-align: center; padding-bottom: 20px; border-bottom: 1px solid #eeeeee;">
            <img src="${LOGO_URL}" alt="${EMAIL_CONFIG.brandName} Logo" style="max-width: 150px; height: auto;">
        </div>
        <h1 style="color: #333333; text-align: center; margin-top: 20px;">${EMAIL_CONFIG.subject}</h1>
        <p style="font-size: 16px; color: #555555; text-align: left;">
            Good morning,
            <br><br>
            Here are the latest potential wealth events identified and synthesized by our AI Agent:
        </p>
        ${formattedEventsHtml}
        <p style="font-size: 16px; color: #555555; text-align: left;">
            Best Regards,<br>The Wealth Insight Team
        </p>
        <div style="text-align: center; margin-top: 30px; padding-top: 20px; border-top: 1px solid #eeeeee; font-size: 12px; color: #888888;">
            <p>${EMAIL_CONFIG.brandName} | ${EMAIL_CONFIG.companyAddress}</p>
            <p><a href="${EMAIL_CONFIG.unsubscribeUrl}" style="color: #888888;">Unsubscribe</a></p>
        </div>
    `;

    return createEmailWrapper(mainContent);
}

# File: src/modules/email/components/eventFormatter.js
// src/modules/email/components/eventFormatter.js
import { logger } from '../../../utils/logger.js';

function createEventBriefCard(event) {
    const {
        synthesized_headline,
        synthesized_summary,
        ai_assessment_reason, // New property
        source_articles,
        highest_relevance_score,
        key_individuals
    } = event;

    const scoreColor = highest_relevance_score >= 80 ? '#27ae60' : highest_relevance_score >= 50 ? '#f39c12' : '#c0392b';

    const contactsHtml = (key_individuals && key_individuals.length > 0)
        ? `<div style="padding:10px; background-color: #f8f9fa; border-radius: 4px; margin-bottom: 15px; font-size: 14px; color: #333;">
             <strong>Key Individuals:</strong> ${key_individuals.map(p => {
                const emailPart = p.email_suggestion ? ` (<a href="mailto:${p.email_suggestion}" style="color: #007bff; text-decoration:none;">${p.email_suggestion}</a>)` : '';
                return `${p.name} - <i>${p.role_in_event}</i>${emailPart}`;
             }).join('; ')}
           </div>`
        : '';
    
    // NEW: HTML block for the AI's reasoning
    const reasoningHtml = ai_assessment_reason 
        ? `<div style="margin-top: 15px; padding-left: 10px; border-left: 2px solid #eeeeee; font-size: 12px; color: #666666; font-style: italic;">
             <strong>AI Reasoning:</strong> ${ai_assessment_reason}
           </div>`
        : '';

    const sourcesHtml = source_articles.map(article => `
        <tr style="vertical-align: top;">
            <td style="padding: 4px 8px 4px 0; color: #555; font-weight: bold; white-space: nowrap;">${article.newspaper}:</td>
            <td style="padding: 4px 0;">
                <a href="${article.link}" style="color: #007bff; text-decoration: none; font-size: 14px;">${article.headline}</a>
            </td>
        </tr>
    `).join('');

    return `
    <div style="border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 25px; padding: 20px; background-color: #ffffff; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
        <h2 style="margin-top: 0; margin-bottom: 15px; font-size: 20px; color: #1a1a1a;">
           <span style="font-weight: bold; color: ${scoreColor};">[${highest_relevance_score}]</span> ${synthesized_headline}
        </h2>
        
        <p style="margin: 0 0 15px; font-size: 15px; color: #555; line-height: 1.6;">${synthesized_summary}</p>
        
        ${contactsHtml}

        ${reasoningHtml}

        <h4 style="margin-top: 20px; margin-bottom: 10px; font-size: 14px; color: #333; border-bottom: 1px solid #eee; padding-bottom: 5px;">Source Articles</h4>
        <table border="0" cellpadding="0" cellspacing="0" width="100%">${sourcesHtml}</table>
    </div>
    `;
}

export function formatEventForEmail(event) {
    if (!event || typeof event !== 'object' || !event.synthesized_headline) {
        logger.warn(`formatEventForEmail: Invalid event object provided.`, { eventPreview: event });
        return `<p style="color:red;">Error: Event data was invalid.</p>`;
    }

    try {
        return createEventBriefCard(event);
    } catch (error) {
        logger.error(`Error creating event card for email: "${event.synthesized_headline}"`, { errorMessage: error.message });
        return `<p style="color:red;">Error formatting event: ${event.synthesized_headline}</p>`;
    }
}

# File: src/modules/email/components/supervisorEmailBodyBuilder.js
// src/modules/email/components/supervisorEmailBodyBuilder.js
import { SUPERVISOR_EMAIL_CONFIG, HEADLINES_RELEVANCE_THRESHOLD } from '../../../config/index.js';
import { LOGO_URL } from '../constants.js';
import { truncateString } from '../../../utils/helpers.js';
import Article from '../../../../models/Article.js';
import SynthesizedEvent from '../../../../models/SynthesizedEvent.js';

function escapeHtml(unsafe) {
    if (unsafe === null || unsafe === undefined) return '';
    return String(unsafe)
         .replace(/&/g, "&")
         .replace(/</g, "<")
         .replace(/>/g, ">")
         .replace(/"/g, "'")
         .replace(/'/g, "'");
}

function createSupervisorEmailWrapper(bodyContent) {
    return `
    <!DOCTYPE html>
    <html>
    <head><title>${SUPERVISOR_EMAIL_CONFIG.subject}</title></head>
    <body style="font-family: sans-serif; background-color: #f0f0f0; padding: 20px;">
        <table width="95%" border="0" cellspacing="0" cellpadding="20" style="max-width: 1200px; margin: auto; background-color: #ffffff;">
            <tr><td>${bodyContent}</td></tr>
        </table>
    </body>
    </html>`;
}

function createScraperHealthTable(healthStats) {
    if (!healthStats || healthStats.length === 0) return '';

    let table = `<h2>Scraper Health Check</h2>
    <table border="1" cellpadding="5" cellspacing="0" style="width: 100%; border-collapse: collapse; font-size: 12px;">
        <thead style="background-color: #f8f8f8;"><tr><th>Source</th><th>Status</th><th>Articles Found</th></tr></thead><tbody>`;
    
    healthStats.sort((a, b) => a.source.localeCompare(b.source));

    for (const stat of healthStats) {
        const status = stat.success ? 'âœ… OK' : 'âŒ FAILED';
        const statusColor = stat.success ? 'green' : 'red';
        table += `<tr>
                <td>${escapeHtml(stat.source)}</td>
                <td style="color: ${statusColor};">${status}</td>
                <td>${stat.count}</td>
            </tr>`;
    }
    table += `</tbody></table>`;
    return table;
}

async function createEventsTableHtml(runStartDate) {
    const recentEvents = await SynthesizedEvent.find({ createdAt: { $gte: runStartDate }})
                                                 .sort({ createdAt: -1 })
                                                 .limit(50)
                                                 .lean();
    if (recentEvents.length === 0) return `<h2>Synthesized Events from this Run</h2><p>No events were synthesized in this run.</p>`;

    let table = `<h2>Synthesized Events from this Run</h2>
    <table border="1" cellpadding="5" cellspacing="0" style="width: 100%; border-collapse: collapse; font-size: 12px;">
        <thead style="background-color: #f8f8f8;"><tr><th>Synthesized Headline</th><th>Score</th><th>Sources</th><th>Key Individuals</th><th>Emailed?</th></tr></thead><tbody>`;
    for (const event of recentEvents) {
        const sources = event.source_articles.map(a => a.newspaper).join(', ');
        const individuals = event.key_individuals.map(p => p.name).join(', ') || 'N/A';
        table += `<tr>
                <td>${truncateString(escapeHtml(event.synthesized_headline), 80)}</td>
                <td>${event.highest_relevance_score}</td>
                <td>${escapeHtml(sources)}</td>
                <td>${escapeHtml(individuals)}</td>
                <td>${event.emailed ? 'Yes' : 'No'}</td>
            </tr>`;
    }
    table += `</tbody></table>`;
    return table;
}

async function createArticlesTableHtml(runStartDate) {
    const freshArticles = await Article.find({ createdAt: { $gte: runStartDate }})
                                         .sort({ relevance_headline: -1 })
                                         .limit(100)
                                         .lean();
    if (freshArticles.length === 0) return `<h2>All Fresh Articles Processed</h2><p>No new raw articles were processed.</p>`;

    let table = `<h2>All Fresh Articles Processed in this Run</h2>
    <table border="1" cellpadding="5" cellspacing="0" style="width: 100%; border-collapse: collapse; font-size: 12px;">
        <thead style="background-color: #f8f8f8;"><tr><th>Headline</th><th>Source</th><th>HL Score</th><th>Status</th></tr></thead><tbody>`;
    for (const article of freshArticles) {
        const status = article.relevance_headline >= HEADLINES_RELEVANCE_THRESHOLD ? 'Relevant for Enrichment' : 'Low Relevance';
        table += `<tr>
                <td><a href="${article.link}">${truncateString(escapeHtml(article.headline), 80)}</a></td>
                <td>${escapeHtml(article.newspaper)}</td>
                <td>${article.relevance_headline}</td>
                <td>${status}</td>
            </tr>`;
    }
    table += `</tbody></table>`;
    return table;
}


export async function createSupervisorEmailBody(runStats) {
    const runTimestamp = new Date().toLocaleString('en-GB', { timeZone: 'Europe/Copenhagen' });
    const runStartDate = new Date(Date.now() - 5 * 60 * 1000); // Assume run started in last 5 mins for querying
    
    let statsHtml = `<h2>Run Statistics</h2><ul>`;
    const statOrder = ['headlinesScraped', 'freshHeadlinesFound', 'headlinesAssessed', 'relevantHeadlines', 'articlesEnriched', 'eventsClustered', 'eventsSynthesized', 'eventsEmailed', 'errors'];
    for (const key of statOrder) {
        if (runStats.hasOwnProperty(key)) {
            const value = runStats[key];
            const formattedKey = key.replace(/([A-Z])/g, ' $1').replace(/^./, str => str.toUpperCase());
            statsHtml += `<li><strong>${formattedKey}:</strong> ${Array.isArray(value) && value.length === 0 ? '0' : (Array.isArray(value) ? value.join(', ') : value)}</li>`;
        }
    }
    statsHtml += `</ul>`;

    const scraperHealthHtml = createScraperHealthTable(runStats.scraperHealth);
    
    const [eventsTableHtml, articlesTableHtml] = await Promise.all([
        createEventsTableHtml(runStartDate),
        createArticlesTableHtml(runStartDate)
    ]);
    
    const bodyContent = `
        <div style="text-align:center;"><img src="${LOGO_URL}" alt="Logo" style="max-width:150px;"></div>
        <h1 style="text-align:center;">${SUPERVISOR_EMAIL_CONFIG.subject}</h1>
        <p style="text-align:center;">Run completed: ${runTimestamp}</p>
        ${statsHtml}
        ${scraperHealthHtml}
        ${eventsTableHtml}
        ${articlesTableHtml}
        <div style="text-align: center; margin-top: 30px; font-size: 12px; color: #888888;">
            <p>This is an automated report from the ${SUPERVISOR_EMAIL_CONFIG.brandName}.</p>
        </div>
    `;

    return createSupervisorEmailWrapper(bodyContent);
}

# File: src/modules/email/constants.js
// src/modules/email/constants.js

// Placeholder for your logo URL (replace with actual URL to a PNG/JPG)
export const LOGO_URL =
  'https://static.seekingalpha.com/cdn/s3/uploads/getty_images/1493722121/image_1493722121.jpg'; // <-- REPLACE THIS


# File: src/modules/email/index.js
// src/modules/email/index.js
import { logger } from '../../utils/logger.js';
import { performActualEmailSend, performActualSupervisorEmailSend } from './mailer.js';
import SynthesizedEvent from '../../../models/SynthesizedEvent.js';

/**
 * Fetches unsent synthesized events, sends them in an email, and updates their status.
 * @returns {Promise<Object>} An object containing the count of events sent.
 */
export async function sendWealthEventsEmail() {
    logger.info(`ðŸ“§ Checking for new synthesized events to email...`);
    
    const eventsToSend = await SynthesizedEvent.find({ emailed: false }).sort({ createdAt: -1 }).lean();
    
    if (eventsToSend.length === 0) {
        logger.info('No new synthesized events to email.');
        return { eventsSentCount: 0 };
    }

    logger.info(`Found ${eventsToSend.length} new events to include in the wealth events email.`);
    
    const sortedEvents = [...eventsToSend].sort((a, b) => b.highest_relevance_score - a.highest_relevance_score);

    const emailSentSuccessfully = await performActualEmailSend(sortedEvents);

    if (emailSentSuccessfully) {
        const eventIds = eventsToSend.map(e => e._id);
        await SynthesizedEvent.updateMany(
            { _id: { $in: eventIds } },
            { $set: { emailed: true, email_sent_at: new Date() } }
        );
        logger.info(`Marked ${eventsToSend.length} events as emailed.`);
        return { eventsSentCount: eventsToSend.length };
    } else {
        logger.error('Wealth events email was not sent due to an error or dev mode skipping.');
        return { eventsSentCount: 0 };
    }
}

/**
 * Coordinates sending the supervisor report email.
 * @param {Object} runStats - Statistics about the current pipeline run.
 */
export async function sendSupervisorReportEmail(runStats) {
    if (!runStats) {
        logger.error('No runStats provided for supervisor report. Skipping email.');
        return;
    }
    
    logger.info('Preparing supervisor report email...');
    
    try {
        await performActualSupervisorEmailSend(runStats);
        logger.info('âœ… Supervisor report email successfully sent/queued.');
    } catch (error) {
        logger.error({ err: error }, 'ðŸ’¥ CRITICAL: Failed to send supervisor report email.');
    }
}

# File: src/modules/email/mailer.js
// src/modules/email/mailer.js
import nodemailer from 'nodemailer';
import { logger } from '../../utils/logger.js';
import { safeExecute } from '../../utils/helpers.js';
import {
  HEADLINE_RECIPIENTS,
  SUPERVISOR_EMAIL,
  EMAIL_CONFIG,
  SUPERVISOR_EMAIL_CONFIG,
  SMTP_CONFIG,
  SEND_TO_DEFAULT_SUPERVISOR,
  IS_PRODUCTION,
  FORCE_EMAIL_SEND_DEV
} from '../../config/index.js';
import { createEmailBody } from './components/emailBodyBuilder.js';
import { createSupervisorEmailBody } from './components/supervisorEmailBodyBuilder.js';

const SMTP_UNCONFIGURED_MSG = 'SMTP authentication not fully configured.';
const RECIPIENTS_UNCONFIGURED_MSG = 'Email recipients not configured.';

async function sendEmail(mailOptions, emailType) {
    if (!IS_PRODUCTION && !FORCE_EMAIL_SEND_DEV) {
        logger.warn(`[${emailType} Mailer] DEV MODE: Skipping actual email send to: ${mailOptions.to}`);
        return { skipped: true, reason: 'DEV mode' };
    }

    if (!SMTP_CONFIG?.auth?.user || !SMTP_CONFIG?.auth?.pass) {
        logger.error(`âŒ [${emailType} Mailer] ${SMTP_UNCONFIGURED_MSG}`);
        return { error: SMTP_UNCONFIGURED_MSG };
    }

    logger.info(`ðŸ“¤ [${emailType} Mailer] Sending email via Nodemailer to: ${mailOptions.to}.`);

    const transporter = nodemailer.createTransport(SMTP_CONFIG);

    const sendResult = await safeExecute(() => transporter.sendMail(mailOptions), {
        errorHandler: (error) => {
            logger.error(`âŒ [${emailType} Mailer] Nodemailer SMTP error:`, { message: error.message, code: error.code });
            return { errorOccurred: true, details: error.message };
        },
    });

    if (sendResult && sendResult.errorOccurred) {
        return { error: `SMTP Error: ${sendResult.details}` };
    }

    logger.info(`âœ… [${emailType} Mailer] Email sent successfully.`);
    return { success: true };
}

export async function performActualEmailSend(eventsForEmail) {
    if (!HEADLINE_RECIPIENTS || HEADLINE_RECIPIENTS.length === 0) {
        logger.error(`âŒ [Wealth Events Mailer] ${RECIPIENTS_UNCONFIGURED_MSG}`);
        return false;
    }

    const emailBodyHtml = createEmailBody(eventsForEmail);
    if (!emailBodyHtml) {
        logger.error('âŒ [Wealth Events Mailer] HTML email body generation failed.');
        return false;
    }

    const mailOptions = {
        from: `"${SMTP_CONFIG.fromName}" <${SMTP_CONFIG.fromAddress}>`,
        to: HEADLINE_RECIPIENTS.join(', '),
        subject: EMAIL_CONFIG.subject,
        html: emailBodyHtml,
    };

    const result = await sendEmail(mailOptions, 'Wealth Events');
    return result.success || false;
}

export async function performActualSupervisorEmailSend(runStats) {
    if (!SUPERVISOR_EMAIL || (SUPERVISOR_EMAIL.toLowerCase().includes('default') && !SEND_TO_DEFAULT_SUPERVISOR)) {
        logger.warn('[Supervisor Mailer] Skipping: Supervisor email not configured or is default.');
        return;
    }

    // CRITICAL FIX: The function createSupervisorEmailBody is now async, so we must 'await' it.
    const emailBodyHtml = await createSupervisorEmailBody(runStats);
    if (!emailBodyHtml) {
        logger.error('âŒ [Supervisor Mailer] HTML email body generation failed.');
        throw new Error('Failed to generate supervisor email body');
    }

    const mailOptions = {
        from: `"${SMTP_CONFIG.fromName}" <${SMTP_CONFIG.fromAddress}>`,
        to: SUPERVISOR_EMAIL,
        subject: SUPERVISOR_EMAIL_CONFIG.subject,
        html: emailBodyHtml,
    };

    const result = await sendEmail(mailOptions, 'Supervisor Report');

    if (result.error) {
        throw new Error(`Failed to send supervisor email: ${result.error}`);
    }
}

# File: src/modules/mongoStore/index.js
// src/modules/mongoStore/index.js
import Article from '../../../models/Article.js';
import { logger } from '../../utils/logger.js';
import { truncateString } from '../../utils/helpers.js';
import { generateEmbedding } from '../../utils/vectorUtils.js';
import { MIN_HEADLINE_CHARS, MAX_HEADLINE_CHARS, IS_REFRESH_MODE } from '../../config/index.js';

function validateInitialArticle(article) {
    if (!article || typeof article !== 'object') return 'Article object is invalid.';
    // In refresh mode, the article is already validated.
    if (article._id && IS_REFRESH_MODE) return null;
    
    if (!article.headline || article.headline.length < MIN_HEADLINE_CHARS) return `Headline is too short (min ${MIN_HEADLINE_CHARS}).`;
    if (article.headline.length > MAX_HEADLINE_CHARS) return `Headline is too long (max ${MAX_HEADLINE_CHARS}).`;
    if (!article.link || !article.link.startsWith('http')) return 'Link is invalid.';
    if (!article.newspaper) return 'Newspaper field is missing.';
    return null;
}

export async function filterFreshArticles(articles) {
    if (!articles || articles.length === 0) return [];

    if (IS_REFRESH_MODE) {
        logger.warn('REFRESH MODE: Re-fetching all scraped articles from DB to re-process.');
        const links = articles.map(a => a.link);
        const refreshedArticles = await Article.find({ link: { $in: links } }).lean();
        logger.info(`Found ${refreshedArticles.length} existing articles to refresh.`);
        return refreshedArticles;
    }
    
    const links = articles.map(a => a.link);
    const existingArticles = await Article.find({ link: { $in: links } }).select('link').lean();
    const existingLinks = new Set(existingArticles.map(a => a.link));
    
    const freshArticles = articles.filter(a => !existingLinks.has(a.link));
    logger.info(`Filtering complete. Found ${existingLinks.size} existing articles, ${freshArticles.length} are fresh.`);
    return freshArticles;
}

export async function prepareArticlesForPipeline(articles) {
    const articlesToProcess = [];
    
    for (const article of articles) {
        const validationError = validateInitialArticle(article);
        if (validationError) {
            logger.warn(`Initial validation failed for "${truncateString(article.headline, 50)}": ${validationError}`);
            continue;
        }
        articlesToProcess.push(article);
    }

    if (articlesToProcess.length === 0) {
        logger.info('No valid new or refreshed articles to prepare for the pipeline.');
        return [];
    }

    const operations = [];
    for (const article of articlesToProcess) {
        // Only generate a new embedding if it's a new article. Refreshed articles already have one.
        let embedding = article.embedding;
        if (!embedding) {
            const textToEmbed = article.headline;
            embedding = await generateEmbedding(textToEmbed);
        }

        const updatePayload = {
            ...article,
            embedding,
            // Reset assessment fields for a fresh run
            relevance_headline: 0,
            assessment_headline: 'Awaiting assessment',
            relevance_article: null,
            assessment_article: null,
            key_individuals: [],
            error: null,
            enrichment_error: null,
        };
        // Remove _id from the payload to avoid immutable field errors on upsert
        delete updatePayload._id; 

        operations.push({
            updateOne: {
                filter: { link: article.link },
                update: { $set: updatePayload },
                upsert: true
            }
        });
    }

    try {
        logger.info(`Preparing ${operations.length} articles in the database for processing...`);
        const bulkResult = await Article.bulkWrite(operations);
        logger.info(`DB Prep complete. Upserted: ${bulkResult.upsertedCount}, Modified: ${bulkResult.modifiedCount}`);

        const links = articlesToProcess.map(a => a.link);
        const finalDocs = await Article.find({ link: { $in: links } }).lean();
        return finalDocs;
    } catch (error) {
        logger.error({ err: error }, 'Bulk upsert operation failed during article preparation.');
        return [];
    }
}

export async function updateArticlesWithFullData(articles) {
    if (articles.length === 0) return [];

    const operations = [];
    for (const article of articles) {
        const { _id, ...dataToSet } = article;
        Object.keys(dataToSet).forEach(key => dataToSet[key] === undefined && delete dataToSet[key]);
        
        const textToEmbed = `${article.headline}\n${article.assessment_article || ''}\n${(article.articleContent?.contents || []).join(' ').substring(0, 500)}`;
        dataToSet.embedding = await generateEmbedding(textToEmbed);

        operations.push({
            updateOne: {
                filter: { _id: article._id },
                update: { $set: dataToSet },
            },
        });
    }

    if (operations.length > 0) {
        try {
            logger.info(`Updating ${operations.length} articles with full data and new embeddings.`);
            await Article.bulkWrite(operations, { ordered: false });
            return articles.map(a => ({...a, db_operation_status: 'updated'}));
        } catch (error) {
            logger.error({ err: error }, 'Bulk write operation failed for final data update.');
            return articles.map(a => ({...a, db_operation_status: 'failed', db_error_reason: 'Bulk DB op failed.' }));
        }
    }
    return [];
}

# File: src/modules/scraper/index.js
// src/modules/scraper/index.js
import axios from 'axios';
import * as cheerio from 'cheerio';
import pLimit from 'p-limit';
import { HttpsProxyAgent } from 'https-proxy-agent';
import { logger } from '../../utils/logger.js';
import { safeExecute } from '../../utils/helpers.js';
import { CONCURRENCY_LIMIT, SCRAPER_PROXY_URL } from '../../config/index.js';
import { SITES_CONFIG, TEXT_SELECTORS } from '../../config/sources.js';

const limit = pLimit(CONCURRENCY_LIMIT);

const axiosInstance = axios.create();
if (SCRAPER_PROXY_URL) {
    logger.info(`Using scraper proxy: ${new URL(SCRAPER_PROXY_URL).hostname}`);
    const httpsAgent = new HttpsProxyAgent(SCRAPER_PROXY_URL);
    axiosInstance.defaults.httpsAgent = httpsAgent;
    axiosInstance.defaults.httpAgent = httpsAgent;
}

const BROWSER_HEADERS = {
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
    'Accept-Encoding': 'gzip, deflate, br',
    'Accept-Language': 'en-US,en;q=0.9',
    'Sec-Ch-Ua': '"Not/A)Brand";v="99", "Google Chrome";v="115", "Chromium";v="115"',
    'Sec-Ch-Ua-Mobile': '?0',
    'Sec-Ch-Ua-Platform': '"Windows"',
    'Sec-Fetch-Dest': 'document',
    'Sec-Fetch-Mode': 'navigate',
    'Sec-Fetch-Site': 'none',
    'Sec-Fetch-User': '?1',
    'Upgrade-Insecure-Requests': '1',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36',
};

async function fetchPage(url) {
    const axiosConfig = { headers: BROWSER_HEADERS, timeout: 30000 };
    const result = await safeExecute(() => axiosInstance.get(url, axiosConfig), {
        errorHandler: (err) => {
            const status = err.response ? err.response.status : 'N/A';
            if (err.code === 'ECONNABORTED' || err.message.includes('timeout')) {
                logger.error(`Request to ${url} timed out after 30 seconds.`);
            } else {
                logger.error(`Failed to fetch page ${url} [Status: ${status}].`);
            }
            return null;
        }
    });
    return result;
}

async function scrapeSite(site) {
    logger.debug(`Scraping headlines from ${site.name}`);
    
    // --- SPECIAL API-BASED SCRAPING FOR EQT ---
    if (site.name === 'EQT') {
        const pageResponse = await fetchPage(site.url);
        if (!pageResponse) return { source: site.name, articles: [], success: false };

        const buildIdMatch = pageResponse.data.match(/"buildId":"([a-zA-Z0-9_-]+)"/);
        if (!buildIdMatch || !buildIdMatch[1]) {
            logger.warn(`Could not find Build ID for EQT. Site structure may have changed.`);
            return { source: site.name, articles: [], success: false };
        }
        const buildId = buildIdMatch[1];
        const apiUrl = `${site.url.replace('/news', '')}/_next/data/${buildId}/en/news.json`;

        const apiResponse = await fetchPage(apiUrl);
        if (!apiResponse) return { source: site.name, articles: [], success: false };
        
        try {
            const hits = apiResponse.data?.pageProps?.page?.pageContent?.find(c => c._type === 'listing')?.initialResults?.main?.hits || [];
            const articles = hits.map(hit => ({
                headline: hit.thumbnail.title,
                link: new URL(hit.thumbnail.path, site.url).href,
                source: site.name,
                newspaper: site.newspaper,
            }));
            logger.info(`Scraped ${articles.length} unique headlines from ${site.name}.`);
            return { source: site.name, articles, success: true };
        } catch (e) {
            logger.error({ err: e }, `Failed to parse API response from EQT.`);
            return { source: site.name, articles: [], success: false };
        }
    }

    // --- STANDARD HTML SCRAPING FOR ALL OTHER SITES ---
    const response = await fetchPage(site.url);
    if (!response) {
        return { source: site.name, articles: [], success: false };
    }
    
    const $ = cheerio.load(response.data);
    let articles = [];

    if (site.useJsonLd) {
        $('script[type="application/ld+json"]').each((_, el) => {
            try {
                const jsonData = JSON.parse($(el).html());
                if (jsonData['@type'] === 'ItemList' && jsonData.itemListElement) {
                    jsonData.itemListElement.forEach(item => {
                        if (item.name && item.url) articles.push({ headline: item.name, link: item.url, source: site.name, newspaper: site.name });
                    });
                }
            } catch (e) { 
                logger.warn({ err: e, site: site.name }, `Failed to parse JSON-LD from ${site.name}`);
            }
        });
    } else {
        $(site.selector).each((_, el) => {
            const articleData = site.extract($(el), site);
            if (articleData && articleData.headline && articleData.link) {
                articles.push(articleData);
            }
        });
    }
    
    const uniqueArticles = Array.from(new Map(articles.map(a => [a.link, a])).values());
    logger.info(`Scraped ${uniqueArticles.length} unique headlines from ${site.name}.`);
    return { source: site.name, articles: uniqueArticles, success: true };
}

export async function scrapeAllHeadlines() {
    logger.info('ðŸ“° Starting headline scraping from all sources...');
    const promises = Object.values(SITES_CONFIG).map(site => limit(() => scrapeSite(site)));
    const results = await Promise.all(promises);

    const allArticles = results.flatMap(r => r.articles);
    const scraperHealth = results.map(r => ({ source: r.source, success: r.success, count: r.articles.length }));

    return { allArticles, scraperHealth };
}

export async function scrapeArticleContent(article) {
    logger.debug(`Enriching article: ${article.link}`);
    
    const pageResponse = await fetchPage(article.link);
    if (!pageResponse) {
        return { ...article, enrichment_error: 'Failed to fetch page' };
    }
    
    // --- SPECIAL JSON-BASED ENRICHMENT FOR EQT ARTICLES ---
    if (article.newspaper === 'EQT') {
        const $page = cheerio.load(pageResponse.data);
        const scriptData = $page('script#__NEXT_DATA__').html();
        if (scriptData) {
            try {
                const jsonData = JSON.parse(scriptData);
                // Navigate through the complex JSON structure to find the article body
                const pageContent = jsonData?.props?.pageProps?.page?.pageContent;
                if (pageContent) {
                    const richTextBlock = pageContent.find(block => block._type === 'richTextBlock');
                    if (richTextBlock && richTextBlock.body) {
                        const bodyHtml = richTextBlock.body;
                        const $body = cheerio.load(bodyHtml);
                        const fullText = $body.text().replace(/\s\s+/g, ' ').trim();
                        article.articleContent = { contents: [fullText] };
                        return article;
                    }
                }
            } catch (e) {
                logger.warn({ err: e }, `Failed to parse JSON data for EQT article: ${article.link}. Falling back to standard method.`);
            }
        }
    }

    // --- STANDARD METHOD FOR ALL OTHER SITES (AND EQT FALLBACK) ---
    const newspaperName = article.newspaper || article.source;
    const selector = TEXT_SELECTORS[newspaperName];
    if (!selector) {
        logger.warn(`No text selector for newspaper "${newspaperName}".`);
        return { ...article, enrichment_error: 'No selector' };
    }

    const $ = cheerio.load(pageResponse.data);
    const fullText = $(selector).map((_, el) => $(el).text()).get().join(' ').replace(/\s\s+/g, ' ').trim();
    
    if (fullText) {
        article.articleContent = { contents: [fullText] };
    } else {
        logger.warn(`Could not find text for "${article.headline}" with selector "${selector}"`);
        article.enrichment_error = 'Content not found';
    }
    return article;
}

# File: src/utils/helpers.js
// src/utils/helpers.js (version 1.0)
import { logger } from './logger.js';

/**
 * Truncates a string to a specified length, adding an ellipsis if truncated.
 * @param {string} str The string to truncate.
 * @param {number} maxLength The maximum length of the string.
 * @returns {string} The truncated string.
 */
export function truncateString(str, maxLength = 100) {
    if (typeof str !== 'string' || str.length <= maxLength) {
        return str;
    }
    return str.substring(0, maxLength) + '...';
}

/**
 * Executes an async function and handles errors gracefully.
 * @param {() => Promise<any>} asyncFn The async function to execute.
 * @param {{errorHandler: (error: Error) => any}} options Error handling options.
 * @returns {Promise<any>} The result of the function or the error handler.
 */
export async function safeExecute(asyncFn, { errorHandler } = {}) {
    try {
        return await asyncFn();
    } catch (error) {
        if (errorHandler) {
            return errorHandler(error);
        }
        logger.error({ err: error }, 'An unexpected error occurred in a safeExecute block.');
        return null; // Default fallback
    }
}

# File: src/utils/logger.js
// src/utils/logger.js
import pino from 'pino';
import { LOG_LEVEL, IS_PRODUCTION } from '../config/index.js';

const pinoConfig = {
    level: LOG_LEVEL || 'info',
    // More concise logging by default, removing pid and hostname
    base: undefined, 
};

if (!IS_PRODUCTION) {
    pinoConfig.transport = {
        target: 'pino-pretty',
        options: {
            colorize: true,
            translateTime: 'HH:MM:ss',
            ignore: 'pid,hostname,runStats', // MODIFIED: Ignore the verbose runStats object in console output
        },
    };
}

export const logger = pino(pinoConfig);

# File: src/utils/vectorUtils.js
// src/utils/vectorUtils.js
import { pipeline } from '@xenova/transformers';

// Use a singleton pattern to ensure we only load the model once.
class EmbeddingPipeline {
    static task = 'feature-extraction';
    static model = 'Xenova/all-MiniLM-L6-v2';
    static instance = null;

    static async getInstance(progress_callback = null) {
        if (this.instance === null) {
            this.instance = pipeline(this.task, this.model, { progress_callback });
        }
        return this.instance;
    }
}

/**
 * Generates an embedding for a given text.
 * @param {string} text The text to embed.
 * @returns {Promise<Array<number>>} A promise that resolves to the embedding vector.
 */
export async function generateEmbedding(text) {
    const extractor = await EmbeddingPipeline.getInstance();
    const output = await extractor(text, { pooling: 'mean', normalize: true });
    return Array.from(output.data);
}

/**
 * Calculates the cosine similarity between two vectors.
 * @param {Array<number>} vecA The first vector.
 * @param {Array<number>} vecB The second vector.
 * @returns {number} The cosine similarity score (between -1 and 1).
 */
export function cosineSimilarity(vecA, vecB) {
    let dotProduct = 0.0;
    let normA = 0.0;
    let normB = 0.0;
    for (let i = 0; i < vecA.length; i++) {
        dotProduct += vecA[i] * vecB[i];
        normA += vecA[i] * vecA[i];
        normB += vecB[i] * vecB[i];
    }
    return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}
